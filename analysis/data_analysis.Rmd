---
title: "Task mapping data analysis"
---

```{r setup, include=FALSE}
library(irr)
library(ggplot2)
library(jsonlite)
library(graphics)
library(ggfortify)
library(factoextra)
library(stats)
library(ggpubr)
library(dbscan)
library(dplyr)
library(tidyverse)
```

# Import Data
```{r}
numerical_responses_matrix <- read_csv('../task_map_numeric.csv')

ordinals <- read_csv('../ordinals.csv')

clean_responses <- read_csv("../cleaned_task_responses.csv")

agreed_responses <- read_csv("../task_map.csv")

questions <- fromJSON("https://task-robot.glitch.me/questions/json")
```


# Addressing Github #199 - Similar Question Sanity Check
```{r}
# github issue 199: Add similar question sanity check in analysis

# QUESTIONS THAT ARE LOGICALLY EXCLUSIONARY #
# goal_full + goal_partial == 6, because they need to be complements
# options_independent + options_dependent== 6, because these are also opposites
# outcome_certain + outcome_probablistic == 6, because these are also opposites
# individual_theoretical + individual_practical == 6, because these are also opposites
# submission_together + submission_separate == 6, because these are also opposites

numerical_completed_tasks <- cbind(task_names, numerical_responses_matrix)

# correct a typo
numerical_completed_tasks <- numerical_completed_tasks %>%
  rename(individual_theoretical = indvidual_theoretical)

# Filter for questions that are logically exclusionary
TOTAL_SCORE = 6

filter_for_agreement <- function(data_table){
  
  data_table <- data_table %>% filter(goal_full+goal_partial == TOTAL_SCORE) %>%
  filter(options_independent+options_dependent == TOTAL_SCORE) %>%
  filter(outcome_certain+outcome_probablistic == TOTAL_SCORE) %>%
  filter(individual_theoretical+individual_practical == TOTAL_SCORE) %>%
  filter(submission_together + submission_separate == TOTAL_SCORE)
  
  return(data_table)
}

# Save the ones that disagree so that we can peek at them
goal_disagreement<- numerical_completed_tasks %>%
  filter(goal_full+goal_partial != TOTAL_SCORE) %>%
  select(c(task_names, goal_full, goal_partial)) %>%
  pivot_longer(c(goal_full, goal_partial), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "goal_full",
    question2 = "goal_partial"
  ) %>%
  rename(
    answer1 = goal_full,
    answer2 = goal_partial,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

options_disagreement<- numerical_completed_tasks %>%
  filter(options_independent+options_dependent != TOTAL_SCORE)%>%
  select(c(task_names, options_independent, options_dependent)) %>%
  pivot_longer(c(options_independent, options_dependent), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "options_independent",
    question2 = "options_dependent"
  ) %>%
  rename(
    answer1 = options_independent,
    answer2 = options_dependent,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

outcome_disagreement<- numerical_completed_tasks %>%
  filter(outcome_certain+outcome_probablistic != TOTAL_SCORE) %>%
  select(c(task_names, outcome_certain, outcome_probablistic)) %>%
  pivot_longer(c(outcome_certain, outcome_probablistic), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "outcome_certain",
    question2 = "outcome_probablistic"
  ) %>%
  rename(
    answer1 = outcome_certain,
    answer2 = outcome_probablistic,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

individual_disagreement<- numerical_completed_tasks %>%
  filter(individual_theoretical+individual_practical != TOTAL_SCORE)%>%
  select(c(task_names, individual_theoretical, individual_practical)) %>%
  pivot_longer(c(individual_theoretical, individual_practical), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
   pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "individual_theoretical",
    question2 = "individual_practical"
  ) %>%
  rename(
    answer1 = individual_theoretical,
    answer2 = individual_practical,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

submission_disagreement<- numerical_completed_tasks %>%
  filter(submission_together+submission_separate != TOTAL_SCORE)%>%
  select(c(task_names, submission_together, submission_separate)) %>%
  pivot_longer(c(submission_together, submission_separate), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "submission_together",
    question2 = "submission_separate"
  ) %>%
  rename(
    answer1 = submission_together,
    answer2 = submission_separate,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))


## consolidate into single csv
inconsistent_questions <- goal_disagreement %>% rbind(options_disagreement) %>%
  rbind(outcome_disagreement) %>% rbind(individual_disagreement) %>% rbind(submission_disagreement)

write.csv(inconsistent_questions,"./analysis_experiments/task_mapping_issues.csv")
```

## Save the agreed ones
```{r}
numerical_completed_and_agreed <- filter_for_agreement(numerical_completed_tasks)
```

# Filtering by Data Source / Top down v. Bottom up Explorations
```{r warning=FALSE}
questions$source_clean = as.factor(questions$source_clean)
questions$source = as.factor(questions$source)

get_filtered_data_for_author <- function(source_name) {
  filtered_questions <-
    questions %>% filter(source_clean == source_name)
  
  filtered_colnams <-
    as.data.frame(filtered_questions$name) %>% rename(name = `filtered_questions$name`)
  
  column_names <-
    pull(inner_join(ordinals %>% rename(name = `ordinals$name`),
                    filtered_colnams), name)
  
  numerical_responses_one_framework <-
    numerical_responses_matrix %>% select(all_of(c(column_names)))
  
  return(cbind(task_names,numerical_responses_one_framework))
  # note - not filtered bc the columns may not exist in there
}

shaw_data <- get_filtered_data_for_author("Shaw")
mcgrath_data <- get_filtered_data_for_author("McGrath")
zigurs_data <- get_filtered_data_for_author("Zigurs")
steiner_data <- get_filtered_data_for_author("Steiner")
```

## Classification in the "old-school" way

### McGrath
```{r}
# Get all columns needed to make McGrath Classification -----------------
additional_mcgrath_cols <-
  numerical_responses_matrix %>% select(
    c(
      "effort_mental",
      "effort_physical",
      "solution_objectivity",
      "solution_verifiability"
    )
  )

mcgrath_data <- cbind(mcgrath_data, additional_mcgrath_cols)
```

```{r}
# Code to make mcgrath categorizations
make_mcgrath_categorizations <- function(MIDDLE, mcgrath_data) {
  #### Execute Tasks (1,8,7,6) ####
  physical_tasks <-
    mcgrath_data %>% filter(effort_mental < MIDDLE |
                              effort_physical > MIDDLE) # there are only 4 of these
  
  # Note --- noticing that I get 0 tasks for type 7 when I filter for physical in this section; thus, I'm loosening the filtering requirements here
  # Noting that "physical" elements are not consistent across different parts of the sectors
  
  ### Type 7: Battles
  type_7 <-
    mcgrath_data %>% filter(conflict_cooperation > MIDDLE) %>%
    filter(external_adversary > MIDDLE)
  
  ### Type 8: Performances
  type_8 <-
    execute_tasks %>%
    filter((conflict_cooperation < MIDDLE) &
             !(generate_process > MIDDLE) &
             !(generate_plan > MIDDLE) &
             external_standard > MIDDLE
    )
  
  # 1 and 6 ---- WEAK EXECUTE
  # Noticing that if you filter for the physical aspect, you get 0 tasks, so I got rid of it
  
  ### Type 1: Planning
  type_1 <-
    mcgrath_data %>% filter(conflict_cooperation < MIDDLE) %>%
    filter(generate_plan > MIDDLE | generate_process > MIDDLE)
  
  ### Type 6: Mixed Motives
  type_6 <-
    mcgrath_data %>% filter(conflict_cooperation > MIDDLE)  %>%
    filter(conflict_interests > MIDDLE)
  
  ############ Conceptual Tasks (2,3,4,5) ############
  mental_tasks <-
    mcgrath_data %>% filter(effort_mental > MIDDLE |
                              effort_physical < MIDDLE)
  
  ## Cooperation (2,3)
  mental_cooperate <- mental_tasks %>%
    filter(conflict_cooperation < MIDDLE)
  
  ### Type 2: Creativity
  type_2 <- mental_cooperate %>%
    filter(generate_ideas > MIDDLE | generate_creativity > MIDDLE)
  
  ### Type 3: Intellective
  type_3 <- mental_cooperate %>%
    filter(
      solution_objectivity > MIDDLE |
        solution_verifiability > MIDDLE | external_standard > MIDDLE
    )
  
  ## Conflict (4,5)
  mental_conflict <-  mental_tasks %>%
    filter(conflict_cooperation > MIDDLE)
  
  ### Type 4: Decision-Making
  type_4 <- mental_conflict %>%
    filter(solution_objectivity < MIDDLE |
             solution_verifiability < MIDDLE)
  
  ### Type 5: Cognitive Conflict
  type_5 <- mental_conflict %>%
    filter(resolve_opinion > MIDDLE | resolve_perspectives > MIDDLE)

####### export the data --- currently commented out
  mcgrath_quadrant_labels <- data.frame(task_names)

  for (i in 1:nrow(mcgrath_data)) {
    task = mcgrath_data$task_names[i]
    mcgrath_quadrant_labels$generate.planning[i] = as.numeric(task %in% type_1$task_names)
    mcgrath_quadrant_labels$generate.creativity[i] = as.numeric(task %in% type_2$task_names)

    mcgrath_quadrant_labels$choose.intellective[i] = as.numeric(task %in% type_3$task_names)
    mcgrath_quadrant_labels$choose.decision[i] = as.numeric(task %in% type_4$task_names)

    mcgrath_quadrant_labels$negotiate.cogconf[i] = as.numeric(task %in% type_5$task_names)
    mcgrath_quadrant_labels$negotiate.mixmotive[i] = as.numeric(task %in% type_6$task_names)

    mcgrath_quadrant_labels$execute.contest[i] = as.numeric(task %in% type_7$task_names)
    mcgrath_quadrant_labels$execute.performance[i] = as.numeric(task %in% type_8$task_names)
  }

  return(mcgrath_quadrant_labels)
  
  # write.csv(
  #   mcgrath_quadrant_labels,
  #   paste(
  #     './analysis_experiments/mcgrath-quadrant-labels-',
  #     MIDDLE,
  #     '.csv'
  #   )
  # )

}
```

Actually run the McGrath categorizations
```{r}
for(MIDDLE in 2:4){ # MIDDLE is used to separate the types of tasks
  make_mcgrath_categorizations(MIDDLE,mcgrath_data)
}
```

```{r mcgrath-intensity}
# Code to weight mcgrath categorizations
create_weighted_mcgrath<- function(MIDDLE) {
  print(MIDDLE)
  
  # Read in McGrath Categorizations
  mcgrath_labels <-  paste('./analysis_experiments/mcgrath-quadrant-labels-',
                           MIDDLE,
                           '.csv') %>% read_csv()
  REVERSE = 6
  
  type_1 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(generate.planning != 0))$task_names) %>%
    mutate(type_1_score = 
             (generate_plan + generate_process) / 
             (max(generate_plan) + max(generate_process))) %>% select(task_names, type_1_score)
  type_2 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(generate.creativity != 0))$task_names) %>%
    mutate(type_2_score = (generate_ideas + generate_creativity) /
             (max(generate_ideas) + max(generate_creativity))) %>% select(task_names, type_2_score)
  type_3 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(choose.intellective != 0))$task_names) %>%
    mutate(
      type_3_score = (
        solution_objectivity + solution_verifiability + external_standard) /
        (max(solution_objectivity) + max(solution_verifiability) + max(external_standard)
      )
    ) %>% select(task_names, type_3_score)
  type_4 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(choose.decision != 0))$task_names)%>%
    mutate(
      type_4_score = (
        REVERSE - solution_objectivity + REVERSE - solution_verifiability
      ) / (10)
    ) %>% select(task_names, type_4_score)
  type_5 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(negotiate.cogconf != 0))$task_names) %>%
    mutate(
      type_5_score = (
        resolve_opinion + resolve_perspectives
      ) / ((max(resolve_opinion) + max(resolve_perspectives)))
    ) %>% select(task_names, type_5_score)
  type_6 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(negotiate.mixmotive != 0))$task_names) %>%
    mutate(type_6_score = (conflict_cooperation + conflict_interests) /
             (max(conflict_cooperation) + max(conflict_interests))) %>% select(task_names, type_6_score)
  type_7 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(execute.contest != 0))$task_names) %>%
    mutate(type_7_score = (conflict_cooperation + external_adversary) /
             (max(conflict_cooperation) + max(external_adversary))) %>% select(task_names, type_7_score)
  type_8 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(execute.performance != 0))$task_names) %>%
    mutate(type_8_score = (REVERSE - conflict_cooperation + external_standard) /
             (10)) %>% select(task_names, type_8_score)

  #### export all results as a weighted matrix instead
  mcgrath_quadrant_labels_weighted <- data.frame(task_names)

  for (i in 1:nrow(mcgrath_data)) {
    task = mcgrath_data$task_names[i]
    mcgrath_quadrant_labels_weighted$generate.planning[i] = ifelse(task %in% type_1$task_names,
     (type_1 %>% filter(task_names == task))$type_1_score, 0)
    mcgrath_quadrant_labels_weighted$generate.creativity[i] = ifelse(task %in% type_2$task_names,
     (type_2 %>% filter(task_names == task))$type_2_score, 0)
    mcgrath_quadrant_labels_weighted$choose.intellective[i] = ifelse(task %in% type_3$task_names,
     (type_3 %>% filter(task_names == task))$type_3_score, 0)
    mcgrath_quadrant_labels_weighted$choose.decision[i] = ifelse(task %in% type_4$task_names,
     (type_4 %>% filter(task_names == task))$type_4_score, 0)
    mcgrath_quadrant_labels_weighted$negotiate.cogconf[i] = ifelse(task %in% type_5$task_names,
     (type_5 %>% filter(task_names == task))$type_5_score, 0)
    mcgrath_quadrant_labels_weighted$negotiate.mixmotive[i] = ifelse(task %in% type_6$task_names,
     (type_6 %>% filter(task_names == task))$type_6_score, 0)
    mcgrath_quadrant_labels_weighted$execute.contest[i] = ifelse(task %in% type_7$task_names,
     (type_7 %>% filter(task_names == task))$type_7_score, 0)
    mcgrath_quadrant_labels_weighted$execute.performance[i] = ifelse(task %in% type_8$task_names,
     (type_8 %>% filter(task_names == task))$type_8_score, 0)
  }

  write.csv(
    mcgrath_quadrant_labels_weighted,
    paste(
      './analysis_experiments/mcgrath-quadrant-labels-weighted',
      MIDDLE,
      '.csv'
    )
  )
  
}
```

```{r}
for(MIDDLE in 2:4){ # MIDDLE is used to separate the types of tasks
  create_weighted_mcgrath(MIDDLE)
}
```

#### Bootstrapping McGrath
```{r}
set.seed(123)

# Select rows with replacement from dataframe
MIDDLE <- 4
N_REPS <- 1000
N_SAMPLES <- nrow(mcgrath_data)

list_num_zeroes<-c()
list_num_above_ones<-c()

for(i in 1:N_REPS){
  sampled_mcgrath_data <- mcgrath_data[sample(nrow(mcgrath_data), N_SAMPLES, replace = T), ]
  mcgrath_categorizations <- make_mcgrath_categorizations(MIDDLE,sampled_mcgrath_data)
  
  #calculate the stats: Num unmapped tasks, Num tasks mapped to more than 1 category
  label_frequency_table <- mcgrath_categorizations %>% mutate(
    num_labels = rowSums(across(where(is.numeric)))
  ) %>% select(num_labels) %>% table()
  
  num_zero <- label_frequency_table[1]
  num_above_one <- ifelse(
    length(label_frequency_table)==4,
    label_frequency_table[4] + label_frequency_table[3],
    label_frequency_table[3]
  )
  
  list_num_zeroes[i] <- num_zero
  list_num_above_ones[i] <- num_above_one

}

sd(list_num_zeroes)
sd(list_num_above_ones)
```

#### Identifying McGrath's Peculiarities
```{r}
# Check Labels
mcgrath_labels_2 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 2 .csv')
mcgrath_labels_3 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 3 .csv')
mcgrath_labels_4 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 4 .csv')

## List of peculiar tasks that get labeled inconsistently
union(
  union(
    setdiff(mcgrath_labels_2, mcgrath_labels_3)$task_names,
    setdiff(mcgrath_labels_3, mcgrath_labels_4)$task_names
  ),
  setdiff(mcgrath_labels_2, mcgrath_labels_4)$task_names
)

```

```{r old-mcgrath}
# This was Emily's first attempt at doing this - saving for posterity but redoing#
# 
# # 1. Generating Alternatives
# mcg_generating <- mcgrath_data %>%
#   filter(
#     (generate_plan > MIDDLE | generate_process > MIDDLE | generate_ideas > MIDDLE | generate_creativity > MIDDLE) & #  Creativity markers
#     (conflict_cooperation < MIDDLE & conflict_interests < MIDDLE) & # NOT conflict/cooperation or conflict of interests
#     (solution_objectivity < MIDDLE | solution_verifiability < MIDDLE) # NOT objective - but this is an OR because some plans are objective?
#     )
# 
# # 2. Choosing Alternatives
# mgc_choosing <- data_with_mcgrath_cols %>%
#   filter(
#     (solution_objectivity > MIDDLE & solution_verifiability > MIDDLE) & # Markers of Objective Choice
#     (generate_plan < MIDDLE | generate_process < MIDDLE | generate_ideas < MIDDLE | generate_creativity < MIDDLE) #  NOT Generating markers
#     # Agnostic towards Negotiation b/c sometimes the choice is a negotiation
#     )
# 
# # 3. Negotiate
# mcg_negotiating <- data_with_mcgrath_cols %>%
#   filter(
#     (resolve_opinion > MIDDLE | resolve_perspectives > MIDDLE | conflict_interests > MIDDLE | conflict_cooperation > MIDDLE) &# Negotiation markers
#      (solution_objectivity < MIDDLE | solution_verifiability < MIDDLE) & # No correct solution (excludes CHOOSE or is explicitly a conflict and cooperation game)
#      (generate_creativity < MIDDLE) # definitely NOT creativity
#     )
# 
# # 4. Execute
# mcg_executing <- data_with_mcgrath_cols %>%
#   filter(
#     (external_adversary > MIDDLE | external_standard > MIDDLE | conflict_interests > MIDDLE) & # Markers of Execute
#     (generate_plan < MIDDLE | generate_process < MIDDLE | generate_ideas < MIDDLE | generate_creativity < MIDDLE) & #  NOT Generating markers
#     (resolve_opinion < MIDDLE & resolve_perspectives < MIDDLE ) # NOT Negotiation markers
#   )

####### Generate McGrath Categorization Summary #####
# mcgrath_quadrant_labels <- data.frame(task_names)
# 
# for (i in 1:nrow(data_with_mcgrath_cols)) {
#   task = data_with_mcgrath_cols$task_names[i]
#   mcgrath_quadrant_labels$generating[i] = as.numeric(task %in% mcg_generating$task_names)
#   mcgrath_quadrant_labels$choosing[i] = as.numeric(task %in% mgc_choosing$task_names)
#   mcgrath_quadrant_labels$negotiating[i] = as.numeric(task %in% mcg_negotiating$task_names)
#   mcgrath_quadrant_labels$executing[i] = as.numeric(task %in% mcg_executing$task_names)
# }
# 
# mcgrath_quadrant_labels <- mcgrath_quadrant_labels %>% mutate(
#   num_total_labels = generating+choosing+negotiating+executing
# )
# table(mcgrath_quadrant_labels$num_total_labels)
# 
# write.csv(mcgrath_quadrant_labels, './analysis_experiments/mcgrath-quadrant-labels.csv')
```


### Steiner
```{r}

### Subtask Structure

# Divisible Tasks
steiner_divisible <- steiner_data %>% filter(
  goal_full < MIDDLE & # there is partial credit - can be divided 
  (goal_partial > MIDDLE | # the rest of these indicate divisibility
  task_divisibility > MIDDLE | # using OR here to cast wider net / gradient
  submission_separate > MIDDLE |
  task_specialization > MIDDLE)
)

# Unitary Tasks
steiner_unitary <- steiner_data %>% filter(
  goal_full > MIDDLE & # there is no partial credit - can't be divided 
  (goal_partial < MIDDLE | # the rest of these indicate divisibility
  task_divisibility < MIDDLE |
  submission_separate < MIDDLE |
  task_specialization < MIDDLE)
)


### Nature of the Goal

# Open question: is it possible to be both maximizing and optimizing?
# Maximizing Tasks
steiner_maximizing <- steiner_data %>% filter(
  goal_maximize > MIDDLE
)

# Optimizing Tasks
steiner_optimizing <- steiner_data %>% filter(
  goal_standard > MIDDLE |
  goal_optimize > MIDDLE
)


### Permitted Group Processes

# Additive Tasks
steiner_additive <- steiner_data %>% filter(
  (subtasks_additive > MIDDLE |
  performance_average > MIDDLE |
  performance_cumulative > MIDDLE) &
  (performance_worst < MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive < MIDDLE & # Disjunctive Characteristics - AND here because it CANNOT be either of these things
  performance_best < MIDDLE) &
  (subtasks_discretionary_weight < MIDDLE) & # NEED to be false for additive
  (subtasks_discretionary_combination < MIDDLE) 
)

# Conjunctive Tasks
steiner_conjunctive <- steiner_data %>% filter(
  (subtasks_additive < MIDDLE & # Additive Characteristics - AND because these cannot be true
  performance_average < MIDDLE &
  performance_cumulative < MIDDLE) &
  (performance_worst > MIDDLE |
     participation_equal > MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive < MIDDLE | # Disjunctive Characteristics, but keeping OR because it's possible w/ conjunctive to have one person determine the outcome ... the worst one
  performance_best < MIDDLE)
)

# Disjunctive Tasks
steiner_disjunctive <- steiner_data %>% filter(
  (subtasks_additive < MIDDLE &# Additive Characteristics - AND because these cannot be true
  performance_average < MIDDLE &
  performance_cumulative < MIDDLE) &
  (performance_worst < MIDDLE &
     participation_equal < MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive > MIDDLE | # Disjunctive Characteristics
  performance_best > MIDDLE)
)

# Discretionary Tasks
steiner_discretionary <- steiner_data %>% filter(
  subtasks_discretionary_weight > MIDDLE |
  subtasks_discretionary_combination > MIDDLE
)

####### Generate Steiner Categorization Summary #####
steiner_labels <- data.frame(task_names)

for (i in 1:nrow(steiner_data)) {
  task = steiner_data$task_names[i]
  steiner_labels$maximizing[i] = as.numeric(task %in% steiner_maximizing$task_names)
  steiner_labels$optimizing[i] = as.numeric(task %in% steiner_optimizing$task_names)
  steiner_labels$divisible[i] = as.numeric(task %in% steiner_divisible$task_names)
  steiner_labels$unitary[i] = as.numeric(task %in% steiner_unitary$task_names)
  steiner_labels$additive[i] = as.numeric(task %in% steiner_additive$task_names)
  steiner_labels$conjunctive[i] = as.numeric(task %in% steiner_conjunctive$task_names)
  steiner_labels$disjunctive[i] = as.numeric(task %in% steiner_disjunctive$task_names)
  steiner_labels$discretionary[i] = as.numeric(task %in% steiner_discretionary$task_names)
}

steiner_labels %>% mutate(
  num_total_labels = maximizing+optimizing+divisible+unitary+additive+conjunctive+disjunctive+discretionary
)

write.csv(steiner_labels, './analysis_experiments/steiner-labels.csv')
```

### Zigurs
```{r}
# TODO
```

### Shaw
```{r}
shaw_processed_dimensions <- shaw_data %>%
  mutate(
    dim_2 =  objective_multiplicity + skills_specialization, #Task Difficulty
    dim_4 =  solution_valid - solution_singularity, # Solution Multiplicity
    dim_5 = solution_path,
    dim_6 = solution_objectivity + solution_verifiability + solution_optimal,
    dim_8 = effort_mental/effort_physical # Ratio of mental to motor
  ) %>%
  select(c(dim_2,dim_4,dim_5,dim_6,dim_8))

# DBSCAN ---- OPTIMIZE TO IDENTIFY CLUSTERS

dbscan_paramsearch_results <- data.frame(NA, NA, NA)
names(dbscan_paramsearch_results) <- c("min.pts", "eps", "noise.pts")

for(minPts in 2:20) {

  print("starting search for min cluster size of...")
  print(minPts)
  
  START = 0
  STEP = 0.01
  
  minimum_number_of_noise_points = 10000
  value_of_eps_at_min = 10000
  eps = START
  
  repeat{
    
    print("eps is currently ...")
    print(eps)
    print(minPts)
    
    dbscan_result <- dbscan(shaw_processed_dimensions,
                            eps = eps,
                            minPts = minPts)
    
    current_num_clusters = length(table(dbscan_result[1]))
    print(current_num_clusters)
    
    # at least 2 clusters
    if(current_num_clusters<=2){
      break
    }
    
    cur_num_noise_points = table(dbscan_result[1])[1]
    
    # print the dbscan result
    print(table(dbscan_result[1]))
    
    if (cur_num_noise_points < minimum_number_of_noise_points) {
      minimum_number_of_noise_points = cur_num_noise_points
      value_of_eps_at_min = eps
    }
    eps = eps + STEP
  }
  
  # STORE RESULT
  result_row <- c(minPts,value_of_eps_at_min,minimum_number_of_noise_points)
  dbscan_paramsearch_results <-
    rbind(dbscan_paramsearch_results,result_row)
}

# DBSCAN search results
dbscan_paramsearch_results

optimized_dbscan_result <- dbscan(shaw_processed_dimensions,
                            eps = 3.88,
                            minPts = 7)

table(optimized_dbscan_result[1])

cbind(data.frame(task_names),data.frame(optimized_dbscan_result[1])) %>% write_csv("./analysis_experiments/shaw_cluster_results.csv")
```

# Laughlin
```{r}

# Pure Laughlin
laughlin_continuum <- numerical_responses_matrix %>%
  select(solution_demonstrability)

cbind(data.frame(task_names),data.frame(laughlin_continuum)) %>% write_csv("./analysis_experiments/laughlin_results.csv")
```


# Clustering Algorithm Explorations

NOTE: the dbscan R package uses the Euclidean distance by default, but this doesn't work well for high-dimensional spaces: https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions

I have to port the data over to scikitlearn...
```{r}
# DBSCAN and HDBSCAN
data <- numerical_completed_tasks %>% select(-c(task_names)) %>% as.matrix()


# playing with dbscan
res.dbscan <-
  dbscan(data,
         eps = 40, # no clusters are showing up no matter what I do - potential eps issue?
         minPts = 0)

res.dbscan$cluster

task_clusters <- as.data.frame(cbind(task_names, res.dbscan$cluster))
task_clusters_dbscan <- task_clusters[order(task_clusters$V2),]%>%
  rename(All_Columns = V2) %>%
  left_join(all_clusters, by = "task_names")

write.csv(task_clusters_dbscan,"./analysis_experiments/task_clusters_dbscan_kmeans_comparison.csv")

# playing with hdbscan
res.dbscan <-
  hdbscan(data,
         minPts = 5)

res.dbscan
```

# Visualization Explorations
```{r}
data = numerical_completed_and_agreed # can update this to whatever

data = as.matrix(data%>%select(-c(task_names)))
```

## Heatmap
```{r}
# heatmap generation
png(
  "./analysis_experiments/heatmap.png",
  width = 20,
  height = 20,
  units = 'in',
  res = 600
)
heatmap <-
  heatmap(data, Colv = NA) #Row dendrogram groups this by similarity in rows
```

## K-means clustering + PCA
```{r}
# k-means clustering + PCA Graph
# source: https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
set.seed(123)

k = 5

res.km <- kmeans(data, k, nstart = 100)
# K-means clusters showing the group of each individuals
task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
task_clusters[order(task_clusters$V2),]

# Dimension reduction using PCA
res.pca <- prcomp(data)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)

ind.coord$lbl <- c(1:nrow(data))

ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)

ggsave(
  paste("./analysis_experiments/Mapped_task_PCA_Clustered_Colored_AGREEED_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```

