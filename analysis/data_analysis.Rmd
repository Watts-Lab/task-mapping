---
title: "Task mapping data analysis"
---

```{r setup, include=FALSE}
library(irr)
library(ggplot2)
library(jsonlite)
library(graphics)
library(ggfortify)
library(factoextra)
library(stats)
library(ggpubr)
library(dbscan)
library(dplyr)
library(tidyverse)
```

# Import Data
```{r}
numerical_responses_matrix <- read_csv('../task_map_numeric.csv')
```

# PCA Map - Basic
```{r}
pca = prcomp(~., data = numerical_responses_matrix,na.action = na.exclude)
# summary(pca)
# plot(pca)
# biplot(pca,var.axes = FALSE,)

# Methods from https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html 
autoplot(pca,
         data = numerical_responses_matrix,
         shape = FALSE,
         label.size = 3) +
  labs(title = paste("PCA of mapped tasks (across",dim(numerical_responses_matrix)[[2]],"task features and",dim(numerical_responses_matrix)[[1]],"tasks)",sep = " "), x = "", y = "") + 
  ggpubr::theme_pubclean()
ggsave("./analysis_experiments/Mapped_task_PCA.png",
       width = 7,
       height = 5) 
```

```{r}
# helpful to get the task names
task_names <- agreed_responses$task
```

# Addressing Github #199 - Similar Question Sanity Check
```{r}
# github issue 199: Add similar question sanity check in analysis

# QUESTIONS THAT ARE LOGICALLY EXCLUSIONARY #
# goal_full + goal_partial == 6, because they need to be complements
# options_independent + options_dependent== 6, because these are also opposites
# outcome_certain + outcome_probablistic == 6, because these are also opposites
# individual_theoretical + individual_practical == 6, because these are also opposites
# submission_together + submission_separate == 6, because these are also opposites

numerical_completed_tasks <- cbind(task_names, numerical_responses_matrix)

# correct a typo
numerical_completed_tasks <- numerical_completed_tasks %>%
  rename(individual_theoretical = indvidual_theoretical)

# Filter for questions that are logically exclusionary
TOTAL_SCORE = 6

filter_for_agreement <- function(data_table){
  
  data_table <- data_table %>% filter(goal_full+goal_partial == TOTAL_SCORE) %>%
  filter(options_independent+options_dependent == TOTAL_SCORE) %>%
  filter(outcome_certain+outcome_probablistic == TOTAL_SCORE) %>%
  filter(individual_theoretical+individual_practical == TOTAL_SCORE) %>%
  filter(submission_together + submission_separate == TOTAL_SCORE)
  
  return(data_table)
}

# Save the ones that disagree so that we can peek at them
goal_disagreement<- numerical_completed_tasks %>%
  filter(goal_full+goal_partial != TOTAL_SCORE) %>%
  select(c(task_names, goal_full, goal_partial)) %>%
  pivot_longer(c(goal_full, goal_partial), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "goal_full",
    question2 = "goal_partial"
  ) %>%
  rename(
    answer1 = goal_full,
    answer2 = goal_partial,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

options_disagreement<- numerical_completed_tasks %>%
  filter(options_independent+options_dependent != TOTAL_SCORE)%>%
  select(c(task_names, options_independent, options_dependent)) %>%
  pivot_longer(c(options_independent, options_dependent), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "options_independent",
    question2 = "options_dependent"
  ) %>%
  rename(
    answer1 = options_independent,
    answer2 = options_dependent,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

outcome_disagreement<- numerical_completed_tasks %>%
  filter(outcome_certain+outcome_probablistic != TOTAL_SCORE) %>%
  select(c(task_names, outcome_certain, outcome_probablistic)) %>%
  pivot_longer(c(outcome_certain, outcome_probablistic), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "outcome_certain",
    question2 = "outcome_probablistic"
  ) %>%
  rename(
    answer1 = outcome_certain,
    answer2 = outcome_probablistic,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

individual_disagreement<- numerical_completed_tasks %>%
  filter(individual_theoretical+individual_practical != TOTAL_SCORE)%>%
  select(c(task_names, individual_theoretical, individual_practical)) %>%
  pivot_longer(c(individual_theoretical, individual_practical), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
   pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "individual_theoretical",
    question2 = "individual_practical"
  ) %>%
  rename(
    answer1 = individual_theoretical,
    answer2 = individual_practical,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

submission_disagreement<- numerical_completed_tasks %>%
  filter(submission_together+submission_separate != TOTAL_SCORE)%>%
  select(c(task_names, submission_together, submission_separate)) %>%
  pivot_longer(c(submission_together, submission_separate), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "submission_together",
    question2 = "submission_separate"
  ) %>%
  rename(
    answer1 = submission_together,
    answer2 = submission_separate,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))


## consolidate into single csv
inconsistent_questions <- goal_disagreement %>% rbind(options_disagreement) %>%
  rbind(outcome_disagreement) %>% rbind(individual_disagreement) %>% rbind(submission_disagreement)

write.csv(inconsistent_questions,"./analysis_experiments/task_mapping_issues.csv")
```

## Save the agreed ones
```{r}
numerical_completed_and_agreed <- filter_for_agreement(numerical_completed_tasks)
```

# Filtering by Data Source / Top down v. Bottom up Explorations
```{r warning=FALSE}
questions$source_clean = as.factor(questions$source_clean)
questions$source = as.factor(questions$source)

shaw <- "Shaw"
mcgrath <- "McGrath"
zigurs <- "Zigurs"
steiner <- "Steiner"

get_filtered_data_for_author <- function(source_name){
  filtered_questions <-
    questions %>% filter(source_clean == source_name)
  
  data_selected <- agreed_responses %>%
    select(c(filtered_questions$name, task))
  
  numerical_responses_one_framework <- data_selected %>%
    column_to_rownames(var = "task") %>%
    mutate(across(everything(),  ~ if_else(is.na(as.numeric(
      .
    )), 0, as.numeric(.)))) %>%
    select_if(colSums(.) != 0) #I don't filter for the ordinals, so just filter out the column if it's zeroed out
  
  # Add the task names back
  numerical_responses_one_framework <-
    cbind(task_names, numerical_responses_one_framework)
  
  return(numerical_responses_one_framework)
  # note - not filtered bc the columns may not exist in there
}

shaw_data <- get_filtered_data_for_author(shaw)
mcgrath_data <- get_filtered_data_for_author(mcgrath)
zigurs_data <- get_filtered_data_for_author(zigurs)
steiner_data <- get_filtered_data_for_author(steiner)
```
## Explorations with comparing how the different authors' frameworks cluster
```{r}
set.seed(123)
k = 5

get_k_clusters <- function (data) {
  data <- as.matrix(data %>% select(-c(task_names)))
  res.km <-
    kmeans(data, k, nstart = 100)
  # K-means clusters showing the group of each individuals
  task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
  return(task_clusters[order(task_clusters$V2),])
}

all_clusters <- get_k_clusters(numerical_completed_tasks) %>%
  rename(All_Columns = V2)
shaw_clusters <- get_k_clusters(shaw_data) %>%
  rename(Shaw = V2)
mcgrath_clusters <- get_k_clusters(mcgrath_data) %>%
  rename(McGrath = V2)
zigurs_clusters <- get_k_clusters(zigurs_data) %>%
  rename(Zigurs = V2)
steiner_clusters <- get_k_clusters(steiner_data) %>%
  rename(Steiner = V2)

consolidated_clusters_by_taxonomy <- all_clusters %>% left_join(shaw_clusters, by = "task_names") %>%
  left_join(mcgrath_clusters, by = "task_names") %>%
  left_join(zigurs_clusters, by = "task_names") %>%
  left_join(steiner_clusters, by = "task_names")

# Export all the clusters into a single CSV
write.csv(consolidated_clusters_by_taxonomy,"./analysis_experiments/consolidated_clusters_by_taxonomy.csv")
```


# Clustering Algorithm Explorations

NOTE: the dbscan R package uses the Euclidean distance by default, but this doesn't work well for high-dimensional spaces: https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions

I have to port the data over to scikitlearn...
```{r}
# DBSCAN and HDBSCAN
data <- numerical_completed_tasks %>% select(-c(task_names)) %>% as.matrix()


# playing with dbscan
res.dbscan <-
  dbscan(data,
         eps = 40, # no clusters are showing up no matter what I do - potential eps issue?
         minPts = 0)

res.dbscan$cluster

task_clusters <- as.data.frame(cbind(task_names, res.dbscan$cluster))
task_clusters_dbscan <- task_clusters[order(task_clusters$V2),]%>%
  rename(All_Columns = V2) %>%
  left_join(all_clusters, by = "task_names")

write.csv(task_clusters_dbscan,"./analysis_experiments/task_clusters_dbscan_kmeans_comparison.csv")

# playing with hdbscan
res.dbscan <-
  hdbscan(data,
         minPts = 5)

res.dbscan
```

# Visualization Explorations
```{r}
data = numerical_completed_and_agreed # can update this to whatever

data = as.matrix(data%>%select(-c(task_names)))
```

## Heatmap
```{r}
# heatmap generation
png(
  "./analysis_experiments/heatmap.png",
  width = 20,
  height = 20,
  units = 'in',
  res = 600
)
heatmap <-
  heatmap(data, Colv = NA) #Row dendrogram groups this by similarity in rows
```

## K-means clustering + PCA
```{r}
# k-means clustering + PCA Graph
# source: https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
set.seed(123)

k = 5

res.km <- kmeans(data, k, nstart = 100)
# K-means clusters showing the group of each individuals
task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
task_clusters[order(task_clusters$V2),]

# Dimension reduction using PCA
res.pca <- prcomp(data)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)

ind.coord$lbl <- c(1:nrow(data))

ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)

ggsave(
  paste("./analysis_experiments/Mapped_task_PCA_Clustered_Colored_AGREEED_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```

