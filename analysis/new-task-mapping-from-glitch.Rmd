---
title: "new-task-mapping"
author: "Emily Hu"
date: "5/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(NbClust)
library(cluster)
library(plotly)
library(irr)
library(anytime)
library(dplyr)
library(tidyverse)
```

```{r}
df.mapping.raw <- read_delim('http://task-robot.glitch.me/results/survey/csv')
```

Ensure we don't have any accidental resubmissions -- sometimes the server logs a "double click" as two separate maps!

Also ensure we don't have anyone submitting without a workerID

```{r}
# Fix an issue with the new Carter racing, in which I forgot to set the task blob URL 
# due to creating the HTML's before I put the new writeup on GitHub
carter_mapped_date <- 1658155951000
df.mapping.raw <- df.mapping.raw %>%
  mutate(
    task_blob_url = ifelse(task == "Carter Racing (Experimenterless Version)" & createdAt < carter_mapped_date,
                           "https://api.github.com/repos/Watts-Lab/task-mapping/git/blobs/353a2dcfffea85ce0d2bbe5a3f0e650341c95ffa", task_blob_url))

# distinct submissions
df.mapping.raw <- distinct(df.mapping.raw, user, task, .keep_all = T)

# no non-Turkers --- your userID needs to start with A
df.mapping.raw <- df.mapping.raw %>% filter(startsWith(user, "A"))

nrow(df.mapping.raw)
```
# Save the Raw Data

```{r}
df.mapping.raw %>% write_csv('../raw_map.csv')
```

# Create a CSV of workers to pay in `survey_workflows` with WorkerID, date, how many tasks they did, whether they've been paid for it

```{r}
# The same spreadsheet logs how much we previously paid; we read this in and update
df.payment.prev <- read_csv('../survey_workflows/mapper_payment.csv') %>% 
  select(WorkerId, amount_paid, last_payment_date)

# First, we keep track of everyone's cumulative payments
df.mapping.payment <- df.mapping.raw %>%
  select(
    user, updatedAt
  ) %>%
  mutate(
    pay = 3, # flat rate of $3 per task
    paid = 0
  ) %>%
  group_by(user) %>%
  summarize(
    lastUpdate = last(updatedAt),
    payment = sum(pay),
    num_tasks_completed = payment/3
  ) %>% rename(WorkerId = user)

# Then we subtract off how much they have already been paid
df.mapping.payment.new <- df.mapping.payment %>% left_join(df.payment.prev, by = "WorkerId") %>%
   mutate(
     amount_paid = ifelse(is.na(amount_paid), 0, amount_paid)
   ) %>%
  mutate(
    amount_to_pay = payment - amount_paid
  )

df.mapping.payment.new %>% write_csv('../survey_workflows/mapper_payment.csv')
```

Budget check!
```{r}
sum(df.mapping.payment.new$payment)
```


# Take a look at the Task Map Itself
```{r}
# Question names
main_questions <- c(
  "Q1concept_behav",
  "Q2intel_manip_1",
  "Q3type_1_planning",
  "Q4type_2_generate",
  "Q5creativity_input_1",
  "Q6type_5_cc",
  "Q7type_7_battle",
  "Q8type_8_performance",
  "Q9divisible_unitary",
  "Q10maximizing",
  "Q11optimizing",
  "Q13outcome_multip",
  "Q14sol_scheme_mul",
  "Q15dec_verifiability",
  "Q16shared_knowledge",
  "Q17within_sys_sol",
  "Q18ans_recog",
  "Q19time_solvability",
  "Q20type_3_type_4",
  "Q21intellective_judg_1",
  "Q22confl_tradeoffs",
  "Q23ss_out_uncert",
  "Q24eureka_question"
)

continuous_questions <- c('Q2intel_manip_1',
                          'Q21intellective_judg_1','Q5creativity_input_1') 
```

```{r}
df.main_questions_summary <- df.mapping.raw %>%
  select(c(main_questions, task, task_blob_url)) %>%
  select(-continuous_questions) %>%
  pivot_longer(cols = -c(task,task_blob_url), names_to = "question_name") %>%
  mutate(value = recode(value, 
                     "Mental" = 0,
                     "Physical" = 1,
                     "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
  filter(value != 3) %>% # remove cases in which people thought it wasn't answerable - for now
  group_by(task, task_blob_url, question_name) %>%
  summarize(mean_rating = mean(value, na.rm = T),
            n_labels = agree(t(value))$raters,
            all_values = paste(value, collapse = " & "),
            agreement = ifelse(mean_rating > 0.5, mean_rating, 1-mean_rating),
            general.alpha = (agreement-0.5)/(0.5)
            )

df.main_questions_summary %>% write_csv('../main_question_summary.csv')
```

Inter-Rater Reliability:
Select 2 raters at random and bootstrap a situation where we have only 2 -- this will mimic stage 1

```{r}
# set.seed(1)
# 
# N_ITER <- 10000
# task_agr_mean <- c()
# q_agr_mean <- c()
# 
# for(i in 1:N_ITER){
#   print(i)
#   dataframe_resampled <- df.mapping.raw %>%
#     group_by(task_blob_url) %>%
#     filter(n() >= 10) %>%
#     slice_sample(n = 2) %>%
#     select(c(main_questions, task, task_blob_url)) %>%
#     select(-continuous_questions) %>%
#     pivot_longer(cols = -c(task, task_blob_url), names_to = "question_name") %>%
#     mutate(
#       value = recode(
#         value,
#         "Mental" = 0,
#         "Physical" = 1,
#         "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
#         "No" = 0,
#         "Yes" = 1
#       )
#     ) %>%
#     group_by(task, task_blob_url, question_name) %>%
#   summarize(mean_rating = mean(value, na.rm = T),
#             n_labels = agree(t(value))$raters,
#             all_values = paste(value, collapse = " & "),
#             agreement = ifelse(mean_rating > 0.5, mean_rating, 1-mean_rating),
#             general.alpha = (agreement-0.5)/(0.5)
#             )
#   
#   task_summary <- dataframe_resampled %>%
#     group_by(task, task_blob_url) %>%
#   summarize(
#     n_labels = round(mean(n_labels),0),
#     mean_agreement = mean(agreement),
#     mean_alpha = mean(general.alpha)
#   ) %>%
#   arrange(desc(mean_alpha))
# 
#   task_agr_mean <- c(task_agr_mean, mean(task_summary$mean_agreement))
# 
#   question_summary <- dataframe_resampled %>%
#   group_by(question_name) %>%
#   summarize(
#     n_labels = round(mean(n_labels),0),
#     mean_agreement = mean(agreement),
#     mean_alpha = mean(general.alpha)
#   ) %>%
#   arrange(desc(mean_alpha))
#   
#   q_agr_mean <- c(q_agr_mean, mean(question_summary$mean_agreement))
#   
# }
# 
# quantile(task_agr_mean, c(0.025, 0.9725))
# quantile(q_agr_mean, c(0.025, 0.9725))
```

Export the task map

```{r}
# Before mapping the tasks, filter to ONLY the most recent blob
# If checking BETWEEN blobs, comment this out
tasks_blobs_and_ids <- df.mapping.raw %>%
  select(task, task_blob_url, updatedAt) %>%
  arrange(desc(updatedAt))
  
most_recent_blob_urls <- tasks_blobs_and_ids %>% distinct(task, .keep_all = T)
  
df.mapping.raw <- df.mapping.raw %>%
  filter(task_blob_url %in% most_recent_blob_urls$task_blob_url)
```

```{r}
categorical <- df.mapping.raw %>%
  select(c(main_questions, task, task_blob_url)) %>%
  select(-continuous_questions) %>%
  pivot_longer(cols = -c(task, task_blob_url), names_to = "question_name") %>%
  mutate(value = recode(value, 
                     "Mental" = 0,
                     "Physical" = 1,
                    # "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
  group_by(question_name, task, task_blob_url) %>%
  mutate(
    value = mean(value, na.rm = T)
  ) %>% unique() %>%
  pivot_wider(values_from = "value", names_from = "question_name")


numeric <- df.mapping.raw %>%
  select(c(continuous_questions, task, task_blob_url)) %>%
  pivot_longer(cols = -c(task, task_blob_url), names_to = "question_name") %>%
   group_by(question_name, task, task_blob_url) %>%
  mutate(
    value = mean(as.numeric(value), na.rm = T)
  ) %>% unique() %>%
  pivot_wider(values_from = c("value"), names_from = "question_name")
  
task_map <- inner_join(categorical, numeric, by = c("task", "task_blob_url")) %>% ungroup() %>%
  select(-task_blob_url) # remove task blob for main task map export

task_map %>% write_csv('../task_map.csv')
```

Special investigation into whether the (second) rewrite of Putting Food Into Categories helped

```{r}
# Commented this out because I've set the task map to take the most recent blob.

# new.writeup <- task_map %>%
#   filter(task_blob_url == "https://api.github.com/repos/Watts-Lab/task-mapping/git/blobs/18f592c297a321002458953433b2e96117c99ae7") %>% t()
# 
# old.writeup <- task_map %>%
#   filter(task_blob_url == "https://api.github.com/repos/Watts-Lab/task-mapping/git/blobs/871175e24910d4800931dd2e8bfbe14475b86343") %>% t()
# 
# new.writeup
# old.writeup
```


Draw the task map using PCA & clustering

```{r, fig.width=12, fig.height=5}
set.seed(1)

pca <- task_map %>% #select(-continuous_questions) %>%
  select(-task) %>%
  prcomp(center = T) # should we center and scale? makes no big difference because everything is already 0-1

# get optimal number of clusters -- "silhouette" method
fviz_nbclust(x = pca$x, FUNcluster = stats::kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")

# get optimal number of clusters -- "wss" elbow method
fviz_nbclust(x = pca$x, FUNcluster = stats::kmeans, method = "wss") +
  labs(subtitle = "Elbow method")

kmeans_output <- pca$x %>% # 2 is the optimal number
  kmeans(centers = 2, nstart = 100)

combined_data <- cbind(task_map,
      pca$x, factor(kmeans_output$cluster)) %>%
  rename(cluster = `factor(kmeans_output$cluster)`)

james_set <- c('Writing story',
 '9 Dot Problem',
 'Word construction from a subset of letters',
 'Image rating',
 'Checkers',
 'Run a mini business',
 'Typing game',
 'Whac-A-Mole',
 'Divergent Association Task',
 'Carter Racing',
 'Object based generalization for reasoning (Phyre)')

 apricot_set <- c('Search for Oil Task',
 'Advertisement writing',
 "Wason's Selection Task",
 'To evacuate or not to evacuate',
 'Space Fortress',
 'Word completion given part of word',
 'Graph coloring task',
 'Estimating social quantity',
 'Logic Problem',
 'Divergent Association Task')


p <- combined_data %>%
  ggplot(aes(
    x = PC1,
    y = PC2,
    label = task,
    fill = cluster
  )) + geom_point() + geom_label(nudge_y = 0.1, size = 2) #+ , alpha=0.05) +
# highlights only the ones in the selected set
  # geom_label(
  #   data = subset(combined_data, task %in% c("NASA Moon survival", "Desert survival")),
  #   aes(
  #     x = PC1,
  #     y = PC2,
  #     label = task ,
  #     fill = cluster
  #   ),
  #   nudge_y = 0.1,
  #   size = 2
  # )
p

plot_ly(
  x = combined_data$PC1,
  y = combined_data$PC2,
  z = combined_data$PC3,
  type = "scatter3d",
  mode = "markers", # can use mode = "text"
  text = combined_data$task ,
  color = combined_data$cluster
)

fviz_eig(pca)
ggsave(plot = p, filename = '../task-map.png')
```

Analysis of what the first three PC's mean
```{r}
# non-absolute value version
pca$rotation[,1:3] %>% data.frame() %>%
  rownames_to_column() %>%
  pivot_longer(cols = c(PC1, PC2, PC3), names_to = "PC") %>%
  ggplot(aes(y = rowname, x = PC, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c(option = "magma")

# absolute value version
pca$rotation[,1:3] %>% data.frame() %>%
  rownames_to_column() %>%
  pivot_longer(cols = c(PC1, PC2, PC3), names_to = "PC") %>%
  ggplot(aes(y = rowname, x = PC, fill = abs(value))) +
  geom_tile() +
  scale_fill_viridis_c(option = "magma")
```
PC1:
- Whether there's a "correct answer" or not

PC2:
- Whether it's maximizing & divisible or an all-or-nothing task

PC3:
- Whether you can know you're right before the game ends / whether there are many possible solutions

# Set up Data Export for Karger's Algo
Currently renamed this to `task_map_long`

```{r}
df.karger <- df.mapping.raw %>%
  select(c(main_questions, task, user)) %>%
  select(-continuous_questions) %>%
  pivot_longer(cols = -c(task,user), names_to = "question_name") %>%
  mutate(
    value = recode(
      value,
      "Mental" = 0,
      "Physical" = 1,
      #"Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
      "No" = 0,
      "Yes" = 1
    )
  ) %>% ungroup() %>%
  select(user, question_name, task, value) %>%
  rename(task_name = task,
         name = user)

df.karger %>% write_csv('task_map_long.csv')
```

# How well did the people who showed up today do on the pre-test?
```{r}
previously_tested <- read_csv('../survey_workflows/previous_tested.csv')

df.rater_distribution <- df.mapping.payment %>%
  select(WorkerId, num_tasks_completed) %>%
  left_join(previously_tested, by = c("WorkerId" = "name")) %>%
  group_by(WorkerId) %>% # get rid of people who did the old pre-test
        arrange(WorkerId, desc(score_pct)) %>% 
        slice(1) %>%
  select(WorkerId, num_tasks_completed, score_pct) %>% ungroup() %>%
  group_by(score_pct) %>%
  summarize(num_workers = sum(num_tasks_completed))
  
ggplot(df.rater_distribution, aes(x = score_pct, y = num_workers)) +
  geom_bar(stat = "identity") +
  scale_x_binned()
```

Look at qualitative feedback about questions
```{r}
df.mapping.raw %>%
select(c(contains("elaboration"),task)) %>%
pivot_longer(cols = -task, names_to = "question_name") %>%
  drop_na() %>%
  filter(nchar(value) > 2) %>%
  # drop people who said like, 'no'
  filter(value != 'no problems.' & value != 'Nope' & value != 'No trouble.') %>% 
  arrange(task) %>% write_csv("./qual-feedbacks/task_mapping_feedback-main.csv")
```

Visualize the original map (Stage 1)
```{r}
# get old task map
df.task_map_old_names <- read_csv('../archive/task_map.csv')
df.task_map_old <- cbind(df.task_map_old_names[,1],read_csv('../archive/task_map_numeric.csv'))

df.task_map_old <- df.task_map_old %>%
  filter(task %in% combined_data$task)

set.seed(1)
pca.old <- df.task_map_old %>%
  select(-task) %>%
  select(-effort_physical) %>% # no variation in this column
  prcomp(scale = T)

# get optimal number of clusters -- "silhouette" method
fviz_nbclust(x = pca.old$x, FUNcluster = stats::kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")

kmeans.old <- pca.old$x %>%
  kmeans(centers = 2, nstart = 100) 

combined_old <- cbind(df.task_map_old,
      pca.old$x, factor(kmeans.old$cluster)) %>%
  rename(
    cluster = `factor(kmeans.old$cluster)`
  )

p.old<- combined_old  %>%
  ggplot(
    aes(x = PC1,
    y = PC2,
    label = task,
    fill = cluster
    )
  ) + geom_point() + geom_label(nudge_y = 0.8, size = 2) # +
# 
#   #highlight similar tasks for sanity check
#   geom_label(
#     data = subset(combined_old, task %in% c("NASA Moon survival", "Desert survival")),
#     aes(
#       x = PC1,
#       y = PC2,
#       label = task ,
#       fill = cluster
#     ),
#     nudge_y = 0.8,
#     size = 2
#   )


p.old
ggsave(plot = p.old, filename = './map-visuals/task-map-OLD.png')
fviz_eig(pca.old)
```