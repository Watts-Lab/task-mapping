{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d23477f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from io import StringIO\n",
    "import requests\n",
    "import ast\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6b0cc",
   "metadata": {},
   "source": [
    "# Load in necessary Raw Score Data for computing Synergy (Group Advantage) from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "38c003f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python equivalent of CSV loader\n",
    "def load_CSVs(pattern, rename=True):\n",
    "\tsearch_pattern = os.path.join('../..', f'**/{pattern}.csv')\n",
    "\tfiles = [\n",
    "\t\tpath for path in glob(search_pattern, recursive=True)\n",
    "\t\tif re.search(rf'Wave [0-9] data.*/{pattern}.csv', path)\n",
    "\t]\n",
    "\t\n",
    "\tdef read_and_process(file_path):\n",
    "\t\tdf = pd.read_csv(file_path, low_memory=False)\n",
    "\t\tdf = df.astype({col: 'str' for col in df.columns if re.search(r\"(data\\.score|duplicateCellID)\", col)})\n",
    "\t\treturn df\n",
    "\n",
    "\tdata_frames = [read_and_process(file) for file in files]\n",
    "\tdata = pd.concat(data_frames).drop_duplicates()\n",
    "\n",
    "\tif rename:\n",
    "\t\tadjusted_pattern = re.sub(r's$', '', pattern)\n",
    "\t\tadjusted_pattern = re.sub(r'-(\\w)', lambda match: match.group(1).upper(), adjusted_pattern) + \"Id\"\n",
    "\t\tcolumns_to_drop = [col for col in data.columns if col.startswith(adjusted_pattern)]\n",
    "\t\tdata = data.drop(columns=columns_to_drop)\n",
    "\t\tdata = data.rename(columns=lambda x: adjusted_pattern if re.search(r\"_id$\", x) else x)\n",
    "\t\t\n",
    "\treturn data\n",
    "\n",
    "games = load_CSVs(\"games\")\n",
    "game_lobbies = load_CSVs(\"game-lobbies\")\n",
    "treatments = load_CSVs(\"treatments\")  \n",
    "factors = load_CSVs(\"factors\")\n",
    "factor_types = load_CSVs(\"factor-types\")\n",
    "lobby_configs = load_CSVs(\"lobby-configs\")\n",
    "batches = load_CSVs(\"batches\")\n",
    "rounds = load_CSVs(\"rounds\")\n",
    "stages = load_CSVs(\"stages\")\n",
    "players = load_CSVs(\"players\")\n",
    "player_logs = load_CSVs(\"player-logs\")\n",
    "player_rounds = load_CSVs(\"player-rounds\")\n",
    "player_stages = load_CSVs(\"player-stages\")\n",
    "player_inputs = load_CSVs(\"player-inputs\")\n",
    "offline_scoring = load_CSVs(\"offline scoring\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ead4a",
   "metadata": {},
   "source": [
    "Cleaning all the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "75e01a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded list of which wave a task is in\n",
    "tasks_in_waves = [\n",
    "\t{\n",
    "\t\t'wave': 1,\n",
    "\t\t'tasks': [\n",
    "\t\t\t\"Moral Reasoning\",\n",
    "\t\t\t\"Allocating Resources\",\n",
    "\t\t\t\"Writing Story\",\n",
    "\t\t\t\"Divergent Association\",\n",
    "\t\t\t\"Room Assignment\",\n",
    "\t\t\t\"Wolf Goat Cabbage\",\n",
    "\t\t\t\"Guess the Correlation\",\n",
    "\t\t\t\"Sudoku\",\n",
    "\t\t\t\"Whac a Mole\",\n",
    "\t\t\t\"Word Construction\"\n",
    "\t\t]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'wave': 2,\n",
    "\t\t'tasks': [\n",
    "\t\t\t\"Logic Problem\",\n",
    "\t\t\t\"Unscramble Words\",\n",
    "\t\t\t\"Recall Word Lists\",\n",
    "\t\t\t\"Random Dot Motion\",\n",
    "\t\t\t\"Typing\"\n",
    "\t\t]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'wave': 3,\n",
    "\t\t'tasks': [\n",
    "\t\t\t\"Putting Food Into Categories\",\n",
    "\t\t\t\"Recall Association\",\n",
    "\t\t\t\"hk_22482ca42486c72f Writing\",\n",
    "\t\t\t\"Wildcat Wells\",\n",
    "\t\t\t\"WildCam\"\n",
    "\t\t]\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Read in the task map\n",
    "task_map_url = \"https://raw.githubusercontent.com/Watts-Lab/task-mapping/master/task_map.csv\"\n",
    "task_map_csv = requests.get(task_map_url).text\n",
    "task_map = pd.read_csv(StringIO(task_map_csv))\n",
    "\n",
    "# all the renamings\n",
    "task_map['task'] = task_map['task'].replace({\n",
    "\t\"Allocating resources to programs\": \"Allocating Resources\",\n",
    "\t\"Guessing the correlation\": \"Guess the Correlation\",\n",
    "\t\"Moral Reasoning (Disciplinary Action Case)\": \"Moral Reasoning\",\n",
    "\t\"Whac-A-Mole\": \"Whac a Mole\",\n",
    "\t\"Divergent Association Task\": \"Divergent Association\",\n",
    "\t\"Room assignment task\": \"Room Assignment\",\n",
    "\t\"Wolf, goat and cabbage transfer\": \"Wolf Goat Cabbage\",\n",
    "\t\"Word construction from a subset of letters\": \"Word Construction\",\n",
    "\t\"Writing story\": \"Writing Story\",\n",
    "\t\"Unscramble words (anagrams)\": \"Unscramble Words\",\n",
    "\t\"Wildcam Gorongosa (Zooniverse)\": \"WildCam\",\n",
    "\t\"Putting food into categories\": \"Putting Food Into Categories\",\n",
    "\t\"Recall association\": \"Recall Association\",\n",
    "\t\"hk_22482ca42486c72f writing\": \"hk_22482ca42486c72f Writing\",\n",
    "\t\"Random dot motion\": \"Random Dot Motion\",\n",
    "\t\"Typing game\": \"Typing\",\n",
    "\t\"Recall word lists\": \"Recall Word Lists\"\n",
    "})\n",
    "\n",
    "# get the wave for a given task\n",
    "def get_wave(task):\n",
    "\tfor wave_info in tasks_in_waves:\n",
    "\t\tif task in wave_info['tasks']:\n",
    "\t\t\treturn wave_info['wave']\n",
    "\treturn pd.NA\n",
    "\n",
    "task_map['wave'] = task_map['task'].apply(get_wave)\n",
    "task_map\n",
    "# drop null tasks\n",
    "task_map = task_map.dropna(subset=['task'])\n",
    "\n",
    "# Get the McGrath categorical rating for all tasks\n",
    "mcgrath_mapping = pd.read_csv(\"../data/20_task_map_mcgrath_manually_updated.csv\")\n",
    "mcgrath_mapping = mcgrath_mapping.melt(\n",
    "\tid_vars='task',\n",
    "\tvalue_vars=[col for col in mcgrath_mapping.columns if col.endswith('_cat')],\n",
    "\tvar_name='mcgrath_type',\n",
    "\tvalue_name='value'\n",
    ")\n",
    "mcgrath_mapping = mcgrath_mapping[mcgrath_mapping['value'] == 1]\n",
    "mcgrath_mapping['mcgrath_type'] = mcgrath_mapping['mcgrath_type'].str.replace('_cat', '')\n",
    "mcgrath_mapping.drop(columns='value', inplace=True)\n",
    "\n",
    "factor_info = factors[[\"factorId\", \"value\", \"factorTypeId\"]].merge(\n",
    "\tfactor_types[[\"factorTypeId\", \"name\"]],\n",
    "\ton=\"factorTypeId\",\n",
    "\thow=\"inner\"\n",
    ")\n",
    "factor_info = factor_info[factor_info[\"name\"].isin({\"unitsSeed\", \"unitsIndex\", \"playerCount\"})].merge(\n",
    "\ttreatments.assign(factorId=treatments['factorIds'].str.split(',')).explode('factorId')[[\"factorId\", \"treatmentId\"]],\n",
    ").filter(items=[\"value\", \"name\", \"treatmentId\"]).drop_duplicates()\n",
    "conditions = factor_info.pivot(index=\"treatmentId\", columns=\"name\", values=\"value\").reset_index().dropna()\n",
    "\n",
    "player_conditions = players.merge(\n",
    "\tplayer_rounds[[\"playerId\", \"gameId\"]].drop_duplicates(),\n",
    "\ton=\"playerId\",\n",
    "\thow=\"left\"\n",
    ").merge(\n",
    "\tgames[[\"gameId\", \"treatmentId\"]],\n",
    "\ton=\"gameId\",\n",
    "\thow=\"inner\"\n",
    ").merge(\n",
    "\tconditions,\n",
    "\ton=\"treatmentId\",\n",
    "\thow=\"inner\"\n",
    ").drop(columns=[\"treatmentId\", \"gameId\"])\n",
    "\n",
    "complexity_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "playerCountLevels = [1, 3, 6]\n",
    "synergy_levels = [\"None\", \"Weak\", \"Strong\"]\n",
    "\n",
    "task_instances = stages[~(stages[\"displayName\"].str.contains(\"Practice\")) & ~(stages[\"displayName\"].str.contains(\"Intro\"))].dropna(subset=[\"data.constants\"])\n",
    "task_instances = (\n",
    "\ttask_instances\n",
    "\t.assign(\n",
    "\t\t# Extracting the instance name\n",
    "\t\tinitial_instance=lambda df: df['data.constants'].str.extract(r'\"name\":\"(.*?)\"', expand=False),\n",
    "\t\t\n",
    "\t\t# Mapping the name to numbers\n",
    "\t\tinstance_number=lambda df: np.select(\n",
    "\t\t\t[\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'zero', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'one', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'two', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'three', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'0', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'1', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'2', na=False),\n",
    "\t\t\t\tdf['initial_instance'].str.contains(r'3', na=False)\n",
    "\t\t\t],\n",
    "\t\t\t[0, 1, 2, 3, 0, 1, 2, 3],\n",
    "\t\t\tdefault=np.nan\n",
    "\t\t)\n",
    "\t)\n",
    "\t.assign(\n",
    "\t\t# Calculating final instance\n",
    "\t\tinstance=lambda df: np.where(\n",
    "\t\t\tdf['initial_instance'].str.contains(r'dat instance', na=False),\n",
    "\t\t\tdf['instance_number'] + 1,\n",
    "\t\t\tdf['instance_number']\n",
    "\t\t)\n",
    "\t)\n",
    ")\n",
    "# Python is zero-indexed; so we need to transform this to get the codes to work\n",
    "task_instances[\"instance\"] = task_instances[\"instance\"].astype(int)-1 \n",
    "task_instances['complexity'] = pd.Categorical.from_codes(\n",
    "\ttask_instances['instance'],\n",
    "\tcategories=complexity_levels,\n",
    "\tordered=True\n",
    ")\n",
    "\n",
    "task_instances = task_instances[['stageId', 'instance', 'data.constants', 'complexity']]\n",
    "task_instances[\"instance\"] = task_instances[\"instance\"].astype(int)+1 # reset indexing to match R\n",
    "\n",
    "merged_score_info = player_conditions[[\"playerId\", \"playerCount\", \"data.playerIds\"]].dropna().merge(\n",
    "\tplayer_stages,\n",
    "\ton=\"playerId\",\n",
    "\thow = \"left\"\n",
    ").merge(\n",
    "\tstages[[\"stageId\", \"displayName\", \"startTimeAt\", \"data.stageLength\", \"data.defaultStageLength\"]],\n",
    "\ton=\"stageId\",\n",
    "\thow=\"left\"\n",
    ").merge(\n",
    "\ttask_instances,\n",
    "\ton=\"stageId\",\n",
    "\thow=\"left\"\n",
    ").merge(\n",
    "\toffline_scoring,\n",
    "\ton=\"stageId\",\n",
    "\thow=\"left\"\n",
    ").dropna(subset = [\"complexity\"])\n",
    "\n",
    "merged_score_info = (\n",
    "\tmerged_score_info\n",
    "\t.assign(\n",
    "\t\ttask=lambda df: df['displayName'].str.replace(r\" Round.*\", \"\", regex=True),\n",
    "\t\tscore=lambda df: pd.to_numeric(np.where(df['score'].isna(), df['data.score'], df['score']), errors='coerce'),\n",
    "\t\tplayerCount=lambda df: pd.Categorical(df['playerCount'], ordered=True)\n",
    "\t)\n",
    "\t.dropna(subset=['score'])\n",
    ")\n",
    "\n",
    "merged_score_info['duration'] = merged_score_info['data.stageLength'] / 60000\n",
    "\n",
    "merged_score_info_with_wave_assigned = pd.DataFrame()\n",
    "for group_keys, group_df in merged_score_info.groupby(['task', 'complexity'], observed=True):\n",
    "  \n",
    "\tmax_score = group_df['score'].dropna().max()\n",
    "\tif np.isnan(max_score) or max_score == 0:\n",
    "\t\tgroup_df['score'] = np.where(group_df['task'] == \"Random Dot Motion\", group_df['score'], 0)\n",
    "\telse:\n",
    "\t\tgroup_df['score'] = np.where(\n",
    "\t\t\tgroup_df['task'] == \"Random Dot Motion\",\n",
    "\t\t\tgroup_df['score'],\n",
    "\t\t\tnp.clip(100 * group_df['score'] / max_score, 0, None)\n",
    "\t\t)\n",
    "\t\n",
    "\tgroup_df['efficiency'] = group_df['score'] / group_df['duration']\n",
    "\tgroup_df['wave'] = group_df['task'].apply(lambda task: get_wave(task))\n",
    "\n",
    "\tmerged_score_info_with_wave_assigned = pd.concat(\n",
    "\t\t[merged_score_info_with_wave_assigned, group_df],\n",
    "\t\tignore_index=True\n",
    "\t)\n",
    "\n",
    "# merged_score_info_with_wave_assigned should have 17,789 rows\n",
    "\n",
    "# Select and aggregate fields\n",
    "merged_score_info_with_wave_assigned = merged_score_info_with_wave_assigned[['wave', 'task', 'complexity', 'playerCount', 'stageId', 'score', 'duration', 'efficiency', 'data.playerIds']].drop_duplicates()\n",
    "merged_score_info_with_wave_assigned = merged_score_info_with_wave_assigned.dropna(subset=['efficiency', 'score'])\n",
    "\n",
    "raw_score_data = (\n",
    "\tmerged_score_info_with_wave_assigned\n",
    "\t.loc[:, ['wave', 'task', 'complexity', 'playerCount', 'stageId', 'score', 'duration', 'efficiency', 'data.playerIds']]\n",
    "\t.drop_duplicates()\n",
    "\t.dropna(subset=['efficiency', 'score']) ### THIS IS DROPPING MORE THAN I WANT\n",
    "\t.groupby(['stageId', 'task', 'complexity', 'playerCount', 'wave', 'data.playerIds'], observed=True)\n",
    "\t.agg({'score': 'max', 'duration': 'min', 'efficiency': 'max'})\n",
    "\t.reset_index()\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "raw_score_data.rename(columns={'data.playerIds': 'playerIds'}, inplace=True)\n",
    "\n",
    "# raw_score data should have 5,972 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a5b8ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_score_data[\"playerCount\"] = raw_score_data[\"playerCount\"].astype(int)\n",
    "team_raw_score_data = raw_score_data[raw_score_data[\"playerCount\"] > 1]\n",
    "individual_raw_score_data = raw_score_data[raw_score_data[\"playerCount\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d612c9",
   "metadata": {},
   "source": [
    "# Recalculating nominal teams using deduplicated sum\n",
    "\n",
    "In the main paper, we use two types of statistical aggregations for the 'nominal' teams: using the 'best' score from an individual player in a nominal team, and using the 'average' score from an individual player (aka a randomly selected player) from a nominal team.\n",
    "\n",
    "For a subset of tasks, it might be possible to add another baseline: **combining (then de-duplicating) the individual units of output**. For example, a standard practice for idea generation tasks is to take all the individually-generated ideas, de-duplicate them, and then look at how groups do in contrast to that.\n",
    "\n",
    "In our data, 4 tasks for which we can do this are:\n",
    "1. **Word Construction**\n",
    "2. **Unscramble Words**\n",
    "3. **Putting Food Into Categories**\n",
    "4. **Recall Association**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a31f8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summable_answers_raw = pd.read_csv('../outputs/summable_answers_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "708fbc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stageId</th>\n",
       "      <th>data.type</th>\n",
       "      <th>data.constants</th>\n",
       "      <th>data.answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2cbSrYP43jpgTwKfu</td>\n",
       "      <td>PuttingFoodIntoCategories</td>\n",
       "      <td>{\"name\":\"Putting Food Into Categories instance...</td>\n",
       "      <td>{\"name\":\"nBkXhWcAi5zEX5Jov\",\"word\":\"red vs. bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>xdGeoybpJ2xWknN2F</td>\n",
       "      <td>WordConstruction</td>\n",
       "      <td>{\"name\":\"Word Construction instance zero\",\"cal...</td>\n",
       "      <td>{\"name\":\"Cck3Sp73QHgk4JAeA\",\"word\":\"peak\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>kFXF6GXyikCeooX7n</td>\n",
       "      <td>WordConstruction</td>\n",
       "      <td>{\"name\":\"Word Construction instance zero\",\"cal...</td>\n",
       "      <td>{\"name\":\"XCmbKAg7L2mErEgsf\",\"word\":\"peak\"},{\"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>GPa6KAvjqqmWH38bj</td>\n",
       "      <td>RecallAssociation</td>\n",
       "      <td>{\"name\":\"recall association instance 0\",\"calcu...</td>\n",
       "      <td>{\"target\":\"fruit\",\"words\":[{\"player\":\"A1ZIIU5H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>4PYJSpeysv2X4KZzQ</td>\n",
       "      <td>WordConstruction</td>\n",
       "      <td>{\"name\":\"Word Construction instance one\",\"calc...</td>\n",
       "      <td>{\"name\":\"TS8EHZeFszZQBBFF6\",\"word\":\"arbs\"},{\"n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                stageId                  data.type  \\\n",
       "52    2cbSrYP43jpgTwKfu  PuttingFoodIntoCategories   \n",
       "606   xdGeoybpJ2xWknN2F           WordConstruction   \n",
       "490   kFXF6GXyikCeooX7n           WordConstruction   \n",
       "1436  GPa6KAvjqqmWH38bj          RecallAssociation   \n",
       "598   4PYJSpeysv2X4KZzQ           WordConstruction   \n",
       "\n",
       "                                         data.constants  \\\n",
       "52    {\"name\":\"Putting Food Into Categories instance...   \n",
       "606   {\"name\":\"Word Construction instance zero\",\"cal...   \n",
       "490   {\"name\":\"Word Construction instance zero\",\"cal...   \n",
       "1436  {\"name\":\"recall association instance 0\",\"calcu...   \n",
       "598   {\"name\":\"Word Construction instance one\",\"calc...   \n",
       "\n",
       "                                           data.answers  \n",
       "52    {\"name\":\"nBkXhWcAi5zEX5Jov\",\"word\":\"red vs. bl...  \n",
       "606          {\"name\":\"Cck3Sp73QHgk4JAeA\",\"word\":\"peak\"}  \n",
       "490   {\"name\":\"XCmbKAg7L2mErEgsf\",\"word\":\"peak\"},{\"n...  \n",
       "1436  {\"target\":\"fruit\",\"words\":[{\"player\":\"A1ZIIU5H...  \n",
       "598   {\"name\":\"TS8EHZeFszZQBBFF6\",\"word\":\"arbs\"},{\"n...  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summable_answers_raw.sample(5) # peek at raw score formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d163db0",
   "metadata": {},
   "source": [
    "### Deduplicated Sum Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "51a69e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score_dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286bcd8d",
   "metadata": {},
   "source": [
    "#### Unscramble Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d0d1cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscramble_words = df_summable_answers_raw[df_summable_answers_raw[\"data.type\"]==\"UnscrambleWords\"]\n",
    "\n",
    "# evaluate unscramble words for a dataframe of players (\"nominal team\")\n",
    "def evaluate_nominal_team_unscramble_words(df):\n",
    "    all_correct_words = set()\n",
    "    for data_answers in df['data.answers']:\n",
    "        all_correct_words.update(evaluate_unscramble_words(data_answers))\n",
    "    return all_correct_words\n",
    "\n",
    "# evaluate unscramble words for ONE player\n",
    "def evaluate_unscramble_words(data_answers):\n",
    "    answer_list = ast.literal_eval(data_answers)\n",
    "    if(type(answer_list) is dict): # in case there's only one answer, make it a list\n",
    "        answer_list = [answer_list]\n",
    "\n",
    "    correct_words = set()\n",
    "    for answer in answer_list:\n",
    "        correct_ans = answer['word'].lower().strip()\n",
    "        input_ans = answer['input'].lower().strip()\n",
    "\n",
    "        if correct_ans == input_ans: correct_words.add(correct_ans)\n",
    "    return correct_words\n",
    "\n",
    "# get the \"original scores\" for the REAL data\n",
    "unscramble_words = unscramble_words.copy()\n",
    "unscramble_words[\"score_real_raw\"] = unscramble_words[\"data.answers\"].apply(\n",
    "    lambda x: len(evaluate_unscramble_words(x))\n",
    ")\n",
    "unscramble_words_orig_data = raw_score_data[raw_score_data[\"task\"]==\"Unscramble Words\"]\n",
    "unscramble_words_orig_data = unscramble_words_orig_data.merge(\n",
    "   unscramble_words[[\"stageId\", \"score_real_raw\"]],\n",
    "   on=\"stageId\",\n",
    "   how=\"left\"\n",
    ")\n",
    "unscramble_words_compiled = unscramble_words_orig_data[[\"stageId\", \"task\", \"complexity\", \"playerCount\", \"score_real_raw\"]]\n",
    "\n",
    "original_score_dfs[\"Unscramble Words\"] = unscramble_words_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab82b5",
   "metadata": {},
   "source": [
    "#### Word Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "36f39220",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_construction = df_summable_answers_raw[df_summable_answers_raw[\"data.type\"]==\"WordConstruction\"]\n",
    "\n",
    "# evaluate word construction for a dataframe of players (\"nominal team\")\n",
    "def evaluate_nominal_team_word_construction(df):\n",
    "    all_correct_words = set()\n",
    "    for data_constants, data_answers in zip(df['data.constants'], df['data.answers']):\n",
    "        all_correct_words.update(evaluate_word_construction(data_constants, data_answers))\n",
    "    return all_correct_words\n",
    "\n",
    "# evaluate word construction for ONE player\n",
    "def evaluate_word_construction(data_constants, data_answers):\n",
    "    import json\n",
    "    \n",
    "    def extract_words_from_trie(node, prefix=\"\", words=None):\n",
    "        if words is None:\n",
    "            words = set()\n",
    "        if node.get(\"end\", False):\n",
    "            words.add(prefix)\n",
    "        for child_key, child_node in node.get(\"children\", {}).items():\n",
    "            extract_words_from_trie(child_node, prefix + child_key, words)\n",
    "        return words\n",
    "    \n",
    "    constants = json.loads(data_constants)\n",
    "    # answers might be array or raw string of JSON objects\n",
    "    answers = json.loads(f\"[{data_answers}]\") if not data_answers.strip().startswith(\"[\") else json.loads(data_answers)\n",
    "\n",
    "    # build set of valid words\n",
    "    trie = constants[\"possible_trie\"]\n",
    "    valid_words = extract_words_from_trie(trie)\n",
    "\n",
    "    # answers attempted by player\n",
    "    participant_words = {a[\"word\"].lower().strip() for a in answers}\n",
    "\n",
    "    # correct = intersection\n",
    "    correct_words = participant_words & {w.lower() for w in valid_words}\n",
    "    return correct_words\n",
    "\n",
    "\n",
    "# apply to the dataframe\n",
    "word_construction = word_construction.copy()\n",
    "word_construction[\"score_real_raw\"] = word_construction.apply(\n",
    "    lambda row: len(evaluate_word_construction(row[\"data.constants\"], row[\"data.answers\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# merge back with raw_score_data (like unscramble words)\n",
    "word_construction_orig_data = raw_score_data[raw_score_data[\"task\"]==\"Word Construction\"]\n",
    "word_construction_orig_data = word_construction_orig_data.merge(\n",
    "   word_construction[[\"stageId\", \"score_real_raw\"]],\n",
    "   on=\"stageId\",\n",
    "   how=\"left\"\n",
    ")\n",
    "\n",
    "# compile clean dataframe\n",
    "word_construction_compiled = word_construction_orig_data[[\"stageId\", \"task\", \"complexity\", \"playerCount\", \"score_real_raw\"]]\n",
    "word_construction_compiled = word_construction_compiled.copy()\n",
    "word_construction_compiled[\"score_real_raw\"] = word_construction_compiled[\"score_real_raw\"].fillna(0)\n",
    "\n",
    "# add to dict\n",
    "original_score_dfs[\"Word Construction\"] = word_construction_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259405d",
   "metadata": {},
   "source": [
    "#### Recall Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9b5a0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_association = df_summable_answers_raw[df_summable_answers_raw[\"data.type\"]==\"RecallAssociation\"]\n",
    "\n",
    "# evaluate RecallAssociation for ONE player\n",
    "def evaluate_recall_association(data_constants, data_answers):\n",
    "    constants = json.loads(data_constants)\n",
    "\n",
    "    # --- fix for answers not being a proper JSON array ---\n",
    "    answers_str = data_answers.strip()\n",
    "    if not answers_str.startswith(\"[\"):\n",
    "        answers_str = f\"[{answers_str}]\"\n",
    "    answers = json.loads(answers_str)\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    # build dictionary: target -> set(valid words)\n",
    "    valid_lookup = {lst[\"target\"].lower(): {w.lower().strip() for w in lst[\"words\"]}\n",
    "                    for lst in constants[\"lists\"]}\n",
    "\n",
    "    correct_words = set()\n",
    "    for response in answers:\n",
    "        target = response[\"target\"].lower()\n",
    "        if target not in valid_lookup:\n",
    "            continue  # ignore unknown target\n",
    "\n",
    "        valid_words = valid_lookup[target]\n",
    "        for w in response[\"words\"]:\n",
    "            word = w[\"word\"].lower().strip()\n",
    "            if word in valid_words:\n",
    "                correct_words.add(word)\n",
    "\n",
    "    return correct_words\n",
    "\n",
    "# pooled evaluation across MULTIPLE rows (nominal team)\n",
    "def evaluate_nominal_team_recall_association(df):\n",
    "    all_correct_words = set()\n",
    "    for _, row in df.iterrows():\n",
    "        all_correct_words.update(\n",
    "            evaluate_recall_association(row[\"data.constants\"], row[\"data.answers\"])\n",
    "        )\n",
    "    return all_correct_words\n",
    "\n",
    "\n",
    "recall_association = recall_association.copy()\n",
    "\n",
    "# score for each row (one player)\n",
    "recall_association[\"score_real_raw\"] = recall_association.apply(\n",
    "    lambda row: len(evaluate_recall_association(row[\"data.constants\"], row[\"data.answers\"])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# merge back with raw_score_data\n",
    "recall_association_orig_data = raw_score_data[raw_score_data[\"task\"]==\"Recall Association\"]\n",
    "recall_association_orig_data = recall_association_orig_data.merge(\n",
    "   recall_association[[\"stageId\", \"score_real_raw\"]],\n",
    "   on=\"stageId\",\n",
    "   how=\"left\"\n",
    ")\n",
    "\n",
    "# compile clean dataframe\n",
    "recall_association_compiled = recall_association_orig_data[[\"stageId\", \"task\", \"complexity\", \"playerCount\", \"score_real_raw\"]]\n",
    "\n",
    "# add to dict\n",
    "original_score_dfs[\"Recall Association\"] = recall_association_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a940a9",
   "metadata": {},
   "source": [
    "#### Putting Food Into Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0745c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD on this one; it's too complicated due to GPT API scoring..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5de593",
   "metadata": {},
   "source": [
    "### Nominal Team Generation --> Scaled Score\n",
    "\n",
    "- We need to compute a new scaled score with the nominal team score\n",
    "- Scaled score: min-max normalization * 100\n",
    "- With the 'summed' values, there are now potentially greater max scores than before\n",
    "\n",
    "So, what we'll do instead:\n",
    "- For each task in the 4 summable tasks:\n",
    "    * generate n = 100 nominal teams\n",
    "    * log the new team AND nominal team AND individual scores\n",
    "    * create a min-max normalization across {team, individual, nominal team}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ed50724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_nominal_teams(num_players, individual_data, task, complexity, MAX_ITER = 100000):\n",
    "\t# filter to the task and complexity\n",
    "\tfiltered_data = individual_data[(individual_data[\"task\"] == task) & (individual_data[\"complexity\"] == complexity)]\n",
    "\t# get all possible ways to sample num_players (rows) from filtered_data\n",
    "\tif(len(list(itertools.combinations(filtered_data.index, num_players))) > MAX_ITER):\n",
    "\t\t# sample teams randomly if there are too many team combinations\n",
    "\t\treturn random.sample(list(itertools.combinations(filtered_data.index, num_players)), MAX_ITER)\n",
    "\n",
    "\treturn list(itertools.combinations(filtered_data.index, num_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "af719c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_nominal_team(nominal_teams_list, nominal_team_eval_func, individual_raw_score_data=individual_raw_score_data, df_summable_answers_raw=df_summable_answers_raw):\n",
    "    scores = []\n",
    "    for nominal_team in nominal_teams_list:\n",
    "        selected_individuals = individual_raw_score_data.loc[list(nominal_team)]\n",
    "        raw_scores_for_selected = df_summable_answers_raw[df_summable_answers_raw[\"stageId\"].isin(selected_individuals[\"stageId\"].values)]\n",
    "        combined_score = nominal_team_eval_func(raw_scores_for_selected)\n",
    "        scores.append(len(combined_score))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c65cb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_functions = {\n",
    "    \"Unscramble Words\": evaluate_nominal_team_unscramble_words,\n",
    "    \"Word Construction\": evaluate_nominal_team_word_construction,\n",
    "    \"Recall Association\": evaluate_nominal_team_recall_association\n",
    "}\n",
    "nominal_dfs = {}\n",
    "\n",
    "for task in [\"Unscramble Words\", \"Word Construction\", \"Recall Association\"]:\n",
    "    individual_raw_score_data_task = individual_raw_score_data[individual_raw_score_data[\"task\"]==task]\n",
    "\n",
    "    nominal_teams_3_low = get_all_possible_nominal_teams(3, individual_raw_score_data_task, task, \"Low\")\n",
    "    nominal_teams_3_medium = get_all_possible_nominal_teams(3, individual_raw_score_data_task, task, \"Medium\")\n",
    "    nominal_teams_3_high = get_all_possible_nominal_teams(3, individual_raw_score_data_task, task, \"High\")\n",
    "\n",
    "    nominal_teams_6_low = get_all_possible_nominal_teams(6, individual_raw_score_data_task, task, \"Low\")\n",
    "    nominal_teams_6_medium = get_all_possible_nominal_teams(6, individual_raw_score_data_task, task, \"Medium\")\n",
    "    nominal_teams_6_high = get_all_possible_nominal_teams(6, individual_raw_score_data_task, task, \"High\")\n",
    "\n",
    "    # for each task condition, sample 100 nominal teams and evaluate their deduplicated sum scores\n",
    "    random.seed(19104)\n",
    "    NUM_NOMINAL_TEAMS = 100\n",
    "    # put together a dataframe that saves the playerCount, complexity, and deduplicated sum scores\n",
    "    nom_3_low_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 3,\n",
    "        \"complexity\": \"Low\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_3_low, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "    nom_3_medium_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 3,\n",
    "        \"complexity\": \"Medium\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_3_medium, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "    nom_3_high_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 3,\n",
    "        \"complexity\": \"High\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_3_high, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "    nom_6_low_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 6,\n",
    "        \"complexity\": \"Low\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_6_low, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "    nom_6_medium_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 6,\n",
    "        \"complexity\": \"Medium\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_6_medium, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "    nom_6_high_df = pd.DataFrame({\n",
    "        \"task\": task,\n",
    "        \"playerCount\": 6,\n",
    "        \"complexity\": \"High\",\n",
    "        \"deduplicated_sum_score\": get_scores_for_nominal_team(random.sample(nominal_teams_6_high, NUM_NOMINAL_TEAMS), evaluation_functions[task])\n",
    "    })\n",
    "\n",
    "    # append all the dataframes together\n",
    "    all_nominal_teams_df = pd.concat([\n",
    "        nom_3_low_df,\n",
    "        nom_3_medium_df,\n",
    "        nom_3_high_df,\n",
    "        nom_6_low_df,\n",
    "        nom_6_medium_df,\n",
    "        nom_6_high_df\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    nominal_dfs[task] = all_nominal_teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5f63d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize_to_100(series):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    if max_val == min_val:\n",
    "        eries.apply(lambda x: 1)\n",
    "    return ((series - min_val) / (max_val - min_val)) * 100\n",
    "\n",
    "def normalize_task_scores(nominal_df, compiled_df, complexity_col=\"complexity\"):\n",
    "    # Prepare copies with stable positional keys\n",
    "    nominal_df = nominal_df.copy()\n",
    "    compiled_df = compiled_df.copy()\n",
    "    nominal_df[\"_pos\"] = np.arange(len(nominal_df))\n",
    "    compiled_df[\"_pos\"] = np.arange(len(compiled_df))\n",
    "\n",
    "    # Stack both sets with a common value column\n",
    "    nom_part = nominal_df[[\"task\", complexity_col, \"_pos\", \"deduplicated_sum_score\"]].rename(\n",
    "        columns={\"deduplicated_sum_score\": \"value\"}\n",
    "    )\n",
    "    nom_part[\"_src\"] = \"nom\"\n",
    "\n",
    "    comp_part = compiled_df[[\"task\", complexity_col, \"_pos\", \"score_real_raw\"]].rename(\n",
    "        columns={\"score_real_raw\": \"value\"}\n",
    "    )\n",
    "    comp_part[\"_src\"] = \"comp\"\n",
    "\n",
    "    combined = pd.concat([nom_part, comp_part], ignore_index=True)\n",
    "\n",
    "    # Groupwise min–max within (task, complexity)\n",
    "    grp = combined.groupby([\"task\", complexity_col])[\"value\"]\n",
    "    gmin = grp.transform(\"min\")\n",
    "    gmax = grp.transform(\"max\")\n",
    "    denom = gmax - gmin\n",
    "\n",
    "    combined[\"normalized\"] = ((combined[\"value\"] - gmin) / denom.replace(0, 1)) * 100\n",
    "    combined.loc[denom == 0, \"normalized\"] = 1  # constant groups → 1\n",
    "\n",
    "    # Split normalized results and merge back via positional key\n",
    "    nom_norm = combined.loc[combined[\"_src\"] == \"nom\", [\"_pos\", \"normalized\"]]\n",
    "    comp_norm = combined.loc[combined[\"_src\"] == \"comp\", [\"_pos\", \"normalized\"]]\n",
    "\n",
    "    nominal_df = nominal_df.merge(nom_norm, on=\"_pos\", how=\"left\").drop(columns=\"_pos\")\n",
    "    compiled_df = compiled_df.merge(comp_norm, on=\"_pos\", how=\"left\").drop(columns=\"_pos\")\n",
    "\n",
    "    nominal_df = nominal_df.rename(columns={\"normalized\": \"deduplicated_sum_score_normalized\"})\n",
    "    compiled_df = compiled_df.rename(columns={\"normalized\": \"score_real_raw_normalized\"})\n",
    "\n",
    "    return nominal_df, compiled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b60b718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_unscrambled, regular_unscrambled = normalize_task_scores(nominal_dfs[\"Unscramble Words\"], unscramble_words_compiled)\n",
    "nominal_word_construction, regular_word_construction = normalize_task_scores(nominal_dfs[\"Word Construction\"], word_construction_compiled)\n",
    "nominal_recall_association, regular_recall_association = normalize_task_scores(nominal_dfs[\"Recall Association\"], recall_association_compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3218cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_all = (\n",
    "    pd.concat([nominal_unscrambled, nominal_word_construction, nominal_recall_association], ignore_index=True)\n",
    ")\n",
    "\n",
    "nominal_avg = (\n",
    "    nominal_all\n",
    "    .groupby([\"task\", \"complexity\", \"playerCount\"])[\"deduplicated_sum_score_normalized\"]\n",
    "    .mean()\n",
    "    .rename(\"nominal_avg_dedup_sum\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "70ec0900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>complexity</th>\n",
       "      <th>playerCount</th>\n",
       "      <th>nominal_avg_dedup_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>48.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>73.670455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>58.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>80.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>47.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall Association</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>70.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>93.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>94.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>99.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>59.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>79.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>36.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>54.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>35.254237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>52.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>49.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>68.113636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task complexity  playerCount  nominal_avg_dedup_sum\n",
       "0   Recall Association       High            3              48.920455\n",
       "1   Recall Association       High            6              73.670455\n",
       "2   Recall Association        Low            3              58.433333\n",
       "3   Recall Association        Low            6              80.900000\n",
       "4   Recall Association     Medium            3              47.830508\n",
       "5   Recall Association     Medium            6              70.644068\n",
       "6     Unscramble Words       High            3              78.000000\n",
       "7     Unscramble Words       High            6              93.125000\n",
       "8     Unscramble Words        Low            3              94.625000\n",
       "9     Unscramble Words        Low            6              99.375000\n",
       "10    Unscramble Words     Medium            3              59.875000\n",
       "11    Unscramble Words     Medium            6              79.875000\n",
       "12   Word Construction       High            3              36.807692\n",
       "13   Word Construction       High            6              54.807692\n",
       "14   Word Construction        Low            3              35.254237\n",
       "15   Word Construction        Low            6              52.864407\n",
       "16   Word Construction     Medium            3              49.022727\n",
       "17   Word Construction     Medium            6              68.113636"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "44246045",
   "metadata": {},
   "outputs": [],
   "source": [
    "### divide the score for each \"real\" team with the average score for the corresponding nominal team\n",
    "def normalize_against_nominal(regular_df, score_col=\"team_score\"):\n",
    "    # Join nominal averages onto the regular df and compute normalized score\n",
    "    out = regular_df.merge(nominal_avg, on=[\"task\", \"complexity\", \"playerCount\"], how=\"left\")\n",
    "    out[\"normalized_score\"] = out[score_col] / out[\"nominal_avg_dedup_sum\"]\n",
    "    return out\n",
    "\n",
    "team_unscrambled_normalized = normalize_against_nominal(regular_unscrambled[regular_unscrambled[\"playerCount\"]>1], score_col=\"score_real_raw_normalized\")\n",
    "team_word_construction_normalized = normalize_against_nominal(regular_word_construction[regular_word_construction[\"playerCount\"]>1], score_col=\"score_real_raw_normalized\")\n",
    "team_recall_association_normalized = normalize_against_nominal(regular_recall_association[regular_recall_association[\"playerCount\"]>1], score_col=\"score_real_raw_normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c637e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_sum_synergy_df = pd.concat([\n",
    "    team_unscrambled_normalized,\n",
    "    team_word_construction_normalized,\n",
    "    team_recall_association_normalized\n",
    "], ignore_index=True).to_csv('../outputs/deduplicated_sum_synergy_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
