---
title: "new-task-map-analysis"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(infotheo)
library(corrplot)
library(factoextra)
library(NbClust)
library(cluster)
library(plotly)
library(irr)
library(anytime)
library(dplyr)
library(ggdendro)
library(tidyverse)
```

Read in the Data
```{r}
df.mapping.raw <- read_csv('../raw_map.csv')
task_map <- read_csv('../task_map.csv')
df.main_questions_summary <- read_csv('../main_question_summary.csv')

task_based_summary <- df.main_questions_summary %>%
  filter(n_labels > 10) %>%
  group_by(task, task_blob_url) %>%
  summarize(
    mean_agreement = mean(agreement),
    mean_alpha = mean(general.alpha)
  ) %>%
  arrange(desc(mean_agreement))

task_based_summary
mean(task_based_summary$mean_agreement)
sd(task_based_summary$mean_agreement)
quantile(task_based_summary$mean_agreement, c(0.025, 0.9725))

question_based_summary <- df.main_questions_summary %>%
  filter(n_labels > 10) %>%
  group_by(question_name) %>%
  summarize(
    mean_agreement = mean(agreement),
    mean_alpha = mean(general.alpha)
  ) %>%
  arrange(desc(mean_agreement))

question_based_summary
mean(question_based_summary$mean_agreement)
sd(question_based_summary$mean_agreement)
quantile(question_based_summary$mean_agreement, c(0.025, 0.9725), na.rm = T)
```


# Correlation Matrix
```{r fig.height=10}
corrplot(abs(cor(task_map[-1])), method = "shade",
         addCoef.col = TRUE,
         tl.col = "black", type = 'lower', diag = FALSE)
```


# Descriptive Statistics
```{r}
task_map[-1] %>% as.matrix() %>% mean()
task_map[-1] %>% as.matrix() %>% median()
task_map[-1] %>% as.matrix() %>% sd()
task_map[-1] %>% as.matrix() %>% range()
```

# Confidence Judgements and Consensus

```{r}
df.confidence_scores_raw <- df.mapping.raw %>%
  select(c(task, grep('confidence', names(df.mapping.raw)))) %>%
  pivot_longer(-task, names_to = "question") %>%
  mutate(
    value = recode(
    value,
    "Very confident" = 5,
    "Confident" = 4,
    "Neutral" = 3,
    "Not confident" = 2,
    "Not at all confident" =1
  )) %>%
  mutate(question = gsub("_confidence", "", question))

# This is z-scored by individual user
df.confidence_scores_zscore <- df.mapping.raw %>%
  select(c(task, user, grep('confidence', names(df.mapping.raw)))) %>%
  pivot_longer(-c(task, user), names_to = "question") %>%
  mutate(
    value = recode(
    value,
    "Very confident" = 5,
    "Confident" = 4,
    "Neutral" = 3,
    "Not confident" = 2,
    "Not at all confident" =1
  )) %>%
  group_by(user) %>%
  mutate(
    value = scale(value)
  ) %>% mutate(question = gsub("_confidence", "", question)) %>% ungroup()
```

There is a very strong correlation between the confidence scores and the level of agreement -- about 0.77. This relationship holds regardless of whether you z-score the confidence scores (which helps to account for individual-level variation in assigning confidence).

```{r}
# Task-based confidence
zscored_confidence_by_task <- df.confidence_scores_zscore %>%
  group_by(task) %>%
  summarize(
    mean_confidence = mean(value, na.rm = T)
  )

task_based_confidence <- inner_join(task_based_summary, zscored_confidence_by_task, by = "task")

cor.test(task_based_confidence$mean_agreement, task_based_confidence$mean_confidence)

# Question-based confidence
zscored_confidence_by_question <- df.confidence_scores_zscore %>%
  group_by(question) %>%
  summarize(
    mean_confidence = mean(value, na.rm = T)
  )

question_based_confidence <- inner_join(question_based_summary, zscored_confidence_by_question, by = c("question_name"="question"))

cor.test(question_based_confidence$mean_agreement, question_based_confidence$mean_confidence)
```

A version of the above with the original ordinal variables (non-normalized)
```{r}
# Task-based confidence
confidence_by_task <- df.confidence_scores_raw %>%
  group_by(task) %>%
  summarize(
    mean_confidence = mean(value, na.rm = T)
  )

task_based_confidence <- inner_join(task_based_summary, confidence_by_task, by = "task")

cor.test(task_based_confidence$mean_agreement, task_based_confidence$mean_confidence)

# Question-based confidence
confidence_by_question <- df.confidence_scores_raw %>%
  group_by(question) %>%
  summarize(
    mean_confidence = mean(value, na.rm = T)
  )

question_based_confidence <- inner_join(question_based_summary, confidence_by_question, by = c("question_name"="question"))

cor.test(question_based_confidence$mean_agreement, question_based_confidence$mean_confidence)
```

```{r}
ggplot(task_based_confidence, 
       aes(x = mean_agreement,
           y = mean_confidence)) +
  geom_point() + 
  labs(title ="Per Task: Level of Rater Agreement v. Mean Normalized Rater Confidence")
```

Hierarchical Clustering
```{r hidden ggdendro plotting function}
set_labels_params <- function(nbLabels,
                              direction = c("tb", "bt", "lr", "rl"),
                              fan       = FALSE) {
  if (fan) {
    angle       <-  360 / nbLabels * 1:nbLabels + 90
    idx         <-  angle >= 90 & angle <= 270
    angle[idx]  <-  angle[idx] + 180
    hjust       <-  rep(0, nbLabels)
    hjust[idx]  <-  1
  } else {
    angle       <-  rep(0, nbLabels)
    hjust       <-  0
    if (direction %in% c("tb", "bt")) { angle <- angle + 45 }
    if (direction %in% c("tb", "rl")) { hjust <- 1 }
  }
  list(angle = angle, hjust = hjust, vjust = 0.5)
}
dendro_data_k <- function(hc, k) {
  
  hcdata    <-  ggdendro::dendro_data(hc, type = "rectangle")
  seg       <-  hcdata$segments
  labclust  <-  cutree(hc, k)[hc$order]
  segclust  <-  rep(0L, nrow(seg))
  heights   <-  sort(hc$height, decreasing = TRUE)
  height    <-  mean(c(heights[k], heights[k - 1L]), na.rm = TRUE)
  
  for (i in 1:k) {
    xi      <-  hcdata$labels$x[labclust == i]
    idx1    <-  seg$x    >= min(xi) & seg$x    <= max(xi)
    idx2    <-  seg$xend >= min(xi) & seg$xend <= max(xi)
    idx3    <-  seg$yend < height
    idx     <-  idx1 & idx2 & idx3
    segclust[idx] <- i
  }
  
  idx                    <-  which(segclust == 0L)
  segclust[idx]          <-  segclust[idx + 1L]
  hcdata$segments$clust  <-  segclust
  hcdata$segments$line   <-  as.integer(segclust < 1L)
  hcdata$labels$clust    <-  labclust
  
  hcdata
}
plot_ggdendro <- function(hcdata,
                          direction   = c("lr", "rl", "tb", "bt"),
                          fan         = FALSE,
                          scale.color = NULL,
                          branch.size = 1,
                          label.size  = 3,
                          nudge.label = 0.01,
                          expand.y    = 0.1) {
  
  direction <- match.arg(direction) # if fan = FALSE
  ybreaks   <- pretty(segment(hcdata)$y, n = 5)
  ymax      <- max(segment(hcdata)$y)
  
  ## branches
  p <- ggplot() +
    geom_segment(data         =  segment(hcdata),
                 aes(x        =  x,
                     y        =  y,
                     xend     =  xend,
                     yend     =  yend,
                     linetype =  factor(line),
                     colour   =  factor(clust)),
                 lineend      =  "round",
                 show.legend  =  FALSE,
                 size         =  branch.size)
  
  ## orientation
  if (fan) {
    p <- p +
      coord_polar(direction = -1) +
      scale_x_continuous(breaks = NULL,
                         limits = c(0, nrow(label(hcdata)))) +
      scale_y_reverse(breaks = ybreaks)
  } else {
    p <- p + scale_x_continuous(breaks = NULL)
    if (direction %in% c("rl", "lr")) {
      p <- p + coord_flip()
    }
    if (direction %in% c("bt", "lr")) {
      p <- p + scale_y_reverse(breaks = ybreaks)
    } else {
      p <- p + scale_y_continuous(breaks = ybreaks)
      nudge.label <- -(nudge.label)
    }
  }
  
  # labels
  labelParams <- set_labels_params(nrow(hcdata$labels), direction, fan)
  hcdata$labels$angle <- labelParams$angle
  
  p <- p +
    geom_text(data        =  label(hcdata),
              aes(x       =  x,
                  y       =  y,
                  label   =  label,
                  colour  =  factor(clust),
                  angle   =  angle),
              vjust       =  labelParams$vjust,
              hjust       =  labelParams$hjust,
              nudge_y     =  ymax * nudge.label,
              size        =  label.size,
              show.legend =  FALSE)
  
  # colors and limits
  if (!is.null(scale.color)) {
    p <- p + scale_color_manual(values = scale.color)
  }
  
  ylim <- -round(ymax * expand.y, 1)
  p    <- p + expand_limits(y = ylim)
  
  p
}
```

```{r, fig.height=12}
set.seed(1)

# Dissimilarity matrix
d <- dist(task_map %>% column_to_rownames("task"), method = "euclidean")

# Hierarchical clustering using Complete Linkage
# Ward's method
hc5 <- hclust(d, method = "ward.D2" )

# get optimal number of clusters
NbClust(data = task_map %>% column_to_rownames("task"), distance = "euclidean", min.nc = 2, max.nc = 15, method = "ward.D2")

# Plot the obtained dendrogram
colors = c( "#118AB2", "#A53860", "#073B4C", "#9071EE", "#209A92", "#3E885B", "#CC9328")
hcdata <- dendro_data_k(hc5, 2)
p <- plot_ggdendro(hcdata,
                   direction   = "lr",
                   scale.color = colors,
                   label.size  = 10,
                   branch.size = 2,
                   expand.y    = 4) + theme_void()
p
```

# Look at "old taxonomies"

```{r}
df.mcg <- task_map %>%
  select(
    task,
    Q1concept_behav,
    Q20type_3_type_4,
    Q3type_1_planning,
    Q4type_2_generate,
    Q6type_5_cc,
    Q7type_7_battle,
    Q8type_8_performance
  )
```

```{r fig.height=9, fig.width=7}
ggplot(
  df.mcg %>%
    rename(
      Physical = Q1concept_behav,
      Intellective = Q20type_3_type_4,
      Planning = Q3type_1_planning,
      Generative = Q4type_2_generate,
      `Cognitive Conflict` = Q6type_5_cc,
      Battle = Q7type_7_battle,
      Performance = Q8type_8_performance
    ) %>%
    pivot_longer(cols = -task) %>%
    rename(`Mean Rater Response` = value),
  aes(x = name, y = task)
) + geom_tile(aes(fill = `Mean Rater Response`)) + scale_fill_gradient(low = "#CC3363",
                                                       high = "#07BEB8") + theme(axis.text.x = element_text(
                                                         angle = 90,
                                                         vjust = 0.5,
                                                         hjust = 1
                                                       )) + 
  labs(x = "Dimension in McGrath's Taxonomy",
       y = "Task Name")

ggsave("26task-mcgrath-ratings.png")
```

McGrath - within v. between-category variance
```
      Physical = Q1concept_behav,
      Intellective = Q20type_3_type_4,
      Planning = Q3type_1_planning,
      Generative = Q4type_2_generate,
      `Cognitive Conflict` = Q6type_5_cc,
      Battle = Q7type_7_battle,
      Performance = Q8type_8_performance
```

# How much more information do we get when adding columns?
- Calculate mutual information for each subset (McGrath, Steiner, etc.)
- Compare to mutual information when using all columns
- We expect there to be *more mutual information* when we use all columns 

```{r set up individual dfs for each source paper}
task_map_discrete <- cbind(task_map$task, discretize(task_map[-1], nbins = 10)) %>%
                        rename(task = `task_map$task`)

df.mcg <- task_map_discrete %>%
  select(
    task,
    Q1concept_behav,
    Q20type_3_type_4,
    Q3type_1_planning,
    Q4type_2_generate,
    Q6type_5_cc,
    Q7type_7_battle,
    Q8type_8_performance
  )
df.laughlin <- task_map_discrete %>%
  select(
    task,
    Q15dec_verifiability,
    Q16shared_knowledge,
    Q17within_sys_sol,
    Q18ans_recog,
    Q19time_solvability,
    Q21intellective_judg_1,
    Q24eureka_question
    )

df.shaw <- task_map_discrete %>%
  select(
    task,
    Q2intel_manip_1,
    Q13outcome_multip,
    Q14sol_scheme_mul
    )

df.steiner <- task_map_discrete %>%
 select(
    task,
    Q9divisible_unitary,
    Q10maximizing,
    Q11optimizing
    )

df.zigurs <- task_map_discrete %>%
 select(
    task,
    Q13outcome_multip,
    Q14sol_scheme_mul,
    Q22confl_tradeoffs,
    Q23ss_out_uncert
    )
```
for documentation, see: https://cran.r-project.org/web/packages/infotheo/infotheo.pdf

Confirming discretization still looks good (qualitatively)
```{r}
pca <- task_map_discrete %>% #select(-continuous_questions) %>%
  select(-task) %>%
  prcomp(center = T)

kmeans_output <- pca$x %>% # 2 is the optimal number
  kmeans(centers = 3, nstart = 100)
combined_data <- cbind(task_map,
      pca$x, factor(kmeans_output$cluster)) %>%
  rename(cluster = `factor(kmeans_output$cluster)`)
         
plot_ly(
  x = combined_data$PC1,
  y = combined_data$PC2,
  z = combined_data$PC3,
  type = "scatter3d",
  mode = "markers", # can use mode = "text"
  text = combined_data$task ,
  color = combined_data$cluster
)
```


```{r}
#total correlation (also known as multi-information)
multiinformation(task_map_discrete[-1])
multiinformation(df.mcg[-1])
multiinformation(df.laughlin[-1])
multiinformation(df.shaw[-1])
multiinformation(df.steiner[-1])
multiinformation(df.zigurs[-1])
```

```{r}
# maybe don't run? takes forever, likely due to calculation of many conditional probabilities. also, negative and not interpretable
# interaction information
# interinformation(task_map_discrete[-1])
# interinformation(df.mcg[-1])
# interinformation(df.laughlin[-1])
# interinformation(df.shaw[-1])
# interinformation(df.steiner[-1])
# interinformation(df.zigurs[-1])
```

```{r}
# entropy?
entropy(task_map_discrete[-1])
entropy(df.mcg[-1])
entropy(df.laughlin[-1])
entropy(df.shaw[-1])
entropy(df.steiner[-1])
entropy(df.zigurs[-1])
```


Notes on how this is supposed to work:

from https://arxiv.org/pdf/1701.08868.pdf
> In the case of three random variables, interaction
information is the gain (or loss) in information transmitted between any two of the variables, due to additional knowledge of the third random variable. That is, interaction information
is the difference between the conditional and unconditional mutual information between two of the variables, where the conditioning is on the third variable. It is important to note that unlike (conditional) mutual information which is always non-negative, interaction information can be negative.




