---
title: "Task mapping data preperation"
---

```{r}
library(tidyverse)
library(irr)
library(ggplot2)
library(jsonlite)
library(graphics)
library(ggfortify)
library(factoextra)
library(stats)
library(ggpubr)
library(dbscan)
library(dplyr)
```

```{r}
# These read from our glitch server. If they are not working, double check that it is live by visiting https://task-robot.glitch.me 
# The server should wake up after the first call, so just running this block twice should get the data on a fresh launch.

# A table of all responses to the task mapping survey (notably this includes agreement instances as well as individual responses)
raw_responses <- fromJSON("https://task-robot.glitch.me/results/survey/json")

# All the tasks that are in our mapping google sheet
tasks <- fromJSON("https://task-robot.glitch.me/tasks/json")

# All the questions asked in the mapping process
questions <- fromJSON("https://task-robot.glitch.me/questions/json")
```


```{r}
ordinals <-
  questions %>% filter(answer_type == "ordinal", focus == "task") %>%
  inner_join(data.frame(name = raw_responses %>% names())) %>%
  mutate(levels = strsplit(answer_choices, " \\| ")) %>%
  select(name, levels, focus)

clean_responses <- raw_responses %>%
  select(-platform, -createdAt, -`_id`) %>%
  mutate(
    across(# this sets our variables to the right type
      ordinals$name,
      ~ ordered(., levels = (
        ordinals %>% filter(name == cur_column())
      )$levels[[1]])),
    user = trimws(gsub(
      "  ", " ",
      
      gsub(
        "( and |, |&|\\/|;)",
        " \\| ",
        gsub(
          "(Subramaniam|Bottcher|Sampath|Cullen|Balasubramanian)",
          "",
          gsub(
            "sarikasu",
            "Sarika",
            gsub(
              "(katelynbottcher|Katelynn)",
              "Katelyn",
              gsub("KaranSampath", "Karan", user)
            )
          )
        )
      )
    )),
    stage = case_when(# lets us know which tasks have agreement
      grepl("\\|", user) ~ "agreement",
      TRUE ~ "individual"),
    name_clean = trimws(gsub("  ", " ",
                             gsub(
                               ".md", "",
                               gsub(
                                 "contruction",
                                 "construction",
                                 gsub("judgement", "judgment",
                                      gsub(
                                        "and slogan",
                                        "slogan",
                                        gsub("hidden figure ", "hidden figures ",
                                        gsub(
                                          "finding the maximum",
                                          "find the maximum",
                                          gsub(
                                            "recall associations",
                                            "recall association",
                                            gsub("husband ", "husbands ",
                                                 gsub(
                                                   "nine", "9",
                                                   gsub("suduko", "sudoku",
                                                        sub(
                                                          "task", "",
                                                          gsub("various versions", "",
                                                               gsub(
                                                                 "hidden profile", "",
                                                                 gsub("[()-]", " ",
                                                                      tolower(task))
                                                               ))
                                                        ))
                                                 )))
                                          )
                                        )
                                      ))
                               )
                             ))),
    performance_all = paste(performance_all, sep = ", ")
  ) %>%
  left_join(tasks %>% mutate(name_clean = trimws(gsub(
    "  ", " ",
    sub("(anagrams)", "",
        sub(
          "task", "",
          gsub(" and its variants", "",
               gsub(
                 "and slogan", "slogan",
                 gsub("various versions", "",
                      gsub(
                        "hidden profile", "",
                        gsub("[\"()-]", " ",
                             tolower(name))
                      ))
               ))
        ))
  ))) %>% select(name, name_clean)) %>%
  mutate(task = name) %>%
  select(task, stage, user, updatedAt , everything())

unrecognised_tasks <-
  clean_responses %>% select(task, name_clean) %>% filter(is.na(task)) %>% arrange(name_clean)

if ((unrecognised_tasks %>% dim())[[1]] > 0)
  stop("Error, some task names did not match:\n\n",
       unrecognised_tasks)
```

```{r}
# Store the main tables to csv so other people can use them.
agreed_responses <- clean_responses %>%
  filter(stage == "agreement") %>% 
  select(-stage,-user,-updatedAt) %>%
  arrange(task)

agreed_responses %>% 
  write_csv("../task_map.csv")

questions %>% 
  select(name,text,focus,answer_choices,answer_type,source) %>% 
  arrange(name) %>% 
  write_csv("../questions.csv")

clean_responses %>% arrange(task,updatedAt)

# Almost complete tasks
clean_responses %>% 
  group_by(task,stage) %>% 
  summarise(mappers=paste(user, collapse = ' & ')) %>% 
  pivot_wider(names_from = stage, values_from = mappers) %>% 
  filter(is.na(agreement)) %>%
  select(-agreement) %>%
  rename(mappers_so_far = individual) %>% 
  arrange(task)
```

```{r}
# Initial analysis that might move to another file at a later point
numerical_responses_matrix <- agreed_responses %>% 
  select(task,ordinals$name) %>% 
  column_to_rownames(var = "task") %>% 
  mutate(across(everything(),~ if_else(is.na(as.numeric(.)),0,as.numeric(.))))

pca = prcomp(~., data = numerical_responses_matrix,na.action = na.exclude)
summary(pca)
plot(pca)
biplot(pca,var.axes = FALSE,)

# Methods from https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html 
autoplot(pca,
         data = numerical_responses_matrix,
         shape = FALSE,
         label.size = 3) +
  labs(title = paste("PCA of mapped tasks (across",dim(numerical_responses_matrix)[[2]],"task features and",dim(numerical_responses_matrix)[[1]],"tasks)",sep = " "), x = "", y = "") + 
  ggpubr::theme_pubclean()
ggsave("./analysis_experiments/Mapped_task_PCA.png",
       width = 7,
       height = 5) 
```

```{r}
# helpful to get the task names
task_names <- agreed_responses$task
```

# Addressing Github #199 - Similar Question Sanity Check
```{r}
# github issue 199: Add similar question sanity check in analysis

# QUESTIONS THAT ARE LOGICALLY EXCLUSIONARY #
# goal_full + goal_partial == 6, because they need to be complements
# options_independent + options_dependent== 6, because these are also opposites
# outcome_certain + outcome_probablistic == 6, because these are also opposites
# individual_theoretical + individual_practical == 6, because these are also opposites
# submission_together + submission_separate == 6, because these are also opposites

numerical_completed_tasks <- cbind(task_names, numerical_responses_matrix)

# correct a typo
numerical_completed_tasks <- numerical_completed_tasks %>%
  rename(individual_theoretical = indvidual_theoretical)

# Filter for questions that are logically exclusionary
TOTAL_SCORE = 6

filter_for_agreement <- function(data_table){
  
  data_table <- data_table %>% filter(goal_full+goal_partial == TOTAL_SCORE) %>%
  filter(options_independent+options_dependent == TOTAL_SCORE) %>%
  filter(outcome_certain+outcome_probablistic == TOTAL_SCORE) %>%
  filter(individual_theoretical+individual_practical == TOTAL_SCORE) %>%
  filter(submission_together + submission_separate == TOTAL_SCORE)
  
  return(data_table)
}

# Save the ones that disagree so that we can peek at them
goal_disagreement<- numerical_completed_tasks %>%
  filter(goal_full+goal_partial != TOTAL_SCORE) %>%
  select(c(task_names, goal_full, goal_partial)) %>%
  pivot_longer(c(goal_full, goal_partial), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "goal_full",
    question2 = "goal_partial"
  ) %>%
  rename(
    answer1 = goal_full,
    answer2 = goal_partial,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

options_disagreement<- numerical_completed_tasks %>%
  filter(options_independent+options_dependent != TOTAL_SCORE)%>%
  select(c(task_names, options_independent, options_dependent)) %>%
  pivot_longer(c(options_independent, options_dependent), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "options_independent",
    question2 = "options_dependent"
  ) %>%
  rename(
    answer1 = options_independent,
    answer2 = options_dependent,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

outcome_disagreement<- numerical_completed_tasks %>%
  filter(outcome_certain+outcome_probablistic != TOTAL_SCORE) %>%
  select(c(task_names, outcome_certain, outcome_probablistic)) %>%
  pivot_longer(c(outcome_certain, outcome_probablistic), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "outcome_certain",
    question2 = "outcome_probablistic"
  ) %>%
  rename(
    answer1 = outcome_certain,
    answer2 = outcome_probablistic,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

individual_disagreement<- numerical_completed_tasks %>%
  filter(individual_theoretical+individual_practical != TOTAL_SCORE)%>%
  select(c(task_names, individual_theoretical, individual_practical)) %>%
  pivot_longer(c(individual_theoretical, individual_practical), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
   pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "individual_theoretical",
    question2 = "individual_practical"
  ) %>%
  rename(
    answer1 = individual_theoretical,
    answer2 = individual_practical,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))

submission_disagreement<- numerical_completed_tasks %>%
  filter(submission_together+submission_separate != TOTAL_SCORE)%>%
  select(c(task_names, submission_together, submission_separate)) %>%
  pivot_longer(c(submission_together, submission_separate), names_to = "question_name") %>%
  rename(task = task_names) %>%
  left_join((clean_responses %>% filter(stage == "agreement")), by = "task") %>%
  select(c(task, user, question_name, value)) %>%
  pivot_wider(names_from = "question_name") %>%
  mutate(
    question1 = "submission_together",
    question2 = "submission_separate"
  ) %>%
  rename(
    answer1 = submission_together,
    answer2 = submission_separate,
    raters = user
  ) %>%
  select(c(task, raters, question1, answer1, question2, answer2))


## consolidate into single csv
inconsistent_questions <- goal_disagreement %>% rbind(options_disagreement) %>%
  rbind(outcome_disagreement) %>% rbind(individual_disagreement) %>% rbind(submission_disagreement)

write.csv(inconsistent_questions,"./analysis_experiments/task_mapping_issues.csv")
```

## Save the agreed ones
```{r}
numerical_completed_and_agreed <- filter_for_agreement(numerical_completed_tasks)
```

# Filtering by Data Source / Top down v. Bottom up Explorations
```{r warning=FALSE}
questions$source_clean = as.factor(questions$source_clean)
questions$source = as.factor(questions$source)

shaw <- "Shaw"
mcgrath <- "McGrath"
zigurs <- "Zigurs"
steiner <- "Steiner"

get_filtered_data_for_author <- function(source_name){
  filtered_questions <-
    questions %>% filter(source_clean == source_name)
  
  data_selected <- agreed_responses %>%
    select(c(filtered_questions$name, task))
  
  numerical_responses_one_framework <- data_selected %>%
    column_to_rownames(var = "task") %>%
    mutate(across(everything(),  ~ if_else(is.na(as.numeric(
      .
    )), 0, as.numeric(.)))) %>%
    select_if(colSums(.) != 0) #I don't filter for the ordinals, so just filter out the column if it's zeroed out
  
  # Add the task names back
  numerical_responses_one_framework <-
    cbind(task_names, numerical_responses_one_framework)
  
  return(numerical_responses_one_framework)
  # note - not filtered bc the columns may not exist in there
}

shaw_data <- get_filtered_data_for_author(shaw)
mcgrath_data <- get_filtered_data_for_author(mcgrath)
zigurs_data <- get_filtered_data_for_author(zigurs)
steiner_data <- get_filtered_data_for_author(steiner)
```

## Explorations with comparing how the different authors' frameworks cluster
```{r}
set.seed(123)
k = 5

get_k_clusters <- function (data) {
  data <- as.matrix(data %>% select(-c(task_names)))
  res.km <-
    kmeans(data, k, nstart = 100)
  # K-means clusters showing the group of each individuals
  task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
  return(task_clusters[order(task_clusters$V2),])
}

all_clusters <- get_k_clusters(numerical_completed_tasks) %>%
  rename(All_Columns = V2)
shaw_clusters <- get_k_clusters(shaw_data) %>%
  rename(Shaw = V2)
mcgrath_clusters <- get_k_clusters(mcgrath_data) %>%
  rename(McGrath = V2)
zigurs_clusters <- get_k_clusters(zigurs_data) %>%
  rename(Zigurs = V2)
steiner_clusters <- get_k_clusters(steiner_data) %>%
  rename(Steiner = V2)

consolidated_clusters_by_taxonomy <- all_clusters %>% left_join(shaw_clusters, by = "task_names") %>%
  left_join(mcgrath_clusters, by = "task_names") %>%
  left_join(zigurs_clusters, by = "task_names") %>%
  left_join(steiner_clusters, by = "task_names")

# Export all the clusters into a single CSV
write.csv(consolidated_clusters_by_taxonomy,"./analysis_experiments/consolidated_clusters_by_taxonomy.csv")
```

# Clustering Algorithm Explorations

NOTE: the dbscan R package uses the Euclidean distance by default, but this doesn't work well for high-dimensional spaces: https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions

I have to port the data over to scikitlearn...
```{r}
# DBSCAN and HDBSCAN
data <- numerical_completed_tasks %>% select(-c(task_names)) %>% as.matrix()


# playing with dbscan
res.dbscan <-
  dbscan(data,
         eps = 13.5,
         minPts = 5)

res.dbscan$cluster

task_clusters <- as.data.frame(cbind(task_names, res.dbscan$cluster))
task_clusters_dbscan <- task_clusters[order(task_clusters$V2),]%>%
  rename(All_Columns = V2) %>%
  left_join(all_clusters, by = "task_names")

write.csv(task_clusters_dbscan,"./analysis_experiments/task_clusters_dbscan_kmeans_comparison.csv")

# playing with hdbscan
res.dbscan <-
  hdbscan(data,
         minPts = 5)

res.dbscan
```

# Visualization Explorations
```{r}
data = numerical_completed_and_agreed # can update this to whatever

data = as.matrix(data%>%select(-c(task_names)))
```

## Heatmap
```{r}
# heatmap generation
png(
  "./analysis_experiments/heatmap.png",
  width = 20,
  height = 20,
  units = 'in',
  res = 600
)
heatmap <-
  heatmap(data, Colv = NA) #Row dendrogram groups this by similarity in rows
```

## K-means clustering + PCA
```{r}
# k-means clustering + PCA Graph
# source: https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
set.seed(123)

k = 5

res.km <- kmeans(data, k, nstart = 100)
# K-means clusters showing the group of each individuals
task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
task_clusters[order(task_clusters$V2),]

# Dimension reduction using PCA
res.pca <- prcomp(data)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)

ind.coord$lbl <- c(1:nrow(data))

ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)

ggsave(
  paste("./analysis_experiments/Mapped_task_PCA_Clustered_Colored_AGREEED_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```
## Plot all taxonomies on the same axes
Just replicates the same code as above, but generates a different file where you use the same PCA but cluster based on the selected columns
```{r}
all_clusters_taxonomies <- read_csv("./analysis_experiments/consolidated_clusters_by_taxonomy_renumbered.csv") %>%
  arrange(id)

# Dimension reduction using PCA
res.pca <- prcomp(as.matrix(numerical_completed_tasks %>% select(-c(task_names))))
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)


# Add clusters
ind.coord$cluster <- factor(all_clusters_taxonomies$Shaw)
ind.coord$lbl <- c(1:nrow(all_clusters_taxonomies))

# Plot
ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)

ggsave(
  paste("./analysis_experiments/SHAW_sharedaxis_Mapped_task_PCA_Clustered_Colored_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```


