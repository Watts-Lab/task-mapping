---
title: "Task mapping data preperation"
---

```{r}
library(tidyverse)
library(irr)
library(ggplot2)
library(jsonlite)
library(graphics)
library(ggfortify)
library(stats)
library(ggpubr)
library(dbscan)
library(EMCluster)
```

```{r}
# These read from our glitch server. If they are not working, double check that it is live by visiting https://task-robot.glitch.me 
# The server should wake up after the first call, so just running this block twice should get the data on a fresh launch.

# A table of all responses to the task mapping survey (notably this includes agreement instances as well as individual responses)
raw_responses <- fromJSON("https://task-robot.glitch.me/results/survey/json")

# All the tasks that are in our mapping google sheet
tasks <- fromJSON("https://task-robot.glitch.me/tasks/json")

# All the questions asked in the mapping process
questions <- fromJSON("https://task-robot.glitch.me/questions/json")
```


```{r}
ordinals <-
  questions %>% filter(answer_type == "ordinal", focus == "task") %>%
  inner_join(data.frame(name = raw_responses %>% names())) %>%
  mutate(levels = strsplit(answer_choices, " \\| ")) %>%
  select(name, levels, focus)

clean_responses <- raw_responses %>%
  select(-platform, -createdAt, -`_id`) %>%
  mutate(
    across(# this sets our variables to the right type
      ordinals$name,
      ~ ordered(., levels = (
        ordinals %>% filter(name == cur_column())
      )$levels[[1]])),
    user = trimws(gsub("  ", " ",
                       gsub(
                         "( and |, |&|\\/|;)",
                         " \\| ",
                         gsub(
                           "(Subramaniam|Bottcher|Sampath|Cullen|Balasubramanian)",
                           "",
                           gsub(
                             "sarikasu",
                             "Sarika",
                             gsub(
                               "(katelynbottcher|Katelynn)",
                               "Katelyn",
                               gsub("KaranSampath", "Karan", user)
                             )
                           )
                         )
                       ))),
    stage = case_when(# lets us know which tasks have agreement
      grepl("\\|", user) ~ "agreement",
      TRUE ~ "individual"),
    name_clean = trimws(gsub(
      "  ", " ",
      gsub(".md","",
      gsub("judgement","judgment",
      gsub("and slogan", "slogan",
      gsub(
        "finding the maximum",
        "find the maximum",
        gsub(
          "recall associations",
          "recall association",
          gsub("husband ", "husbands ",
               gsub(
                 "nine", "9",
                 gsub("suduko", "sudoku",
                      sub(
                        "task", "",
                        gsub("various versions", "",
                             gsub(
                               "hidden profile", "",
                               gsub("[()-]", " ",
                                    tolower(task))
                             ))
                      ))
               ))
        )))
      ))
    )),
    performance_all = paste(performance_all,sep = ", ")
  ) %>%
  left_join(tasks %>% mutate(name_clean = trimws(gsub(
    "  ", " ",
    sub("(anagrams)","",
    sub("task", "",
        gsub(" and its variants","",
             gsub("and slogan", "slogan",
        gsub(
          "various versions", "",
          gsub("hidden profile", "",
               gsub("[\"()-]", " ",
                    tolower(name))))
        ))))
  ))) %>% select(name, name_clean)) %>%
  mutate(task = name) %>%
  select(task, stage, user, updatedAt ,everything())

unrecognised_tasks <-
  clean_responses %>% select(task, name_clean) %>% filter(is.na(task)) %>% arrange(name_clean)
```

```{r}
# Store the main tables to csv so other people can use them.
agreed_responses <- clean_responses %>%
  filter(stage == "agreement") %>% 
  select(-stage,-user,-updatedAt) %>%
  arrange(task)

agreed_responses %>% 
  write_csv("../task_map.csv")

questions %>% 
  select(name,text,focus,answer_choices,answer_type,source) %>% 
  arrange(name) %>% 
  write_csv("../questions.csv")

clean_responses %>% arrange(task,updatedAt)

# Almost complete tasks
clean_responses %>% 
  group_by(task,stage) %>% 
  summarise(mappers=paste(user, collapse = ' & ')) %>% 
  pivot_wider(names_from = stage, values_from = mappers) %>% 
  filter(is.na(agreement)) %>%
  select(-agreement) %>%
  rename(mappers_so_far = individual) %>% 
  arrange(task)
```

```{r}
# Initial analysis that might move to another file at a later point
numerical_responses_matrix <- agreed_responses %>% 
  select(task,ordinals$name) %>% 
  column_to_rownames(var = "task") %>% 
  mutate(across(everything(),~ if_else(is.na(as.numeric(.)),0,as.numeric(.))))

pca = prcomp(~., data = numerical_responses_matrix,na.action = na.exclude)
summary(pca)
plot(pca)
biplot(pca,var.axes = FALSE,)

# Methods from https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html 
autoplot(pca,
         data = numerical_responses_matrix,
         shape = FALSE,
         label.size = 3) +
  labs(title = paste("PCA of mapped tasks (across",dim(numerical_responses_matrix)[[2]],"task features and",dim(numerical_responses_matrix)[[1]],"tasks)",sep = " "), x = "", y = "") + 
  ggpubr::theme_pubclean()
ggsave("Mapped_task_PCA.png",
       width = 7,
       height = 5) 
```

```{r}
# helpful to get the task names
task_names <- agreed_responses$task
```

# Addressing Github #199 - Similar Question Sanity Check
```{r}
# github issue 199: Add similar question sanity check in analysis

# QUESTIONS THAT ARE LOGICALLY EXCLUSIONARY #
# goal_full + goal_partial == 6, because they need to be complements
# options_independent + options_dependent== 6, because these are also opposites
# outcome_certain + outcome_probablistic == 6, because these are also opposites
# individual_theoretical + individual_practical == 6, because these are also opposites
# submission_together + submission_separate == 6, because these are also opposites

numerical_completed_tasks <- cbind(task_names, numerical_responses_matrix)

# correct a typo
numerical_completed_tasks <- numerical_completed_tasks %>%
  rename(individual_theoretical = indvidual_theoretical)

# Filter for questions that are logically exclusionary
TOTAL_SCORE = 6


filter_for_agreement <- function(data_table){
  
  data_table <- data_table %>% filter(goal_full+goal_partial == TOTAL_SCORE) %>%
  filter(options_independent+options_dependent == TOTAL_SCORE) %>%
  filter(outcome_certain+outcome_probablistic == TOTAL_SCORE) %>%
  filter(individual_theoretical+individual_practical == TOTAL_SCORE) %>%
  filter(submission_together + submission_separate == TOTAL_SCORE)
  
  return(data_table)
}

numerical_completed_and_agreed <- filter_for_agreement(numerical_completed_tasks)

# Save the ones that disagree so that we can peek at them
goal_disagreement<- numerical_completed_tasks %>%
  filter(goal_full+goal_partial != TOTAL_SCORE) %>%
  select(c(task_names, goal_full, goal_partial))

options_disagreement<- numerical_completed_tasks %>%
  filter(options_independent+options_dependent != TOTAL_SCORE)%>%
  select(c(task_names, options_independent, options_dependent))

outcome_disagreement<- numerical_completed_tasks %>%
  filter(outcome_certain+outcome_probablistic != TOTAL_SCORE)%>%
  select(c(task_names, outcome_certain, outcome_probablistic))

individual_disagreement<- numerical_completed_tasks %>%
  filter(individual_theoretical+individual_practical != TOTAL_SCORE)%>%
  select(c(task_names, individual_theoretical, individual_practical))

submission_disagreement<- numerical_completed_tasks %>%
  filter(submission_together+submission_separate != TOTAL_SCORE)%>%
  select(c(task_names, submission_together, submission_separate))
```

```{r}
numerical_completed_and_agreed
```

# Filtering by Data Source / Top down v. Bottom up Explorations
```{r warning=FALSE}
questions$source_clean = as.factor(questions$source_clean)
questions$source = as.factor(questions$source)

print(levels(questions$source_clean))

shaw <- "Shaw"
mcgrath <- "McGrath"
zigurs <- "Zigurs"
steiner <- "Steiner"

source_name <- zigurs

get_filtered_data_for_author <- function(source_name){
  filtered_questions <-
    questions %>% filter(source_clean == source_name)
  
  data_selected <- agreed_responses %>%
    select(c(filtered_questions$name, task))
  
  numerical_responses_one_framework <- data_selected %>%
    column_to_rownames(var = "task") %>%
    mutate(across(everything(),  ~ if_else(is.na(as.numeric(
      .
    )), 0, as.numeric(.)))) %>%
    select_if(colSums(.) != 0) #I don't filter for the ordinals, so just filter out the column if it's zeroed out
  
  numerical_responses_one_framework <-
    cbind(task_names, numerical_responses_one_framework)
  
  return(numerical_responses_one_framework)
  # note - not filtered bc the columns may not exist in there
}

shaw_data <- get_filtered_data_for_author(shaw)
mcgrath_data <- get_filtered_data_for_author(mcgrath)
zigurs_data <- get_filtered_data_for_author(zigurs)
steiner_data <- get_filtered_data_for_author(steiner)
```

## Explorations with comparing how the different authors' frameworks cluster
```{r}
set.seed(123)
k = 5

get_k_clusters <- function (data) {
  data <- as.matrix(data %>% select(-c(task_names)))
  res.km <-
    kmeans(data, k, nstart = 100)
  # K-means clusters showing the group of each individuals
  task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
  return(task_clusters[order(task_clusters$V2),])
}


all_clusters <- get_k_clusters(numerical_completed_tasks) %>%
  rename(All_Columns = V2)
shaw_clusters <- get_k_clusters(shaw_data) %>%
  rename(Shaw = V2)
mcgrath_clusters <- get_k_clusters(mcgrath_data) %>%
  rename(McGrath = V2)
zigurs_clusters <- get_k_clusters(zigurs_data) %>%
  rename(Zigurs = V2)
steiner_clusters <- get_k_clusters(steiner_data) %>%
  rename(Steiner = V2)

consolidated_clusters_by_taxonomy <- all_clusters %>% left_join(shaw_clusters, by = "task_names") %>%
  left_join(mcgrath_clusters, by = "task_names") %>%
  left_join(zigurs_clusters, by = "task_names") %>%
  left_join(steiner_clusters, by = "task_names")

write.csv(consolidated_clusters_by_taxonomy,"consolidated_clusters_by_taxonomy.csv")
```

# Visualization Explorations
```{r}
data = numerical_completed_and_agreed # can update this to whatever

data = as.matrix(data%>%select(-c(task_names)))
```

```{r}
# heatmap generation
png(
  "heatmap.png",
  width = 20,
  height = 20,
  units = 'in',
  res = 600
)
heatmap <-
  heatmap(data, Colv = NA) #Row dendrogram groups this by similarity in rows
```

```{r}
# k-means clustering + PCA Graph
# source: https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
set.seed(123)

k = 5

res.km <- kmeans(data, k, nstart = 100)
# K-means clusters showing the group of each individuals
task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
task_clusters[order(task_clusters$V2),]

# Dimension reduction using PCA
res.pca <- prcomp(data)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)

ind.coord$lbl <- c(1:nrow(data))

ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)
    # + ggtitle("Zigurs")
ggsave(
  paste("Mapped_task_PCA_Clustered_Colored_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```






