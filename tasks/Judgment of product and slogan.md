# Summary
Participants predicted how a larger group of Americans would rate a series of slogans and images for quality on a ten-point scale.

# References
Main Paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115212#pone.0115212.s002
Task Descriptions: https://doi.org/10.1371/journal.pone.0115212.s002


## Materials for alternative versions of the experiment 
If the task has multiple versions based on changing stimuli (e.g. the set of eyes in RME), if possible, provide a complete set, or a specification of the rules for generating that set. For example, in the RME task, provide all of the eye images, and a table of terms.  

In the case that the complete set is not possible, provide enough unique examples that the reference version of the task experiment could be completed. If there are various levels of the task, e.g., in Sudoku, include a similarly sized sample of each level.

# Procedure
## Steps
1. Each of the 68 groups was randomly assigned to one of two conditions: face-to-face or online. All participants were seated in front of personal laptop computers and worked with their group members in a shared online system to complete the tasks described below. 
> Each face-to-face group was seated in a private room around a small table and was allowed to communicate freely.
>  Members in the online groups were randomly seated in a large room with members of other groups. They did not know who else was in their group, and they only communicated with their group members via text chat in the shared online system. 
2. The first stimulus was a series of products and accompanying slogans. The group had to rate these slogans on a scale of 1 (worst) to 10 (best) based on what they believed a large sample of Americans would rate their suitability for the given products. 
> Altogether, there were 4 products with 3 slogans each, resulting in 12 total slogans for groups to rate. The ground truth was based on poll responses of 100 American users on Amazon Mechanical Turk. 
> The groups received points based on how close their ratings were to the ground truth averages. 
3. The combined time for all judgment tasks was 10 minutes.


## Instructions
Instructions written by CSS Lab 

As a group you will need to rate product slogans on a scale of 1 (worst) to 10 (best) based on what you believe a large sample of Americans would rate their suitability for the given products. 

You will earn points based on how close your ratings are to ground truth averages. 


# Criteria
## Performance calculation
The ground truth was based on poll responses of 100 American users on Amazon Mechanical Turk. The groups received points based on how close their ratings were to the ground truth averages.

## Incentives
No incentives listed 
