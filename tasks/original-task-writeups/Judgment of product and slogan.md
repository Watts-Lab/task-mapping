# Summary
Participants predicted how a larger group of Americans would rate a series of slogans and images for quality on a ten-point scale.

# References
Main Paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115212#pone.0115212.s002
Task Descriptions: https://doi.org/10.1371/journal.pone.0115212.s002

# Stimuli
CSS lab needs to develop slogans/products, none provided in original paper 

# Procedure
## Steps
1. Each of the 68 groups was randomly assigned to one of two conditions: face-to-face or online. All participants were seated in front of personal laptop computers and worked with their group members in a shared online system to complete the tasks described below. 
> Each face-to-face group was seated in a private room around a small table and was allowed to communicate freely.
>  Members in the online groups were randomly seated in a large room with members of other groups. They did not know who else was in their group, and they only communicated with their group members via text chat in the shared online system. 
2. The first stimulus was a series of products and accompanying slogans. The group had to rate these slogans on a scale of 1 (worst) to 10 (best) based on what they believed a large sample of Americans would rate their suitability for the given products. 
> Altogether, there were 4 products with 3 slogans each, resulting in 12 total slogans for groups to rate. The ground truth was based on poll responses of 100 American users on Amazon Mechanical Turk. 
> The groups received points based on how close their ratings were to the ground truth averages. 
3. The combined time for all judgment tasks was 10 minutes.


## Instructions
Instructions written by CSS Lab 

As a group you will need to rate product slogans on a scale of 1 (worst) to 10 (best) based on what you believe a large sample of Americans would rate their suitability for the given products. 

You will earn points based on how close your ratings are to ground truth averages. 


# Criteria
## Performance calculation
The ground truth was based on poll responses of 100 American users on Amazon Mechanical Turk. The groups received points based on how close their ratings were to the ground truth averages.

## Incentives
No incentives listed 
