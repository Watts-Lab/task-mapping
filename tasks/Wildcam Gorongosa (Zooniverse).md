# Summary
Participants classified pictures taken by motion-detecting camera traps in Gorongosa National Park in Mozambique as part of a wildlife conservation effort (the trail cameras are designed to automatically take a photo when an animal moves in front of them)

> For each image, participants in the experiment were tasked with (1) detecting the presence of the animal(s), (2) identifying the species type, (3) counting how many animals there are, (4) identifying the behaviors exhibited, specifically, identifying whether the animal(s) is (a) standing, (b) resting, (c) moving, (d) eating, or (e) interacting (multiple behaviors may be selected), and (5) recognizing whether any young are present. The 52 possible species options include a ‘Nothing here’ button but no ‘I don’t know’ option

# References
Main Paper: https://arxiv.org/pdf/2009.11038.pdf
> Includes supplemental questions/materials 
Task Website: https://www.zooniverse.org/projects/zooniverse/wildcam-gorongosa/classify

# Stimuli
## The visual components
![Example Animals](https://user-images.githubusercontent.com/78745728/129454241-95fbadbc-0c3f-41ec-bc97-89de498beaac.png)

# Procedure
## Steps
In each stage of the experiment, participants first read instructions and could start classifying images only after they had clicked through on each of the instruction slides. Participants were in a single room, each facing a large screen; participants working in a dyad were sat in front of a single monitor

The experiment was divided into a training and a testing stage (T1 and T2). For T1, participants were randomly assigned to two different training conditions, ‘General’ and ‘Targeted’, and asked to individually classify a sequence of approximately 50 images, where the content of the images was varied between conditions.
> T1 was designed to provide selective training to participants in the Targeted treatment condition. The set of images seen by these participants (Targeted set) thus consisted of pictures sharing specific features, sampled from a predetermined subset of all the images available to classify on Wildcam Gorongosa. Specifically, the Targeted set was restricted to pictures containing antelope species: bushbuck, duiker, impala, kudu, nyala, oribi, reedbuck, and waterbuck. These animals were chosen as they look visually similar, share a number of morphological features, and exhibit similar behaviors, thus making them relatively harder to distinguish
> For the General condition, pictures shared less specific features and were instead sampled from a much broader predetermined subset containing a more diverse set of animals other than the ones mentioned above which are easier to distinguish, including baboons, warthogs, and lions, among many others

For T2, participants were further randomly assigned to either a ‘Solo’ or ‘Dyad’ condition, with participants in the dyad condition having to jointly classify images; one of the dyad members was randomly assigned to input the decisions on behalf of the pair. When taking into account the level of training, this resulted in 2 individual testing conditions, ‘General Solo’ and ‘Targeted Solo’, and 3 dyad testing conditions, ‘General Dyad’, ‘Targeted Dyad’, and ‘Mixed Dyad’.
> T2 was designed to assess the effect of differences in task-relevant training as well as the effect of working alone versus collectively. The set of images seen by all participants, regardless of testing condition, thus consisted of pictures sampled from the Targeted set

Participants had 30 minutes to complete the T1 and 45 minutes to complete T2. During T2, participants working in a dyad did not know each other before the experiment.

At the end of testing, participants individually completed an exit survey which asked questions about their demographic background, previous experience and future intentions regarding citizen science, as well as experience of the experiment. 

## Instructions
![image](https://user-images.githubusercontent.com/78745728/129453565-6d9a8acf-2355-41db-93aa-7f5301ac9691.png)
![image](https://user-images.githubusercontent.com/78745728/129453570-9a786883-e78c-43dc-8065-1939c2bc000c.png)
![image](https://user-images.githubusercontent.com/78745728/129453581-b1d44b61-4cbc-443b-ba94-d5a539e786b4.png)
![image](https://user-images.githubusercontent.com/78745728/129453596-71295ae8-7520-4b9d-ba45-581eb38b078a.png)




# Criteria
## Performance calculation
Pace: defined as the number of images classified by i per minute (referred to as volume when considering the absolute number)
Accuracy: defined as the number of correct guesses made by i as a proportion of volume
Efficiency: defined as the number of correct guesses made by i per minute.  

## Incentives
Participants were paid £18 upon successfully completing both the training and testing stage.
