---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(DescTools)
library(factoextra)
library(httr)
library(jsonlite)
library(stats)
library(corrplot)
library(irr)
library(icr)
library(stringr)
library(markdown)
library(qualtRics)
library(ggplot2)
library(plotly)
library(dplyr)
library(tidyverse)
```

# Pull in Survey Data
```{r}
surveys <- all_surveys()

task_mapping_survey_id <- (surveys %>% filter(name == "Task Mapping Survey [NEW]"))$id
```

# Look at Survey Results for Task MAPPING

Get survey data
```{r}
df.task_map <- fetch_survey(
  surveyID = task_mapping_survey_id,
  save_dir = ".",
  force_request = TRUE
)

df.task_map
```

Get a mapping of the task name to the loop numbers
```{r}
df.task_writing_survey <- fetch_survey(
  surveyID = (surveys %>% filter(name == "Task Rewriting Submission Form [NEW]"))$id,
  save_dir = ".",
  force_request = TRUE
)

# these are the 26 tasks
all_tasks <- df.task_writing_survey$`task-name`

df.task_name_to_index <- cbind(all_tasks, rep(1:length(all_tasks))) %>%
                                as.data.frame() %>%
                                rename(
                                  task_name = all_tasks,
                                  task_num = V2
                                ) %>%
                                mutate(
                                  task_num = strtoi(task_num)
                                )
```

# Check how many people did
```{r}
df.task_map$`name` %>% table()
```

Names of the questions
```{r}
# Question names
main_questions <- c(
  "Q1concept_behav",
  "Q2intel_manip_1",
  "Q3type_1_planning",
  "Q4type_2_generate",
  "Q5creativity_input_1",
  "Q6type_5_cc",
  "Q7type_7_battle",
  "Q8type_8_performance",
  "Q9divisible_unitary",
  "Q10maximizing",
  "Q11optimizing",
  "Q13outcome_multip",
  "Q14sol_scheme_mul",
  "Q15dec_verifiability",
  "Q16shared_knowledge",
  "Q17within_sys_sol",
  "Q18sol_eureka",
  "Q19time_solvability",
  "Q20type_3_type_4",
  "Q21intellective_judg_1",
  "Q22confl_tradeoffs",
  "Q23ss_out_uncert"
)

feedback_questions <- c(
  "Q1concept_beh_feedbk",
  "Q2intel_manip_fdbk",
  "Q3type_1_feedback",
  "Q4type_2_feedbck",
  "Q5creativity_feedbck",
  "Q6type_5_feedback",
  "Q7type_7_feedback",
  "Q8type_8_feedback",
  "Q9div_unitary_feedbk",
  "Q10maximizing_feedbk",
  "Q11optimizing_feedbk",
  "Q13out_mult_feedbk",
  "Q14sol_s_mult_fdbk",
  "Q15d_verif_feedbk",
  "Q16shared_kno_feedbk",
  "Q17within_sys_feedbk",
  "Q18sol_eureka_feedbk",
  "Q19time_solv_feedbk",
  "Q20type_3_4_feedbk",
  "Q21int_jud_feedbk",
  "Q22con_trade_feedbk",
  "Q23ss_outc_u_feedbk"
)

confidence_questions <- c(
  "Q1concept_beh_conf",
  "Q2intel_manip_conf",
  "Q3type_1_conf",
  "Q4type_2_conf",
  "Q5creativity_conf",
  "Q6_type_5_conf",
  "Q7type_7_conf",
  "Q8_type_8_conf",
  "Q9div_unitary_conf",
  "Q10maximizing_conf",
  "Q11optimizing_conf",
  "Q13out_mult_conf",
  "Q14sol_s_mult_conf",
  "Q15d_verif_conf",
  "Q16shared_kno_conf",
  "Q17within_sys_conf",
  "Q18sol_eureka_conf",
  "Q19time_solv_conf",
  "Q20type_3_4_conf",
  "Q21int_jud_conf",
  "Q22con_trade_conf",
  "Q23ss_out_u_conf"
)

# For getting median time
df.task_map%>%
  mutate(
    Duration = EndDate-StartDate
  ) %>%
  summarize(
    medianDuration = median(Duration),
    sdDuration = sd(Duration)/60
  )
```

Gather all of the raw ratings
```{r}
df.task_map <- df.task_map %>% # need to only filter for complete responses
  filter(Finished == T)

df.all_ratings_raw <- df.task_map %>%
  select(c(matches('[0-9]_'))) %>%
  mutate(across(everything(), as.character)) %>%
  cbind(df.task_map %>%  # Get the identities of the raters; for now - use IPAddress, but eventually will use `name`
          # Need to cleave off the last two parts of the IPAddress bc they vary too much by person
          mutate(IPAddress = as.factor(IPAddress))%>% select(IPAddress)) %>%
          #mutate(IPAddress = as.factor(str_extract(IPAddress, "[0-9]*\\.[0-9]*\\."))) %>% select(IPAddress)) %>%
  group_by(IPAddress) %>% # Group by the rater
  pivot_longer(
    cols = -c(IPAddress),
    names_sep = 2,
    names_to = c("task_num", "question_name")
  ) %>%
  mutate(task_num = strtoi(gsub("[^0-9]", "", task_num)),
         question_name = str_extract(question_name, "Q[0-9].*")) %>% 
  drop_na() %>%
  group_by(task_num) %>%
  inner_join(df.task_name_to_index,
            by = "task_num")
```

# Get number of ratings so far
```{r}
df.all_ratings_raw %>%
  filter(question_name == "Q1concept_behav") %>%
  ungroup() %>%
  select(task_name) %>%
  table() %>% data.frame() %>% summarise(mean(Freq))
```
Each task received a mean of 3.30 ratings

```{r}
df.task_map %>% select(name) %>% unique()
```
~ approx 10 raters in the internal pool

Export the task map
```{r}
categorical <- df.all_ratings_raw %>%
  filter(question_name %in% main_questions) %>%
  filter(question_name != 'Q2intel_manip_1' & 
            question_name != 'Q21intellective_judg_1' &
            question_name != 'Q5creativity_input_1') %>%
  mutate(value = recode(value,
                     "Mental" = 0,
                     "Physical" = 1,
                     "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
  group_by(question_name, task_name) %>%
  mutate(
    value = mean(value)
    #value = Mode(value)[1]
  ) %>%
 # replace_na(list(value = 0.5)) %>% # these are cases where there is no mode
  select(-c(IPAddress, task_num)) %>% unique() %>%
  pivot_wider(values_from = c("value"), names_from = "question_name") 


numeric <- df.all_ratings_raw %>%
  filter(question_name %in% main_questions) %>% 
    filter(question_name == 'Q2intel_manip_1' | 
            question_name == 'Q21intellective_judg_1' |
            question_name == 'Q5creativity_input_1') %>%
  group_by(question_name, task_name) %>%
  mutate(
    value = mean(as.numeric(value))
  ) %>%
  select(-c(IPAddress, task_num)) %>% unique() %>%
  pivot_wider(values_from = c("value"), names_from = "question_name")
  

inner_join(categorical, numeric, by = "task_name") %>% write_csv('../task_map.csv')
```
How many people answered NA?
```{r}
df.all_ratings_raw %>%
  filter(value == "Not applicable or not answerable based on the task description (Please Elaborate Below.)") %>%
  mutate(value = 1) %>%
  pivot_wider(names_from = "question_name", values_from = value) %>%
  group_by(task_name) %>%
  summarize(
    across(matches('Q'), ~sum(., na.rm = T))
  )
```

Looking at inter-rater reliability

1. General Agreement and Alpha Per Question, Per Task
```{r}
# main summary stats
df.main_questions_summary <- df.all_ratings_raw %>%
  filter(question_name %in% main_questions) %>%
  filter(question_name != 'Q2intel_manip_1' & 
            question_name != 'Q21intellective_judg_1' &
            question_name != 'Q5creativity_input_1') %>%
  mutate(value = recode(value, 
                     "Mental" = 0,
                     "Physical" = 1,
                     "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
  filter(value != 3) %>% # remove cases in which people thought it wasn't answerable - for now
  group_by(task_name,question_name) %>%
  summarize(mean_rating = mean(value),
            n_labels = agree(t(value))$raters,
            all_values = paste(value, collapse = " & "),
            agreement = ifelse(mean_rating > 0.5, mean_rating, 1-mean_rating),
            general.alpha = (agreement-0.5)/(0.5)
            )

df.task_map_summary <- df.main_questions_summary %>%
  filter(n_labels > 1) %>%
  group_by(question_name) %>% # can do task_name, question_name
  summarize(
    n_labels = round(mean(n_labels),0),
    mean_agreement = mean(agreement),
    mean_alpha = mean(general.alpha)
  )

df.task_map_summary %>% arrange(desc(mean_alpha))
```



Try to incorporate any feedback people had about that question
```{r}
df.all_ratings_raw %>%
  filter(question_name %in% feedback_questions) %>%
  arrange(question_name) %>%
  write_csv('./question_confusion_feedback.csv')
```

Get level of agreement per task and per question
```{r}
df.per_task_q_agreement <-
  df.main_questions_summary %>% filter(n_labels > 1) %>% 
  select(task_name, question_name, agreement) %>%
  pivot_wider(names_from = question_name, values_from = agreement) %>%
  drop_na()

# sort by columnns
df.per_task_q_agreement <- df.per_task_q_agreement[,-1][,order(colSums(df.per_task_q_agreement[,-1],na.rm=T))] %>%
  cbind(df.per_task_q_agreement$task_name) %>%
  rename(
    task_name = `df.per_task_q_agreement$task_name`
  ) %>%
  relocate(task_name)

# sort by rows
df.per_task_q_agreement <- df.per_task_q_agreement %>%
  mutate(
    rowsum = rowSums(across(where(is.numeric)))
  ) %>%
  arrange(rowsum) %>%
  select(-rowsum)
  
df.per_task_q_agreement %>%
  write_csv('irr-analysis/per-task-per-q-agreement.csv')
```

2. Krippendorf's Alpha - Across the 22 questions, aggregating all questions
```{r message=FALSE, warning=FALSE}
#  kripp_alpha_per_question <- data.frame(
#   question_name = c(),
#   num_tasks = c(),
#   num_raters = c(),
#   krippendorf_alpha = c()
# )
# 
# for(i in 1:length(main_questions)){
#   q_name <- main_questions[i]
#   
#   kripp_alpha_matrix <- df.all_ratings_raw %>%
#   filter(question_name == q_name) %>%
#   group_by(task_name) %>%
#   left_join(df.task_map_summary %>% select(task_name, n_labels)) %>% # get n_labels
#   filter(n_labels > 3) %>% # remove tasks with just 2 raters
#   pivot_wider(names_from = c(IPAddress),
#               values_from = c(value),
#               values_fn = list) %>%
#   mutate(across(matches('[0-9]'), as.character)) %>%
#   mutate(across(matches('[0-9]'),
#                 function(x) case_when( # commenting out case where someone says "maybe"
#                   x == "Mental" ~ 0,
#                   x == "Physical" ~ 1,
#                   x == "No" ~ 0,
#                   x == "Yes" ~ 1,
#                   # x == "Not applicable or not answerable based on the task description (Please Elaborate Below.)" ~ 3,
#                   x == "c(\"Yes\", \"Yes\")" ~ 1,
#                   x == "c(\"No\", \"No\")" ~ 0,
#                   !is.na(as.numeric(x)) ~ as.numeric(x)
#                 ))) %>%
#     ungroup() %>%
#     select(matches('[0-9]')) %>%
#     as.matrix() %>%
#     t() %>% as.data.frame()
# 
#     # drop all rows with only 1 non-NA value  
#     kripp_alpha_matrix$not.Na <- rowSums(!is.na(kripp_alpha_matrix))
#     kripp_alpha_matrix <- kripp_alpha_matrix %>%
#                 filter(not.Na > 1) %>%
#                 select(-not.Na) %>%
#                 as.matrix()
#   
#     kripp_alpha <- NA
#     # these are numeric
#     if(q_name == 'Q2intel_manip_1' | 
#             q_name == 'Q21intellective_judg_1' |
#             q_name == 'Q5creativity_input_1'){
#       kripp_alpha <- kripp_alpha_matrix %>% krippalpha(metric = "interval")
#     }else{
#       kripp_alpha <- kripp_alpha_matrix %>% krippalpha(metric = "nominal")
#     }
# 
#     kripp_alpha_per_question <- kripp_alpha_per_question %>% rbind(
#       data.frame(
#         question_name = q_name,
#         num_tasks = kripp_alpha$n_units,
#         num_raters = kripp_alpha$n_coders,
#         krippendorf_alpha = kripp_alpha$alpha
#         #kripp_matrix = kripp_alpha_matrix
#     ))
# }

# kripp_alpha_per_question %>% arrange(desc(krippendorf_alpha)) #%>% View()
```

```{r}
#kripp_alpha_per_question %>% arrange(desc(krippendorf_alpha)) %>% write_csv("krippendorf_alpha_per_question.csv")
```

```{r}
# kripp_alpha_per_question %>% arrange(desc(mean_alpha))
```

Look at "old taxonomies"
```{r}
df.mcg <- df.main_questions_summary %>%
  filter(!is.na(str_match(question_name, "type")) | !is.na(str_match(question_name, "behav"))) %>%
  select(task_name, question_name, mean_rating) %>%
  pivot_wider(names_from = question_name, values_from = mean_rating)

total_mcgrath <- rowSums(df.mcg[c(2:7)])

df.mcg <- cbind(df.mcg, data.frame("total_mcgrath" = total_mcgrath))
```

```{r, fig.height = 6, fig.width= 6}
ggplot(
  df.mcg %>%
    rename(
      Physical = Q1concept_behav,
      Intellective = Q20type_3_type_4,
      Planning = Q3type_1_planning,
      Creativity = Q4type_2_generate,
      `Cognitive Conflict` = Q6type_5_cc,
      Battle = Q7type_7_battle,
      Performance = Q8type_8_performance
    ) %>%
    select(-total_mcgrath) %>%
    pivot_longer(cols = -task_name) %>%
    rename(`Mean Rater Response` = value),
  aes(x = name, y = task_name)
) + geom_tile(aes(fill = `Mean Rater Response`)) + scale_fill_gradient(low = "#CC3363",
                                                       high = "#07BEB8") + theme(axis.text.x = element_text(
                                                         angle = 90,
                                                         vjust = 0.5,
                                                         hjust = 1
                                                       )) + 
  labs(x = "Dimension in McGrath's Taxonomy",
       y = "Task Name")

ggsave("26task-mcgrath-ratings.png")
```


Look at raters' confidence

```{r, fig.width= 18}
p <- df.all_ratings_raw %>%
  filter(question_name %in% confidence_questions) %>%
  mutate(
    value = recode(value,
                   "Not at all confident" = "1",
                   "Not confident" = "2",
                   "Neutral" = "3",
                   "Confident" = "4",
                   "Very confident" ="5"
                   )
  ) %>%
  ggplot(
    aes(
      x = value,
      fill = task_name
    )
  ) +
  geom_bar() 

p + facet_wrap(~question_name, scales = "free")

ggsave('./map-visuals/question-confidence-analysis.png')
```


# Actually form a map!

```{r}
task.map.data <- df.main_questions_summary %>% select(task_name, question_name, mean_rating) %>%
  pivot_wider(names_from = question_name, values_from = mean_rating) %>% ungroup() #%>%
  #drop the less reliable cols
  # select(-c(
  #   Q13outcome_multip,
  #   Q10maximizing,
  #   Q23ss_out_uncert,
  #   Q11optimizing,
  #   Q9divisible_unitary
  # ))


implemented_tasks <- c(
  "Euclidean traveling salesperson",
  "Allocating resources to programs",
  "9 Dot Problem",
  "Guessing the correlation",
  "Abstract grid task",
  "Advertisement writing",
  "Whac-A-Mole",
  "Putting food into categories",
  "Room assignment task" ,
  "Divergent Association Task",
  "Recall association"
)

similar_mcg_tasks <- c(
  "Abstract grid task",
  "Letters-to-numbers problems (cryptography)",
  "9 Dot Problem"
)

set.seed(1)
pca <- task.map.data %>%
  select(-task_name) %>%
  prcomp()

kmeans <- pca$x %>%
  kmeans(centers = 4, nstart = 100) # setting this to 10

combined_data <- cbind(task.map.data,
      pca$x, factor(kmeans$cluster)) %>%
  rename(cluster = `factor(kmeans$cluster)`)

p <- combined_data %>%
  ggplot(aes(
    x = PC1,
    y = PC2,
    label = task_name ,
    fill = cluster
  )) + geom_point(alpha = 0.1) + geom_label(nudge_y = 0.1,
                                            size = 2,
                                            alpha = 0.05) +
  geom_point(
    data = subset(combined_data, task_name %in% similar_mcg_tasks),
    aes(
      x = PC1,
      y = PC2,
    )
  ) +
  geom_label(
    data = subset(combined_data, task_name %in% similar_mcg_tasks),
    aes(
      x = PC1,
      y = PC2,
      label = task_name ,
      fill = cluster
    ),
    nudge_y = 0.1,
    size = 2
  )

p

ggsave(plot = p, filename = './map-visuals/map-experiments.png')

plot_ly(
  x = combined_data$PC1,
  y = combined_data$PC2,
  z = combined_data$PC3,
  type = "scatter3d",
  mode = "markers", # can use mode = "text"
  text = combined_data$task_name #,
  #color = combined_data$cluster
)

#ggsave(plot = p, filename = './map-visuals/task-map-unreliable-dropped-10-tasks-highlighted.png')
#ggsave(plot = p, filename = './map-visuals/task-map-standard.png')
#ggsave(plot = p, filename = './map-visuals/task-map-unreliable-dropped.png')
fviz_eig(pca)

# biplot(pca, cex=0.5,
#        main="")
# abline(h=0, v=0, col="red", lwd=2)
```

# Version of map done with the filtered data (1 unreliable rater dropped)
```{r}
# set.seed(1)
# pca.filtered <- df.task_map_from_filtered %>%
#   select(-task_name) %>%
#   prcomp()
# 
# kmeans.filtered <- pca.filtered$x %>%
#   kmeans(centers = 4, nstart = 100) 
# 
# p<-cbind(df.task_map_from_filtered,
#       pca.filtered$x, factor(kmeans.filtered$cluster)) %>%
#   rename(
#     cluster = `factor(kmeans.filtered$cluster)`
#   ) %>%
#   ggplot(
#     aes(x = PC1,
#     y = PC2,
#     label = task_name,
#     fill = cluster)
#   ) + geom_point() + geom_label(nudge_y = 0.05, size = 2) 
# 
# ggsave(plot = p, filename = './map-visuals/task-map-filtered-irr.png')
# 
# combined_data <- cbind(df.task_map_from_filtered,
#       pca.filtered$x, factor(kmeans.filtered$cluster)) %>%
#   rename(cluster = `factor(kmeans.filtered$cluster)`)
# 
# plot_ly(
#   x = combined_data$PC1,
#   y = combined_data$PC2,
#   z = combined_data$PC3,
#   type = "scatter3d",
#   mode = "markers", # can use mode = "text"
#   text = combined_data$task_name,
#   color = combined_data$cluster
# )
```



# Compare to the previous task map

```{r warning=FALSE}
df.task_map_new <- df.all_ratings_raw %>% mutate(value = recode(value, 
                     "Mental" = 0,
                     "Physical" = 1,
                     "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
    filter(question_name %in% main_questions) %>%
    filter(value != 3 && !is.na(value)) %>% # remove NA's, focus only on the task map features
    pivot_wider(names_from = "question_name") %>% # Note that there are 2 repeated labels!
    group_by(task_name) %>%
    select(-c(IPAddress, task_num)) %>%
    summarize( # note that repeated labels are just being averaged in
      Q1concept_behav = mean(unlist(Q1concept_behav)),
      Q3type_1_planning = mean(unlist(Q3type_1_planning)),
      Q4type_2_generate = mean(unlist(Q4type_2_generate)),
      Q6type_5_cc = mean(unlist(Q6type_5_cc)),
      Q7type_7_battle = mean(unlist(Q7type_7_battle)),
      Q8type_8_performance = mean(unlist(Q8type_8_performance)),
      Q9divisible_unitary = mean(unlist(Q9divisible_unitary)),
      Q10maximizing = mean(unlist(Q10maximizing)),
      Q11optimizing = mean(unlist(Q11optimizing)),
      Q13outcome_multip = mean(unlist(Q13outcome_multip)),
      Q14sol_scheme_mul = mean(unlist(Q14sol_scheme_mul)),
      Q15dec_verifiability = mean(unlist(Q15dec_verifiability)),
      Q16shared_knowledge = mean(unlist(Q16shared_knowledge)),
      Q17within_sys_sol = mean(unlist(Q17within_sys_sol)),
      Q18sol_eureka = mean(unlist(Q18sol_eureka)),
      Q19time_solvability = mean(unlist(Q19time_solvability)),
      Q20type_3_type_4 = mean(unlist(Q20type_3_type_4)),
      Q22confl_tradeoffs = mean(unlist(Q22confl_tradeoffs)),
      Q23ss_out_uncert = mean(unlist(Q23ss_out_uncert))
    )
  
# get old task map
df.task_map_old_names <- read_csv('../archive/task_map.csv')
df.task_map_old <- cbind(df.task_map_old_names[,1],read_csv('../archive/task_map_numeric.csv'))
```

Let's plot the task map using the same format and see how much (qualitative) improvement there has been!
```{r}
df.task_map_old <- df.task_map_old %>%
  filter(task %in% df.task_map_new$task_name)

set.seed(1)
pca.old <- df.task_map_old %>%
  select(-task) %>%
  prcomp()

kmeans.old <- pca.old$x %>%
  kmeans(centers = 4, nstart = 100) 

p.old<-cbind(df.task_map_old,
      pca.old$x, factor(kmeans.old$cluster)) %>%
  rename(
    cluster = `factor(kmeans.old$cluster)`
  ) %>%
  ggplot(
    aes(x = PC1,
    y = PC2,
    label = task,
    fill = cluster)
  ) + geom_point() + geom_label(nudge_y = 0.8, size = 2) 

ggsave(plot = p.old, filename = './map-visuals/task-map-OLD.png')
fviz_eig(pca.old)
```


```{r}
# # get them to the same dimensions :)
# df.task_map_old <- df.task_map_old %>%
#   filter(task %in% df.task_map_new$task_name) %>% arrange(task)
# 
# df.task_map_new <- df.task_map_new %>%
#   filter(task_name %in% df.task_map_old$task) %>% arrange(task_name)
# 
# # START WITH CORRELATIONS
# 
# # Q3type_1_planning
# cor(df.task_map_new$Q3type_1_planning, df.task_map_old$generate_plan)
# cor(df.task_map_new$Q3type_1_planning, df.task_map_old$generate_process)
# 
# # Q4type_2_generate
# cor(df.task_map_new$Q4type_2_generate, df.task_map_old$generate_ideas)
# cor(df.task_map_new$Q4type_2_generate, df.task_map_old$generate_creativity)
# 
# # Q6type_5_cc
# cor(df.task_map_new$Q6type_5_cc, df.task_map_old$conflict_cooperation)
# cor(df.task_map_new$Q6type_5_cc, df.task_map_old$conflict_interests)
# 
# # Q7type_7_battle
# cor(df.task_map_new$Q7type_7_battle, df.task_map_old$external_adversary)
# 
# # Q8type_8_performance
# cor(df.task_map_new$Q8type_8_performance, df.task_map_old$external_standard)
# cor(df.task_map_new$Q8type_8_performance, df.task_map_old$goal_standard)
# 
# # Q9divisible_unitary
# cor(df.task_map_new$Q9divisible_unitary, df.task_map_old$task_divisibility)
# cor(df.task_map_new$Q9divisible_unitary, df.task_map_old$skills_specialization)
# 
# # Q10maximizing
# cor(df.task_map_new$Q10maximizing, df.task_map_old$goal_maximize)
# 
# # Q11optimizing
# cor(df.task_map_new$Q11optimizing, df.task_map_old$goal_optimize)
# 
# # Q13outcome_multip
# cor(df.task_map_new$Q13outcome_multip, df.task_map_old$solution_multiplicity)
# cor(df.task_map_new$Q13outcome_multip, df.task_map_old$solution_singularity)
# cor(df.task_map_new$Q13outcome_multip, df.task_map_old$objective_multiplicity)
# 
# #Q14sol_scheme_mul
# cor(df.task_map_new$Q14sol_scheme_mul, df.task_map_old$solution_path)
# cor(df.task_map_new$Q14sol_scheme_mul, df.task_map_old$objective_multiplicity)
# 
# #Q15dec_verifiability
# cor(df.task_map_new$Q15dec_verifiability, df.task_map_old$solution_verifiability)
# 
# #Q16shared_knowledge
# cor(df.task_map_new$Q15dec_verifiability, df.task_map_old$solution_demonstrability)
# 
# #Q17within_sys_sol
# cor(df.task_map_new$Q17within_sys_sol, df.task_map_old$solution_demonstrability)
# cor(df.task_map_new$Q17within_sys_sol, df.task_map_old$solution_valid)
# 
# #Q18sol_eureka
# cor(df.task_map_new$Q18sol_eureka, df.task_map_old$solution_demonstrability)
# 
# #Q19time_solvability
# cor(df.task_map_new$Q19time_solvability, df.task_map_old$individual_theoretical)
# cor(df.task_map_new$Q19time_solvability, df.task_map_old$individual_practical)
# 
# #Q20type_3_type_4
# cor(df.task_map_new$Q20type_3_type_4, df.task_map_old$solution_objectivity)
# cor(df.task_map_new$Q20type_3_type_4, df.task_map_old$solution_verifiability)
# 
# #Q22confl_tradeoffs
# cor(df.task_map_new$Q22confl_tradeoffs, df.task_map_old$resolve_information)
# cor(df.task_map_new$Q22confl_tradeoffs, df.task_map_old$resolve_data)
# cor(df.task_map_new$Q22confl_tradeoffs, df.task_map_old$metric_multiplicity_tradeoff)
# cor(df.task_map_new$Q22confl_tradeoffs, df.task_map_old$stakeholder_multiplicity)
# 
# #Q23ss_out_uncert
# cor(df.task_map_new$Q23ss_out_uncert, df.task_map_old$measure_easy)
# cor(df.task_map_new$Q23ss_out_uncert, df.task_map_old$measure_immediate)
# 
# # physical/mental
# cor(df.task_map_new$Q1concept_behav, df.task_map_old$effort_mental)
```

```{r}
# taskmap_new_mat <- as.matrix(df.task_map_new %>% select(-c(task_name)))
# taskmap_old_mat <- as.matrix(df.task_map_old %>% select(generate_plan, generate_ideas, conflict_interests, external_adversary, external_standard, goal_standard, task_divisibility, skills_specialization, goal_maximize, goal_optimize, solution_singularity, solution_path, solution_verifiability, solution_demonstrability, solution_objectivity, resolve_information, resolve_data, metric_multiplicity_tradeoff, stakeholder_multiplicity))
# taskmap_new_mat <- taskmap_new_mat[, qr(taskmap_new_mat)$pivot[seq_len(qr(taskmap_new_mat)$rank)]]
# taskmap_old_mat <- taskmap_old_mat[, qr(taskmap_old_mat)$pivot[seq_len(qr(taskmap_old_mat)$rank)]]
# 
# lm(taskmap_new_mat~taskmap_old_mat) %>% summary()
```


