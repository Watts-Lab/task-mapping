---
title: "test-4-task-irr"
author: "Emily Hu"
date: "4/6/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(stats)
library(corrplot)
library(irr)
library(icr)
library(stringr)
library(markdown)
library(qualtRics)
library(ggplot2)
library(dplyr)
library(tidyverse)
```

# Pull in Survey Data
```{r}
surveys <- all_surveys()

task_htmls <- read_csv('./html/task-htmls.csv')
all_tasks <- task_htmls$Task.Name

df.task_name_to_index <- cbind(all_tasks, rep(1:length(all_tasks))) %>%
                                as.data.frame() %>%
                                rename(
                                  task_name = all_tasks,
                                  task_num = V2
                                ) %>%
                                mutate(
                                  task_num = strtoi(task_num)
                                )
task_mapping_irr_survey_id <- surveys$id[2]
```
```{r}
df.task_map <- fetch_survey(
  surveyID = task_mapping_irr_survey_id,
  save_dir = ".",
  force_request = TRUE
)

# Question names
main_questions <- c(
  "Q1concept_behav",
  "Q2intel_manip_1",
  "Q3type_1_planning",
  "Q4type_2_generate",
  "Q5creativity_input_1",
  "Q6type_5_cc",
  "Q7type_7_battle",
  "Q8type_8_performance",
  "Q9divisible_unitary",
  "Q10maximizing",
  "Q11optimizing",
  "Q13outcome_multip",
  "Q14sol_scheme_mul",
  "Q15dec_verifiability",
  "Q16shared_knowledge",
  "Q17within_sys_sol",
  "Q18ans_recog",
  "Q19time_solvability",
  "Q20type_3_type_4",
  "Q21intellective_judg_1",
  "Q22confl_tradeoffs",
  "Q23ss_out_uncert",
  "Q24eureka_question"
)

feedback_questions <- c(
  "Q1concept_beh_feedbk",
  "Q2intel_manip_fdbk",
  "Q3type_1_feedback",
  "Q4type_2_feedbck",
  "Q5creativity_feedbck",
  "Q6type_5_feedback",
  "Q7type_7_feedback",
  "Q8type_8_feedback",
  "Q9div_unitary_feedbk",
  "Q10maximizing_feedbk",
  "Q11optimizing_feedbk",
  "Q13out_mult_feedbk",
  "Q14sol_s_mult_fdbk",
  "Q15d_verif_feedbk",
  "Q16shared_kno_feedbk",
  "Q17within_sys_feedbk",
  "Q18ans_recog_feedbk",
  "Q19time_solv_feedbk",
  "Q20type_3_4_feedbk",
  "Q21int_jud_feedbk",
  "Q22con_trade_feedbk",
  "Q23ss_outc_u_feedbk",
  "Q24eureka_q_fdbk"
)

confidence_questions <- c(
  "Q1concept_beh_conf",
  "Q2intel_manip_conf",
  "Q3type_1_conf",
  "Q4type_2_conf",
  "Q5creativity_conf",
  "Q6_type_5_conf",
  "Q7type_7_conf",
  "Q8_type_8_conf",
  "Q9div_unitary_conf",
  "Q10maximizing_conf",
  "Q11optimizing_conf",
  "Q13out_mult_conf",
  "Q14sol_s_mult_conf",
  "Q15d_verif_conf",
  "Q16shared_kno_conf",
  "Q17within_sys_conf",
  "Q18ans_recog_conf",
  "Q19time_solv_conf",
  "Q20type_3_4_conf",
  "Q21int_jud_conf",
  "Q22con_trade_conf",
  "Q23ss_out_u_conf",
  "Q24eureka_q_conf"
)

df.task_map <- df.task_map %>% # need to only filter for complete responses
  filter(Finished == T)

df.all_ratings_raw <- df.task_map %>%
  select(c(matches('[0-9]_'))) %>%
  mutate(across(everything(), as.character)) %>%
  cbind(df.task_map %>% 
          mutate(name = as.factor(name))%>% select(name)) %>%
  group_by(name) %>% # Group by the rater
  pivot_longer(
    cols = -c(name),
    names_sep = 2,
    names_to = c("task_num", "question_name")
  ) %>%
  mutate(task_num = strtoi(gsub("[^0-9]", "", task_num)),
         question_name = str_extract(question_name, "Q[0-9].*")) %>% 
  drop_na() %>%
  group_by(task_num) %>%
  inner_join(df.task_name_to_index,
            by = "task_num")

get_expected_agreement <- function(r){
  expected_prob <- round(0.5*r)/r
  return(ifelse(expected_prob > 0.5, expected_prob, 1-expected_prob))
}

# main summary stats
df.main_questions_summary <- df.all_ratings_raw %>%
  filter(question_name %in% main_questions) %>%
  filter(question_name != 'Q2intel_manip_1' & 
            question_name != 'Q21intellective_judg_1' &
            question_name != 'Q5creativity_input_1') %>%
  mutate(value = recode(value, 
                     "Mental" = 0,
                     "Physical" = 1,
                     "Not applicable or not answerable based on the task description (Please Elaborate Below.)" = 3,
                     "No" = 0,
                     "Yes" = 1
                   )) %>%
  filter(value != 3) %>% # remove cases in which people thought it wasn't answerable - for now
  group_by(task_name,question_name) %>%
  summarize(mean_rating = mean(value),
            n_labels = agree(t(value))$raters,
            all_values = paste(value, collapse = " & "),
            # TODO - this is a manual way of calculating percent agreement
            agreement = ifelse(mean_rating > 0.5, mean_rating, 1-mean_rating),
            # TODO - this is a manual way of calculating Kripp's Alpha
            exp.prob = get_expected_agreement(n_labels),
            general.alpha = 1-((1-agreement)/(1-get_expected_agreement(n_labels)))
            )

df.task_map_summary <- df.main_questions_summary %>%
  filter(n_labels > 1) %>%
  group_by(task_name) %>% # can do task_name, question_name
  summarize(
    n_labels = round(mean(n_labels),0),
    mean_agreement = mean(agreement),
    mean_alpha = mean(general.alpha)
  )

df.task_map_summary %>% arrange(desc(mean_alpha))
```

TODO > How do we handle the case where the same person labels repeatedly? I (Emily) am in the data twice, and currently it's actually throwing out both of my labels ...

```{r message=FALSE, warning=FALSE}
kripp_alpha_per_question <- data.frame(
  question_name = c(),
  num_tasks = c(),
  num_raters = c(),
  krippendorf_alpha = c()
)

for(i in 1:length(main_questions)){
  q_name <- main_questions[i]
  
  kripp_alpha_matrix <- df.all_ratings_raw %>%
  filter(question_name == q_name) %>%
  group_by(task_name) %>%
  left_join(df.task_map_summary %>% select(task_name, n_labels)) %>% # get n_labels
  pivot_wider(names_from = c(name),
              values_from = c(value),
              values_fn = list) %>%
    ungroup() %>%
    select(-c(task_num, question_name, task_name, n_labels)) %>%
    mutate(across(everything(), as.character)) %>%
    mutate(across(everything(),
                function(x) case_when(
                  x == "Mental" ~ 0,
                  x == "Physical" ~ 1,
                  x == "No" ~ 0,
                  x == "Yes" ~ 1,
                  x == "Not applicable or not answerable based on the task description (Please Elaborate Below.)" ~ 3,
                  !is.na(as.numeric(x)) ~ as.numeric(x)
                ))) %>%
    as.matrix() %>%
    t() %>% as.data.frame()

    # drop all rows with only 1 non-NA value  
    kripp_alpha_matrix$not.Na <- rowSums(!is.na(kripp_alpha_matrix))
    kripp_alpha_matrix <- kripp_alpha_matrix %>%
                filter(not.Na > 1) %>%
                select(-not.Na) %>%
                as.matrix()
  
    kripp_alpha <- NA
    # these are numeric
    if(q_name == 'Q2intel_manip_1' | 
            q_name == 'Q21intellective_judg_1' |
            q_name == 'Q5creativity_input_1'){
      kripp_alpha <- kripp_alpha_matrix %>% krippalpha(metric = "interval")
    }else{
      kripp_alpha <- kripp_alpha_matrix %>% krippalpha(metric = "nominal")
    }

    kripp_alpha_per_question <- kripp_alpha_per_question %>% rbind(
      data.frame(
        question_name = q_name,
        num_tasks = kripp_alpha$n_units,
        num_raters = kripp_alpha$n_coders,
        krippendorf_alpha = kripp_alpha$alpha
        #kripp_matrix = kripp_alpha_matrix
    ))
}

kripp_alpha_per_question %>% arrange(desc(krippendorf_alpha)) # %>% View()
```

