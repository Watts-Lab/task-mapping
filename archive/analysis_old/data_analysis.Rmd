---
title: "Task mapping data analysis"
---

```{r setup, include=FALSE}
library(irr)
library(egg)
library(grid)
library(ggplot2)
library(jsonlite)
library(graphics)
library(ggfortify)
library(factoextra)
library(stats)
library(ggpubr)
library(dbscan)
library(ecodist)
library(fBasics)
library(corrr)
#library(plyr)
library(cowplot)
library(dplyr)
library(tidyverse)
```

# Import Data
```{r}
numerical_responses_matrix <- read_csv('../../archive/task_map_numeric.csv')

ordinals <- read_csv('../../archive/ordinals.csv')

clean_responses <- read_csv("../../archive/cleaned_task_responses.csv")

agreed_responses <- read_csv("../../archive/task_map.csv")

#questions <- fromJSON("https://task-robot.glitch.me/questions/json")

task_names <- agreed_responses$task
```

# Get the original labels from individuals

```{r}
responses_clean_ind <- clean_responses %>%
  filter(stage == "individual") %>%
  select(c(task, user, ordinals$`ordinals$name`)) %>%
  pivot_longer(cols = -c(task, user),
               names_to = "question") %>%
   mutate(value = recode(value,
                     "Strongly agree" = 5,
                     "Somewhat agree" = 4,
                     "Neither agree nor disagree" = 3,
                     "Somewhat disagree" = 2,
                     "Strongly disagree" = 1
                   )) %>%
  # filter(task %in%
  #         c("9 Dot Problem",
  #           "Abstract grid task",
  #           "Advertisement writing",
  #           "Allocating resources to programs",
  #           "Divergent Association Task",
  #           "Estimating pages of a book",
  #           "Euclidean traveling salesperson",
  #           "Graph coloring task",
  #           "Guessing the correlation",
  #           "Image rating",
  #           "Letters-to-numbers problems (cryptography)",
  #           "Moral Reasoning (Disciplinary Action Case)",
  #           "Putting food into categories",
  #           "Ravens Matrices",
  #           "Recall association",
  #           "Recall videos",
  #           "Room assignment task",
  #           "Search for Oil Task",
  #           "Shopping plan",
  #           "Summarize Discussion",
  #           "To evacuate or not to evacuate",
  #           "Whac-A-Mole",
  #           "Wildcat Wells",
  #           "Wolf, goat and cabbage transfer",
  #           "Word completion given part of word",
  #           "Word completion given starting letter")) %>%
  group_by(task, user, question) %>%
  summarize(value = mean(value))
```

```{r}
tasks <- responses_clean_ind %>% ungroup() %>% select(task) %>% unique()
```

Get a sense of inter-rater reliability

```{r}
task_response_summary <- responses_clean_ind %>%
  group_by(task, question) %>%
  # set NA to 0
  mutate_all(funs(ifelse(is.na(.), 0, .))) %>% 
  summarize(mean_rating = mean(value, na.rm = T),
            agreement = ifelse(abs(value-mean(value))==0, 1, 0),
            n_labels = agree(t(value))$raters,
            all_values = paste(value, collapse = " & ")) %>%
  ungroup()%>%
  group_by(task) %>%
  summarize(
    n_labels = round(mean(n_labels),0),
    mean_agreement = mean(agreement)
  ) %>%
  arrange(desc(mean_agreement)) %>%
  filter(n_labels > 1)

task_response_summary

mean(task_response_summary$mean_agreement)
sd(task_response_summary$mean_agreement)
quantile(task_response_summary$mean_agreement, c(0.025, 0.9725))

question_response_summary <- responses_clean_ind %>%
  group_by(task, question) %>%
  # set NA to 0
  mutate_all(funs(ifelse(is.na(.), 0, .))) %>% 
  summarize(mean_rating = mean(value, na.rm = T),
            agreement = ifelse(abs(value-mean(value))==0, 1, 0),
            n_labels = agree(t(value))$raters,
            all_values = paste(value, collapse = " & ")) %>%
  ungroup()%>%
  group_by(question) %>%
  summarize(
    n_labels = round(mean(n_labels),0),
    mean_agreement = mean(agreement)
  ) %>%
  arrange(desc(mean_agreement)) %>%
  filter(n_labels > 1)

question_response_summary

mean(question_response_summary$mean_agreement)
sd(question_response_summary$mean_agreement)
quantile(question_response_summary$mean_agreement, c(0.025, 0.9725))


kripp.alpha.by.task <- data.frame(matrix(nrow = 0, ncol = 2))

for(task_name in task_response_summary$task){
  ka <- responses_clean_ind %>% filter(task == task_name) %>%
  pivot_wider(names_from = question, values_from = value) %>% ungroup() %>%
  select(-c(task, user)) %>%
  as.matrix() %>% kripp.alpha("ordinal")
  
  newrow = data.frame(
    task = task_name,
    k.alpha = ka$value
  )
  
  kripp.alpha.by.task <- rbind(kripp.alpha.by.task, newrow)
}

kripp.alpha.by.task %>% arrange(desc(k.alpha))
```


Look at correlations of similar questions

```{r, fig.height=8, fig.width=10}
averaged_by_task <- responses_clean_ind %>%
  ungroup() %>%
  group_by(task, question) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  pivot_wider(names_from = question, values_from = value)

# conflict_cooperation and conflict_interests
p1 <- averaged_by_task %>%
  ggplot(aes(
    x = conflict_cooperation,
    y = conflict_interests
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "A") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$conflict_cooperation, averaged_by_task$conflict_interests, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# generate_plan and generate_process
p2 <- averaged_by_task %>%
  ggplot(aes(
    x = generate_plan,
    y = generate_process
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "B") +
  ylim(c(1,5)) +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$generate_plan, averaged_by_task$generate_process, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# generate_ideas and generate_creativity
p3 <- averaged_by_task %>%
  ggplot(aes(
    x = generate_ideas,
    y = generate_creativity
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "C") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$generate_ideas, averaged_by_task$generate_creativity, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# resolve_opinion and resolve_perspectives
p4 <- averaged_by_task %>%
  ggplot(aes(
    x = resolve_opinion,
    y = resolve_perspectives
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "D") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$resolve_opinion, averaged_by_task$resolve_perspectives, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# resolve_information and resolve_data
p5 <- averaged_by_task %>%
  ggplot(aes(
    x = resolve_information,
    y = resolve_data
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "E") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$resolve_information, averaged_by_task$resolve_data, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# solution_objectivity and solution_optimal
p6 <- averaged_by_task %>%
  ggplot(aes(
    x = solution_objectivity,
    y = solution_optimal
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "F") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$solution_objectivity, averaged_by_task$solution_optimal, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# task_divisibility and task_specialization
p7 <- averaged_by_task %>%
  ggplot(aes(
    x = task_divisibility,
    y = task_specialization
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "G") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$task_divisibility, averaged_by_task$task_specialization, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

# measure_easy and measure_immediate
p8 <- averaged_by_task %>%
  ggplot(aes(
    x = measure_easy,
    y = measure_immediate
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "H") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$measure_easy, averaged_by_task$measure_immediate, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))


# performance_cumulative and subtasks_additive
p9 <- averaged_by_task %>%
  ggplot(aes(
    x = performance_cumulative,
    y = subtasks_additive
  )) + geom_count() +
  geom_smooth(method = 'lm')+
  labs(title = "I") +
  annotate("text", x = 1.5, y = 4, size = 10, label = toString(round(cor(averaged_by_task$performance_cumulative, averaged_by_task$subtasks_additive, use="complete.obs"),3))) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size=12, face="bold"))

g <- arrangeGrob(p1,p2,p3,p4,p5,p6,p7,p8,p9, nrow = 5)

ggsave("correlations_of_similar_questions.png", g)
```


# Distribution of Answer Choices
```{r}
first_third_matrix <- numerical_responses_matrix[39:ncol(numerical_responses_matrix)]

my_plots <- lapply(names(first_third_matrix), function(var_x){
  p <- 
    ggplot(first_third_matrix) +
    aes_string(var_x)

  if(is.numeric(numerical_responses_matrix[[var_x]])) {
    p <- p + geom_histogram(bins=5) +
      theme(axis.text.y = element_blank(),
            axis.title.y = element_blank())

  } else {
    p <- p + geom_bar()
  } 

})

plot_grid(plotlist = my_plots)
```



# Filtering by Data Source / Top down v. Bottom up Explorations
```{r warning=FALSE}
questions$source_clean = as.factor(questions$source_clean)
questions$source = as.factor(questions$source)

get_filtered_data_for_author <- function(source_name) {

  filtered_questions <-
    questions %>% filter(source_clean == source_name)
  
  filtered_colnams <-
    as.data.frame(filtered_questions$name) %>% rename(name = `filtered_questions$name`)
  
  column_names <-
    pull(inner_join(ordinals %>% rename(name = `ordinals$name`),
                    filtered_colnams), name)
  
  numerical_responses_one_framework <-
    numerical_responses_matrix %>% select(all_of(c(column_names)))
  
  return(cbind(task_names,numerical_responses_one_framework))
  # note - not filtered bc the columns may not exist in there
}

shaw_data <- get_filtered_data_for_author("Shaw")
mcgrath_data <- get_filtered_data_for_author("McGrath")
zigurs_data <- get_filtered_data_for_author("Zigurs")
steiner_data <- get_filtered_data_for_author("Steiner")
```

## Classification in the "old-school" way

### McGrath
```{r}
# Get all columns needed to make McGrath Classification -----------------
additional_mcgrath_cols <-
  numerical_responses_matrix %>% select(
    c(
      "effort_mental",
      "effort_physical",
      "solution_objectivity",
      "solution_verifiability"
    )
  )

mcgrath_data <- cbind(mcgrath_data, additional_mcgrath_cols)
```

```{r}
# Code to make mcgrath categorizations
make_mcgrath_categorizations <- function(MIDDLE, mcgrath_data) {
  #### Execute Tasks (1,8,7,6) ####
  physical_tasks <-
    mcgrath_data %>% filter(effort_mental < MIDDLE |
                              effort_physical > MIDDLE) # there are only 4 of these
  
  # Note --- noticing that I get 0 tasks for type 7 when I filter for physical in this section; thus, I'm loosening the filtering requirements here
  # Noting that "physical" elements are not consistent across different parts of the sectors
  
  ### Type 7: Battles
  type_7 <-
    mcgrath_data %>% filter(conflict_cooperation > MIDDLE) %>%
    filter(external_adversary > MIDDLE)
  
  ### Type 8: Performances
  type_8 <-
    execute_tasks %>%
    filter((conflict_cooperation < MIDDLE) &
             !(generate_process > MIDDLE) &
             !(generate_plan > MIDDLE) &
             external_standard > MIDDLE
    )
  
  # 1 and 6 ---- WEAK EXECUTE
  # Noticing that if you filter for the physical aspect, you get 0 tasks, so I got rid of it
  
  ### Type 1: Planning
  type_1 <-
    mcgrath_data %>% filter(conflict_cooperation < MIDDLE) %>%
    filter(generate_plan > MIDDLE | generate_process > MIDDLE)
  
  ### Type 6: Mixed Motives
  type_6 <-
    mcgrath_data %>% filter(conflict_cooperation > MIDDLE)  %>%
    filter(conflict_interests > MIDDLE)
  
  ############ Conceptual Tasks (2,3,4,5) ############
  mental_tasks <-
    mcgrath_data %>% filter(effort_mental > MIDDLE |
                              effort_physical < MIDDLE)
  
  ## Cooperation (2,3)
  mental_cooperate <- mental_tasks %>%
    filter(conflict_cooperation < MIDDLE)
  
  ### Type 2: Creativity
  type_2 <- mental_cooperate %>%
    filter(generate_ideas > MIDDLE | generate_creativity > MIDDLE)
  
  ### Type 3: Intellective
  type_3 <- mental_cooperate %>%
    filter(
      solution_objectivity > MIDDLE |
        solution_verifiability > MIDDLE | external_standard > MIDDLE
    )
  
  ## Conflict (4,5)
  mental_conflict <-  mental_tasks %>%
    filter(conflict_cooperation > MIDDLE)
  
  ### Type 4: Decision-Making
  type_4 <- mental_conflict %>%
    filter(solution_objectivity < MIDDLE |
             solution_verifiability < MIDDLE)
  
  ### Type 5: Cognitive Conflict
  type_5 <- mental_conflict %>%
    filter(resolve_opinion > MIDDLE | resolve_perspectives > MIDDLE)

####### export the data --- currently commented out
  mcgrath_quadrant_labels <- data.frame(task_names)

  for (i in 1:nrow(mcgrath_data)) {
    task = mcgrath_data$task_names[i]
    mcgrath_quadrant_labels$generate.planning[i] = as.numeric(task %in% type_1$task_names)
    mcgrath_quadrant_labels$generate.creativity[i] = as.numeric(task %in% type_2$task_names)

    mcgrath_quadrant_labels$choose.intellective[i] = as.numeric(task %in% type_3$task_names)
    mcgrath_quadrant_labels$choose.decision[i] = as.numeric(task %in% type_4$task_names)

    mcgrath_quadrant_labels$negotiate.cogconf[i] = as.numeric(task %in% type_5$task_names)
    mcgrath_quadrant_labels$negotiate.mixmotive[i] = as.numeric(task %in% type_6$task_names)

    mcgrath_quadrant_labels$execute.contest[i] = as.numeric(task %in% type_7$task_names)
    mcgrath_quadrant_labels$execute.performance[i] = as.numeric(task %in% type_8$task_names)
  }

  return(mcgrath_quadrant_labels)
  
  # write.csv(
  #   mcgrath_quadrant_labels,
  #   paste(
  #     './analysis_experiments/mcgrath-quadrant-labels-',
  #     MIDDLE,
  #     '.csv'
  #   )
  # )

}
```

Actually run the McGrath categorizations
```{r}
# for(MIDDLE in 2:4){ # MIDDLE is used to separate the types of tasks
#   make_mcgrath_categorizations(MIDDLE,mcgrath_data)
# }
```

```{r mcgrath-intensity}
# Code to weight mcgrath categorizations
# create_weighted_mcgrath<- function(MIDDLE) {
#   print(MIDDLE)
#   
#   # Read in McGrath Categorizations
#   mcgrath_labels <-  paste('./analysis_experiments/mcgrath-quadrant-labels-',
#                            MIDDLE,
#                            '.csv') %>% read_csv()
#   REVERSE = 6
#   
#   type_1 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(generate.planning != 0))$task_names) %>%
#     mutate(type_1_score = 
#              (generate_plan + generate_process) / 
#              (max(generate_plan) + max(generate_process))) %>% select(task_names, type_1_score)
#   type_2 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(generate.creativity != 0))$task_names) %>%
#     mutate(type_2_score = (generate_ideas + generate_creativity) /
#              (max(generate_ideas) + max(generate_creativity))) %>% select(task_names, type_2_score)
#   type_3 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(choose.intellective != 0))$task_names) %>%
#     mutate(
#       type_3_score = (
#         solution_objectivity + solution_verifiability + external_standard) /
#         (max(solution_objectivity) + max(solution_verifiability) + max(external_standard)
#       )
#     ) %>% select(task_names, type_3_score)
#   type_4 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(choose.decision != 0))$task_names)%>%
#     mutate(
#       type_4_score = (
#         REVERSE - solution_objectivity + REVERSE - solution_verifiability
#       ) / (10)
#     ) %>% select(task_names, type_4_score)
#   type_5 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(negotiate.cogconf != 0))$task_names) %>%
#     mutate(
#       type_5_score = (
#         resolve_opinion + resolve_perspectives
#       ) / ((max(resolve_opinion) + max(resolve_perspectives)))
#     ) %>% select(task_names, type_5_score)
#   type_6 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(negotiate.mixmotive != 0))$task_names) %>%
#     mutate(type_6_score = (conflict_cooperation + conflict_interests) /
#              (max(conflict_cooperation) + max(conflict_interests))) %>% select(task_names, type_6_score)
#   type_7 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(execute.contest != 0))$task_names) %>%
#     mutate(type_7_score = (conflict_cooperation + external_adversary) /
#              (max(conflict_cooperation) + max(external_adversary))) %>% select(task_names, type_7_score)
#   type_8 <- mcgrath_data %>% filter(task_names %in% (mcgrath_labels %>% filter(execute.performance != 0))$task_names) %>%
#     mutate(type_8_score = (REVERSE - conflict_cooperation + external_standard) /
#              (10)) %>% select(task_names, type_8_score)
# 
#   #### export all results as a weighted matrix instead
#   mcgrath_quadrant_labels_weighted <- data.frame(task_names)
# 
#   for (i in 1:nrow(mcgrath_data)) {
#     task = mcgrath_data$task_names[i]
#     mcgrath_quadrant_labels_weighted$generate.planning[i] = ifelse(task %in% type_1$task_names,
#      (type_1 %>% filter(task_names == task))$type_1_score, 0)
#     mcgrath_quadrant_labels_weighted$generate.creativity[i] = ifelse(task %in% type_2$task_names,
#      (type_2 %>% filter(task_names == task))$type_2_score, 0)
#     mcgrath_quadrant_labels_weighted$choose.intellective[i] = ifelse(task %in% type_3$task_names,
#      (type_3 %>% filter(task_names == task))$type_3_score, 0)
#     mcgrath_quadrant_labels_weighted$choose.decision[i] = ifelse(task %in% type_4$task_names,
#      (type_4 %>% filter(task_names == task))$type_4_score, 0)
#     mcgrath_quadrant_labels_weighted$negotiate.cogconf[i] = ifelse(task %in% type_5$task_names,
#      (type_5 %>% filter(task_names == task))$type_5_score, 0)
#     mcgrath_quadrant_labels_weighted$negotiate.mixmotive[i] = ifelse(task %in% type_6$task_names,
#      (type_6 %>% filter(task_names == task))$type_6_score, 0)
#     mcgrath_quadrant_labels_weighted$execute.contest[i] = ifelse(task %in% type_7$task_names,
#      (type_7 %>% filter(task_names == task))$type_7_score, 0)
#     mcgrath_quadrant_labels_weighted$execute.performance[i] = ifelse(task %in% type_8$task_names,
#      (type_8 %>% filter(task_names == task))$type_8_score, 0)
#   }
# 
#   write.csv(
#     mcgrath_quadrant_labels_weighted,
#     paste(
#       './analysis_experiments/mcgrath-quadrant-labels-weighted',
#       MIDDLE,
#       '.csv'
#     )
#   )
#   
# }
```

```{r}
# for(MIDDLE in 2:4){ # MIDDLE is used to separate the types of tasks
#   create_weighted_mcgrath(MIDDLE)
# }
```

#### Bootstrapping McGrath
```{r}
# set.seed(123)
# 
# # Select rows with replacement from dataframe
# MIDDLE <- 4
# N_REPS <- 1000
# N_SAMPLES <- nrow(mcgrath_data)
# 
# list_num_zeroes<-c()
# list_num_above_ones<-c()
# 
# for(i in 1:N_REPS){
#   sampled_mcgrath_data <- mcgrath_data[sample(nrow(mcgrath_data), N_SAMPLES, replace = T), ]
#   mcgrath_categorizations <- make_mcgrath_categorizations(MIDDLE,sampled_mcgrath_data)
#   
#   #calculate the stats: Num unmapped tasks, Num tasks mapped to more than 1 category
#   label_frequency_table <- mcgrath_categorizations %>% mutate(
#     num_labels = rowSums(across(where(is.numeric)))
#   ) %>% select(num_labels) %>% table()
#   
#   num_zero <- label_frequency_table[1]
#   num_above_one <- ifelse(
#     length(label_frequency_table)==4,
#     label_frequency_table[4] + label_frequency_table[3],
#     label_frequency_table[3]
#   )
#   
#   list_num_zeroes[i] <- num_zero
#   list_num_above_ones[i] <- num_above_one
# 
# }
# 
# mean(list_num_zeroes)
# sd(list_num_zeroes)
# quantile(list_num_zeroes, probs=c(0.025, 0.975))
# 
# mean(list_num_above_ones)
# sd(list_num_above_ones)
# quantile(list_num_above_ones, probs=c(0.025, 0.975))
# ```
# 
# #### Identifying McGrath's Peculiarities
# ```{r}
# # Check Labels
# mcgrath_labels_2 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 2 .csv')
# mcgrath_labels_3 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 3 .csv')
# mcgrath_labels_4 <- read_csv('./analysis_experiments/mcgrath-quadrant-labels- 4 .csv')
# 
# ## List of peculiar tasks that get labeled inconsistently
# union(
#   union(
#     setdiff(mcgrath_labels_2, mcgrath_labels_3)$task_names,
#     setdiff(mcgrath_labels_3, mcgrath_labels_4)$task_names
#   ),
#   setdiff(mcgrath_labels_2, mcgrath_labels_4)$task_names
# )

```

### Continuous McGrath Mapping
```{r}
type_7_cols <- mcgrath_data%>%select(c("conflict_cooperation","external_adversary")) %>%
    rowwise() %>%
    mutate(
      type_7 = distance(rbind(across(),c(5,5)), method="euclidean")[1]
    )

type_8_cols <- mcgrath_data%>%select(c("conflict_cooperation","generate_process","generate_plan","external_standard","effort_mental","effort_physical")) %>%
    rowwise() %>%
    mutate(
      type_8 = distance(rbind(across(),c(1,1,1,5,1,5)), method="euclidean")[1]
    )

type_1_cols <- mcgrath_data%>%select(c("conflict_cooperation","generate_process","generate_plan")) %>%
    rowwise() %>%
    mutate(
      type_1 = distance(rbind(across(),c(1,5,5)), method="euclidean")[1]
    )
  
type_6_cols <- mcgrath_data%>%select(c("conflict_cooperation","conflict_interests")) %>%
    rowwise() %>%
    mutate(
      type_6 = distance(rbind(across(),c(5,5)), method="euclidean")[1]
    )
  
type_2_cols <- mcgrath_data%>%select(c("generate_ideas","generate_creativity","effort_mental","effort_physical")) %>%
    rowwise() %>%
    mutate(
      type_2 = distance(rbind(across(),c(5,5,5,1)), method="euclidean")[1]
    )

type_3_cols <- mcgrath_data%>%select(c("solution_objectivity","solution_verifiability","external_standard","effort_mental","effort_physical")) %>%
    rowwise() %>%
    mutate(
      type_3 = distance(rbind(across(),c(5,5,5,5,1)), method="euclidean")[1]
    )

type_4_cols <- mcgrath_data%>%select(c("solution_objectivity", "solution_verifiability", "conflict_cooperation","effort_mental","effort_physical")) %>%
    rowwise() %>%
    mutate(
      type_4 = distance(rbind(across(),c(1,1,5,5,1)), method="euclidean")[1]
  )

type_5_cols <- mcgrath_data%>%select(c("resolve_opinion", "resolve_perspectives", "conflict_cooperation","effort_mental","effort_physical")) %>%
    rowwise() %>%
    mutate(
      type_5 = distance(rbind(across(),c(5,5,5,5,1)), method="euclidean")[1]
  )

  mcgrath_quadrant_labels_cont <- data.frame(task_names)

  for (i in 1:nrow(mcgrath_data)) {
    task = mcgrath_data$task_names[i]
    mcgrath_quadrant_labels_cont$generate.planning[i] = type_1_cols$type_1[i]
    mcgrath_quadrant_labels_cont$generate.creativity[i] = type_2_cols$type_2[i]

    mcgrath_quadrant_labels_cont$choose.intellective[i] = type_3_cols$type_3[i]
    mcgrath_quadrant_labels_cont$choose.decision[i] = type_4_cols$type_4[i]

    mcgrath_quadrant_labels_cont$negotiate.cogconf[i] = type_5_cols$type_5[i]
    mcgrath_quadrant_labels_cont$negotiate.mixmotive[i] = type_6_cols$type_6[i]

    mcgrath_quadrant_labels_cont$execute.contest[i] = type_7_cols$type_7[i]
    mcgrath_quadrant_labels_cont$execute.performance[i] = type_8_cols$type_8[i]
  }

write.csv(
    mcgrath_quadrant_labels_cont,
    './analysis_experiments/mcgrath-quadrant-labels-continuous.csv'
)
```

### McGrath Correlations - Collapse to 10 Cols

```{r}
mcgrath_data %>% select(c(conflict_cooperation, conflict_interests)) %>% as.matrix()
questions
#cronbach.alpha(cols)
```

```{r}
# mcgrath_data %>% select(-task_names) %>% correlate(method = "pearson") %>%
#   shave() %>%
#   rplot(shape = 15, colours = c("red", "green")) +
#   theme(axis.text.x = element_text(angle = 60, hjust = 1)) #otherwise too crowded

numerical_completed_and_agreed %>% select(-task_names) %>% correlate(method = "pearson") %>%
  select(c(term, outcome_certain))
```

Working out the worst offenders

```{r}
user_freq <- 
  clean_responses %>% filter(stage == "agreement") %>% 
  select(user) %>% table() %>% data.frame()



worst_30_tasks <- mcgrath_data %>%
  rename(task = task_names) %>%
  mutate(
    physical_mental_err = abs(6 - (effort_physical + effort_mental)),
    generate_plan_err = abs(generate_plan - generate_process),
    generate_ideas_err = abs(generate_ideas - generate_creativity),
    solution_objectivity_err = abs(solution_objectivity - solution_verifiability),
    resolve_opinion_err = abs(resolve_opinion - resolve_perspectives),
    conflict_interests_err = abs(conflict_interests - conflict_cooperation),
    total_err = physical_mental_err + generate_plan_err +
      generate_ideas_err + solution_objectivity_err +
      resolve_opinion_err + conflict_interests_err
  ) %>%
  arrange(desc(total_err)) %>%
  left_join((clean_responses %>% filter(stage == "agreement")) %>% select(c(task, user)), by = "task") %>%
  select(
    task,
    user,
    physical_mental_err,
    generate_plan_err,
    generate_ideas_err,
    solution_objectivity_err,
    resolve_opinion_err,
    conflict_interests_err,
    conflict_interests_err,
    total_err
  ) %>%
  head(30) 

#####

user_freq <- clean_responses %>% filter(stage == 'individual') %>% select(user)%>%table()

w30_tasknames <- worst_30_tasks %>% select(task) %>% as.list() %>% unlist()
clean_responses %>% filter(task %in% w30_tasknames) %>% filter(stage == 'individual') %>% 
  select(user) %>%
  table() %>% data.frame() %>% merge(user_freq, by= ".") %>%
  filter(
    Freq.y > 1
  ) %>%
  mutate(
    count_normalized = Freq.x/Freq.y
  ) %>%
  ggplot(aes(
    x = .,
    y = count_normalized
  ))+
  geom_bar(stat="identity")+
  ggtitle("Students Who Mapped the Top 30 Inconsistent Tasks")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) #otherwise too crowded


# 
# %>%
#   select(user) %>%
#   table() %>% data.frame() %>% merge(user_freq, by= ".") %>%
#   filter(
#     Freq.y > 1
#   ) %>%
#   mutate(
#     count_normalized = Freq.x/Freq.y
#   ) %>%
#   ggplot(aes(
#     x = .,
#     y = count_normalized
#   ))+
#   geom_bar(stat="identity")+
#   ggtitle("Students Who Mapped the Top 30 Inconsistent Tasks")+
#   theme(axis.text.x = element_text(angle = 60, hjust = 1)) #otherwise too crowded
#   
  
  
  # ggplot(
  #   aes(x = total_err)
  # ) +
  # geom_histogram(bins = 16)
  
  #write_csv('./analysis_experiments/mcgraths-worst-offenders.csv')
```

Remapping euclidean traveling salesperson
```{r}
agreed_responses %>% filter(task=="Euclidean traveling salesperson") %>% pivot_longer(cols = everything(),
  names_to = "question"
) %>%
  write_csv('analysis_experiments/euclidean-traveling-salesperson.csv')
```

Radio Assembly Task
```{r}
agreed_responses %>% filter(task=="Radio assembly task") %>% pivot_longer(cols = everything(),
  names_to = "question"
) %>%
  write_csv('analysis_experiments/radio-assembly-task.csv')
```
Word completion given part of word
```{r}
agreed_responses %>% filter(task=="Word completion given part of word") %>% pivot_longer(cols = everything(),
  names_to = "question"
) %>%
  write_csv('analysis_experiments/word-completion-part-of-word-task.csv')
```
Architectural design task
```{r}
agreed_responses %>% filter(task=="Architectural design task") %>% pivot_longer(cols = everything(),
  names_to = "question"
) %>%
  write_csv('analysis_experiments/architectural-design-task.csv')
```


Looking at how individual students influenced the agreement of tasks, pre-agreement phase

```{r message=FALSE, warning=FALSE}
 factorize <- function(x) {
   case_when(
     x %in% c("Strongly disagree") ~ 1,
     x %in% c("Disagree") ~ 2,
     x %in% c("Neither agree nor disagree") ~ 3,
     x %in% c("Agree") ~ 4,
     x %in% c("Strongly agree") ~ 5
   )
 }
  
df.disagreed_questions <- data.frame(matrix(ncol=1, nrow=0))
colnames(df.disagreed_questions) <- c("question")

df.rater_differences <- data.frame(matrix(ncol=4, nrow=0))
rater_diff_colnames <- c(
   "task",
   "agreement_dataframe",
   "num_disagreed",
   "num_one_person_dominant")
colnames(df.rater_differences) <- rater_diff_colnames

individual_responses <- clean_responses %>% filter(stage == 'individual')

for (i in 1:nrow(agreed_responses)){
  task_row = agreed_responses[i, ]
  task_name = task_row$task
  
  # Agreed Response
  agreed_result_for_task <- clean_responses %>% filter(stage == 'agreement') %>%
    filter(task == task_name)
  agreed_result_for_task <- mutate_at(
     agreed_result_for_task %>% select(task, user, ordinals$`ordinals$name`),
     ordinals$`ordinals$name`,
     factorize
   )
  agreed_result_for_task[is.na(agreed_result_for_task)] <- 0 #treat NA as 0

  agreed_numeric <- agreed_result_for_task %>% select(-c(task, user)) %>% 
    pivot_longer(names_to = "question", cols = everything())

  # Individual Responses
  individual_results_for_task <-
    individual_responses %>% select(task, user, ordinals$`ordinals$name`) %>% 
    filter(task == task_name) %>% unique()
  
  ## BELOW ASSUMES 2 MAPPERS. There's 1 exception with 5 distinct mappings?
  if(nrow(individual_results_for_task) != 2){
    next
  }
  
   individual_results_for_task <- mutate_at(
     individual_results_for_task,
     ordinals$`ordinals$name`,
     factorize
   )
   individual_results_for_task[is.na(individual_results_for_task)] <- 0 #treat NA as 0
   
   # key question: how much did people adjust in order to get to the final agreement?
   # how do we know who contributed more to the mean?
   
    individual1 <- individual_results_for_task[1,]$user
    individual2 <- individual_results_for_task[2,]$user
    
    individual1_numeric <- individual_results_for_task[1,] %>% select(-c(task, user)) %>% 
      pivot_longer(names_to = "question", cols = everything()) %>%
      rename(value1 = value)
    individual2_numeric <- individual_results_for_task[2,] %>% 
      select(-c(task, user)) %>%
       pivot_longer(names_to = "question", cols = everything()) %>%
        rename(value2 = value)
    
    individual_decisions <- merge(individual1_numeric,individual2_numeric, by = "question") %>%
      mutate(
        difference = value1-value2
      ) 
    
    # get a summary of how the ratings got combined into the final agreement, and who was influential
    agreement_summary <-
      merge(individual_decisions, agreed_numeric, by = "question") %>%
      rename(final.agreement = value) %>%
      mutate(
        is.ind.1 = ifelse(difference != 0 &
                            final.agreement == value1, 1, 0),
        is.ind.2 = ifelse(difference != 0 &
                            final.agreement == value2, 1, 0),
        is.neither = ifelse(is.ind.1+is.ind.2 == 0, 0 , 1),
        dpte.ind.1 = ifelse(difference==0, 0,1),
        dpte.ind.2 = dpte.ind.1
      ) %>%
      rename(
        individual1 = value1,
        individual2 = value2,
        !!paste("is.", individual1) := is.ind.1,
        !!paste("is.", individual2) := is.ind.2,
        !!paste("dpte.", individual1) := dpte.ind.1,
        !!paste("dpte.", individual2) := dpte.ind.2)
  
    # store our results
    disagreed_qs <- agreement_summary %>% filter(difference!=0) %>% select(question)
    
    df.disagreed_questions <- rbind(df.disagreed_questions, 
                                   disagreed_qs)
    
    df.rater_differences <- rbind(
      df.rater_differences,
      data.frame(
        "task" = task_name,
        "agreement_dataframe" = nest(agreement_summary),
        "num_disagreed" = nrow(agreement_summary %>% filter(difference != 0)),
        "num_one_person_dominant" = nrow(agreement_summary %>% filter(is.neither != 0))
      )
    )
}
```


```{r}
df.disagreed_questions %>% table() %>% data.frame() %>% arrange(desc(Freq))
```

```{r}
df.rd.bar <- df.rater_differences %>%
         pivot_longer(names_to = "disagreements",
                      cols = c(num_disagreed, num_one_person_dominant))
                      
ggplot(df.rd.bar,
      aes(
       x = task,
       y = value,
       fill = disagreements)) +
  geom_bar(position = "dodge2", stat = "identity") +
  geom_hline(aes(yintercept=mean(df.rater_differences$num_disagreed))) +
  geom_text(aes(0,mean(df.rater_differences$num_disagreed),label = "mean", hjust = -1, vjust = -1))+
   theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```
which students tended to dominate the most?
```{r}
df_all_users_dominance <- data.frame(matrix(nrow=57,ncol=0))
df_all_users_numdisputes <- data.frame(matrix(nrow=57,ncol=0))

for(i in 1:nrow(df.rater_differences)){
  task_dataframe = as.data.frame(df.rater_differences[i,]$data)
  
  col_names <- colnames(task_dataframe)
  infl_col_names <- col_names[grepl("is.", col_names)]
  
  dis_col_names <- col_names[grepl("dpte.", col_names)]
  
  influence_cols <- task_dataframe %>% select(infl_col_names)
  disp_cols <- task_dataframe %>% select(dis_col_names)
  
  if(nrow(influence_cols) != 57){ #what's going on here?
    #print(influence_cols)
    next
  }
  
  df_all_users_dominance<-cbind(df_all_users_dominance,influence_cols)
  df_all_users_numdisputes<-cbind(df_all_users_numdisputes,disp_cols)
}

# Sum everything together
df_all_users_dominance<- t(rowsum(t(df_all_users_dominance), group = colnames(df_all_users_dominance), na.rm = T)) %>%
  as.data.frame()

print(colSums(df_all_users_dominance) %>% data.frame())

# Get fraction of dominance normalized by number of disagreements encountered
df_all_users_numdisputes<- t(rowsum(t(df_all_users_numdisputes), group = colnames(df_all_users_numdisputes), na.rm = T)) %>%
  as.data.frame()

print(colSums(df_all_users_numdisputes) %>% data.frame())
```


Condensed to 10 McGrath Cols

```{r}
mgrath_condensed <- mcgrath_data %>%
  mutate(
    effort_mental_physical = (effort_mental + (6-effort_physical))/2,
    correct_answer = (solution_objectivity+solution_verifiability)/2,
    conflict_mixed_motive = (conflict_interests+conflict_cooperation)/2,
    generate_plan_process = (generate_plan + generate_process)/2,
    conflict_cognitive = (resolve_opinion+resolve_perspectives)/2
  ) %>%
  select(-c(
    effort_mental,effort_physical,
    solution_objectivity,solution_verifiability,
    conflict_interests,conflict_cooperation,
    generate_plan,generate_process,
    resolve_opinion,resolve_perspectives,
    generate_creativity
  )) 


mgrath_condensed  %>% select(-task_names) %>% correlate(method = "pearson") %>%
  shave() %>%
  rplot(shape = 15, colours = c("red", "green")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) #otherwise too crowded
```

```{r}
mcgrath_weights <- read_csv("mcgrath-weighted-rule-matrix-normalized.csv")%>%
  select(-c(X1, total_weight))

mcgrath_weighted_cols <- mgrath_condensed %>%
  select(
    c(
      -task_names,
      generate_plan_process,
      generate_ideas,
      correct_answer,
      conflict_cognitive,
      conflict_mixed_motive,
      external_adversary,
      external_standard,
      effort_mental_physical
    )
  )

mcgrath_inner_products <- as.data.frame(
  t(as.matrix(mcgrath_weights) %*% t(as.matrix(
  mcgrath_weighted_cols)))
)

cbind(task_names,mcgrath_inner_products)%>%
  rename(
    planning = V1,
    creativity = V2,
    intellective = V3,
    decision.making = V4,
    cognitive.conflict = V5,
    mixed.motive = V6,
    contests = V7,
    performances = V8
  )%>%
  write_csv('./analysis_experiments/mcgrath_task_weighted_inner_products.csv')
```












### How different are tasks that are all 0 for choose.intellective?
```{r}
intellective_tasks <- mcgrath_quadrant_labels_cont %>% filter(choose.intellective == 0) %>% select("task_names")

intellective_tasks_numeric <- numerical_completed_tasks %>%
      filter(task_names %in% intellective_tasks$task_names) %>% select(-task_names)
  
# Distance
distance(intellective_tasks_numeric) %>% c() %>% summary()

# How much unexplained variance
#intellective_tasks_numeric %>% as.matrix() %>% var() %>% eigen()
```


```{r old-mcgrath}
# This was Emily's first attempt at doing this - saving for posterity but redoing#
# 
# # 1. Generating Alternatives
# mcg_generating <- mcgrath_data %>%
#   filter(
#     (generate_plan > MIDDLE | generate_process > MIDDLE | generate_ideas > MIDDLE | generate_creativity > MIDDLE) & #  Creativity markers
#     (conflict_cooperation < MIDDLE & conflict_interests < MIDDLE) & # NOT conflict/cooperation or conflict of interests
#     (solution_objectivity < MIDDLE | solution_verifiability < MIDDLE) # NOT objective - but this is an OR because some plans are objective?
#     )
# 
# # 2. Choosing Alternatives
# mgc_choosing <- data_with_mcgrath_cols %>%
#   filter(
#     (solution_objectivity > MIDDLE & solution_verifiability > MIDDLE) & # Markers of Objective Choice
#     (generate_plan < MIDDLE | generate_process < MIDDLE | generate_ideas < MIDDLE | generate_creativity < MIDDLE) #  NOT Generating markers
#     # Agnostic towards Negotiation b/c sometimes the choice is a negotiation
#     )
# 
# # 3. Negotiate
# mcg_negotiating <- data_with_mcgrath_cols %>%
#   filter(
#     (resolve_opinion > MIDDLE | resolve_perspectives > MIDDLE | conflict_interests > MIDDLE | conflict_cooperation > MIDDLE) &# Negotiation markers
#      (solution_objectivity < MIDDLE | solution_verifiability < MIDDLE) & # No correct solution (excludes CHOOSE or is explicitly a conflict and cooperation game)
#      (generate_creativity < MIDDLE) # definitely NOT creativity
#     )
# 
# # 4. Execute
# mcg_executing <- data_with_mcgrath_cols %>%
#   filter(
#     (external_adversary > MIDDLE | external_standard > MIDDLE | conflict_interests > MIDDLE) & # Markers of Execute
#     (generate_plan < MIDDLE | generate_process < MIDDLE | generate_ideas < MIDDLE | generate_creativity < MIDDLE) & #  NOT Generating markers
#     (resolve_opinion < MIDDLE & resolve_perspectives < MIDDLE ) # NOT Negotiation markers
#   )

####### Generate McGrath Categorization Summary #####
# mcgrath_quadrant_labels <- data.frame(task_names)
# 
# for (i in 1:nrow(data_with_mcgrath_cols)) {
#   task = data_with_mcgrath_cols$task_names[i]
#   mcgrath_quadrant_labels$generating[i] = as.numeric(task %in% mcg_generating$task_names)
#   mcgrath_quadrant_labels$choosing[i] = as.numeric(task %in% mgc_choosing$task_names)
#   mcgrath_quadrant_labels$negotiating[i] = as.numeric(task %in% mcg_negotiating$task_names)
#   mcgrath_quadrant_labels$executing[i] = as.numeric(task %in% mcg_executing$task_names)
# }
# 
# mcgrath_quadrant_labels <- mcgrath_quadrant_labels %>% mutate(
#   num_total_labels = generating+choosing+negotiating+executing
# )
# table(mcgrath_quadrant_labels$num_total_labels)
# 
# write.csv(mcgrath_quadrant_labels, './analysis_experiments/mcgrath-quadrant-labels.csv')
```


### Steiner
```{r}

### Subtask Structure

# Divisible Tasks
steiner_divisible <- steiner_data %>% filter(
  goal_full < MIDDLE & # there is partial credit - can be divided 
  (goal_partial > MIDDLE | # the rest of these indicate divisibility
  task_divisibility > MIDDLE | # using OR here to cast wider net / gradient
  submission_separate > MIDDLE |
  task_specialization > MIDDLE)
)

# Unitary Tasks
steiner_unitary <- steiner_data %>% filter(
  goal_full > MIDDLE & # there is no partial credit - can't be divided 
  (goal_partial < MIDDLE | # the rest of these indicate divisibility
  task_divisibility < MIDDLE |
  submission_separate < MIDDLE |
  task_specialization < MIDDLE)
)


### Nature of the Goal

# Open question: is it possible to be both maximizing and optimizing?
# Maximizing Tasks
steiner_maximizing <- steiner_data %>% filter(
  goal_maximize > MIDDLE
)

# Optimizing Tasks
steiner_optimizing <- steiner_data %>% filter(
  goal_standard > MIDDLE |
  goal_optimize > MIDDLE
)


### Permitted Group Processes

# Additive Tasks
steiner_additive <- steiner_data %>% filter(
  (subtasks_additive > MIDDLE |
  performance_average > MIDDLE |
  performance_cumulative > MIDDLE) &
  (performance_worst < MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive < MIDDLE & # Disjunctive Characteristics - AND here because it CANNOT be either of these things
  performance_best < MIDDLE) &
  (subtasks_discretionary_weight < MIDDLE) & # NEED to be false for additive
  (subtasks_discretionary_combination < MIDDLE) 
)

# Conjunctive Tasks
steiner_conjunctive <- steiner_data %>% filter(
  (subtasks_additive < MIDDLE & # Additive Characteristics - AND because these cannot be true
  performance_average < MIDDLE &
  performance_cumulative < MIDDLE) &
  (performance_worst > MIDDLE |
     participation_equal > MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive < MIDDLE | # Disjunctive Characteristics, but keeping OR because it's possible w/ conjunctive to have one person determine the outcome ... the worst one
  performance_best < MIDDLE)
)

# Disjunctive Tasks
steiner_disjunctive <- steiner_data %>% filter(
  (subtasks_additive < MIDDLE &# Additive Characteristics - AND because these cannot be true
  performance_average < MIDDLE &
  performance_cumulative < MIDDLE) &
  (performance_worst < MIDDLE &
     participation_equal < MIDDLE)  & # Conjunctive Characteristics
  (subtasks_disjunctive > MIDDLE | # Disjunctive Characteristics
  performance_best > MIDDLE)
)

# Discretionary Tasks
steiner_discretionary <- steiner_data %>% filter(
  subtasks_discretionary_weight > MIDDLE |
  subtasks_discretionary_combination > MIDDLE
)

####### Generate Steiner Categorization Summary #####
steiner_labels <- data.frame(task_names)

for (i in 1:nrow(steiner_data)) {
  task = steiner_data$task_names[i]
  steiner_labels$maximizing[i] = as.numeric(task %in% steiner_maximizing$task_names)
  steiner_labels$optimizing[i] = as.numeric(task %in% steiner_optimizing$task_names)
  steiner_labels$divisible[i] = as.numeric(task %in% steiner_divisible$task_names)
  steiner_labels$unitary[i] = as.numeric(task %in% steiner_unitary$task_names)
  steiner_labels$additive[i] = as.numeric(task %in% steiner_additive$task_names)
  steiner_labels$conjunctive[i] = as.numeric(task %in% steiner_conjunctive$task_names)
  steiner_labels$disjunctive[i] = as.numeric(task %in% steiner_disjunctive$task_names)
  steiner_labels$discretionary[i] = as.numeric(task %in% steiner_discretionary$task_names)
}

steiner_labels %>% mutate(
  num_total_labels = maximizing+optimizing+divisible+unitary+additive+conjunctive+disjunctive+discretionary
)

write.csv(steiner_labels, './analysis_experiments/steiner-labels.csv')
```

### Zigurs
```{r}
# TODO
```

### Shaw
```{r}
shaw_processed_dimensions <- shaw_data %>%
  mutate(
    dim_2 =  objective_multiplicity + skills_specialization, #Task Difficulty
    dim_4 =  solution_valid - solution_singularity, # Solution Multiplicity
    dim_5 = solution_path,
    dim_6 = solution_objectivity + solution_verifiability + solution_optimal,
    dim_8 = effort_mental/effort_physical # Ratio of mental to motor
  ) %>%
  select(c(dim_2,dim_4,dim_5,dim_6,dim_8))

# DBSCAN ---- OPTIMIZE TO IDENTIFY CLUSTERS

dbscan_paramsearch_results <- data.frame(NA, NA, NA)
names(dbscan_paramsearch_results) <- c("min.pts", "eps", "noise.pts")

for(minPts in 2:20) {

  print("starting search for min cluster size of...")
  print(minPts)
  
  START = 0
  STEP = 0.01
  
  minimum_number_of_noise_points = 10000
  value_of_eps_at_min = 10000
  eps = START
  
  repeat{
    
    print("eps is currently ...")
    print(eps)
    print(minPts)
    
    dbscan_result <- dbscan(shaw_processed_dimensions,
                            eps = eps,
                            minPts = minPts)
    
    current_num_clusters = length(table(dbscan_result[1]))
    print(current_num_clusters)
    
    # at least 2 clusters
    if(current_num_clusters<=2){
      break
    }
    
    cur_num_noise_points = table(dbscan_result[1])[1]
    
    # print the dbscan result
    print(table(dbscan_result[1]))
    
    if (cur_num_noise_points < minimum_number_of_noise_points) {
      minimum_number_of_noise_points = cur_num_noise_points
      value_of_eps_at_min = eps
    }
    eps = eps + STEP
  }
  
  # STORE RESULT
  result_row <- c(minPts,value_of_eps_at_min,minimum_number_of_noise_points)
  dbscan_paramsearch_results <-
    rbind(dbscan_paramsearch_results,result_row)
}

# DBSCAN search results
dbscan_paramsearch_results

optimized_dbscan_result <- dbscan(shaw_processed_dimensions,
                            eps = 3.88,
                            minPts = 7)

table(optimized_dbscan_result[1])

cbind(data.frame(task_names),data.frame(optimized_dbscan_result[1])) %>% write_csv("./analysis_experiments/shaw_cluster_results.csv")
```

# Laughlin
```{r}

# Pure Laughlin
laughlin_continuum <- numerical_responses_matrix %>%
  select(solution_demonstrability)

cbind(data.frame(task_names),data.frame(laughlin_continuum)) %>% write_csv("./analysis_experiments/laughlin_results.csv")
```


# Clustering Algorithm Explorations

NOTE: the dbscan R package uses the Euclidean distance by default, but this doesn't work well for high-dimensional spaces: https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions

I have to port the data over to scikitlearn...
```{r}
# DBSCAN and HDBSCAN
data <- numerical_completed_tasks %>% select(-c(task_names)) %>% as.matrix()


# playing with dbscan
res.dbscan <-
  dbscan(data,
         eps = 40, # no clusters are showing up no matter what I do - potential eps issue?
         minPts = 0)

res.dbscan$cluster

task_clusters <- as.data.frame(cbind(task_names, res.dbscan$cluster))
task_clusters_dbscan <- task_clusters[order(task_clusters$V2),]%>%
  rename(All_Columns = V2) %>%
  left_join(all_clusters, by = "task_names")

write.csv(task_clusters_dbscan,"./analysis_experiments/task_clusters_dbscan_kmeans_comparison.csv")

# playing with hdbscan
res.dbscan <-
  hdbscan(data,
         minPts = 5)

res.dbscan
```

# Visualization Explorations
```{r}
data = numerical_completed_tasks # can update this to whatever

data = as.matrix(data%>%select(-c(task_names)))
```

## Heatmap
```{r}
# heatmap generation
png(
  "./analysis_experiments/heatmap.png",
  width = 20,
  height = 20,
  units = 'in',
  res = 600
)
heatmap <-
  heatmap(data, Colv = NA) #Row dendrogram groups this by similarity in rows
```

## K-means clustering + PCA
```{r}
# k-means clustering + PCA Graph
# source: https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
set.seed(123)

k = 5

res.km <- kmeans(data, k, nstart = 100)
# K-means clusters showing the group of each individuals
task_clusters <- as.data.frame(cbind(task_names, res.km$cluster))
task_clusters[order(task_clusters$V2),]

# Dimension reduction using PCA
res.pca <- prcomp(data)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)

ind.coord$lbl <- c(1:nrow(data))

ggscatter(
  ind.coord,
  x = "Dim.1",
  y = "Dim.2",
  color = "cluster",
  palette = "npg",
  ellipse = TRUE,
  ellipse.type = "convex",
  label = ind.coord$lbl
) +
  stat_mean(aes(color = cluster), size = k)

ggsave(
  paste("./analysis_experiments/Mapped_task_PCA_Clustered_Colored_AGREEED_", k , ".png", sep = ""),
  width = 7,
  height = 6
)
```

